[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "ReadingsSoftwareTrainingHelp\n\n\n\nTextbooks\nThe course does not strictly follow the content of a textbook, but the expectation is that students will read as much as possible of the assigned chapters from the following books:\n\n\n\n\n\n\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and other stories. Cambridge: Cambridge University Press.  ROS\n\n\nFree to download PDF version from the book’s website: https://avehtari.github.io/ROS-Examples\n\n\n\n\n\n\n\nAlexander, Rohan. 2023. Telling Stories with Data. Chapman and Hall/CRC  TSD\n\n\nFree online book: https://tellingstorieswithdata.com\n\n\n\n\n\n\n\nGelman, A., and Hill, J. 2007. Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge: Cambridge University Press.  ARM\n\n\nNote: ROS is the expanded and updated version of Part 1 (and some of Part 3) of this book. While everyone in the free world eagerly awaits the publication of ROS’s multilevel counterpart, we’ll use ARM as a reference work for the theory underpinning multilevel modelling.  Not freely available. Access it in print or online via the NU library\n\n\n\n\n\nRelatively large portions of text will be assigned for reading in each week from these books, referring to them by their acronyms. Don’t worry if you cannot read all the textbook content assigned in any given week! Those for whom the method covered by the assigned readings is new, will be able to refer back to them throughout the semester and beyond, reading thoroughly and completing the applied exercises. Those already familiar to some extent with the methods, should nonetheless read the text as a narrative and will discover hidden gems that will spectacularly improve their understanding and ability to interpret their statistical results.\n\n\nApplication\nIn the IT labs we will practice applying methods by reproducing small bits of published research, using the data and (critically) the modelling approaches used by the authors. To fully understand the context of these data and the methods used, you must read the original journal articles and the available supplementary materials provided alongside. These readings will be listed under each week’s outline (still work in progress!).\nThe articles come from a variety of different fields, so expect them to push you outside your disciplinary comfort zone. The point is to see how methods have been used in practice and learn how to reproduce (and potentially improve) those analyses. This will then enable you to apply this knowledge to your own research questions.\nWhen selecting the articles, the aim was to strike a fine balance between (a) the simplicity of the methods employed, (b) data and analytical transparency, and (c) the strength of the analysis. So don’t take them as examples of all-rounds best practice, but examples of research that gets published while being self-confident enough to open itself up for public scrutiny. Aim for this in your own research!\n\n\nTechnique\nThere will also be various readings relating more closely to the technicalities of coding in R and scientific writing, collaboration and communication in general. These readings will also be listed under each week’s outline as the semester progresses. The generic reading that students are advised to go through on their own is:\n\n\n\n\n\n\n\nWickham, Çetinkaya-Rundel and Grolemund. 2022. R for Data Science (2nd ed.)  R4DS\n\n\nFree online book: https://r4ds.hadley.nz/\n\n\n\n\n\n\nIntuition\nFinally, there will also be recommended readings listed under certain weeks that help place methods, statistics and probability theory in a broader frame. These are useful readings for everyone, regardless of whether you will be applying quantitative analysis in your research or future work.\n\n\n\n\nRequired software\nWe will use a number of open-source software for data analysis and scientific writing. You need to install these on your personal computers to be able to work away from campus:\n\n\n\n\nR\n(programming language)\nEssential\nR needs to be installed even if we will only use it via the RStudio interface.\nInstall the latest version from here\n\n\n\nRStudio\n(integrated development environment)\nEssential\nYou will need the free desktop version appropriate for your operating system. RStudio combines the R Console - the direct interface to R - with a number of other panels.\nInstall the latest version from here\n\n\n\nTidyverse\n(collection of R packages)\nEssential\nThe tidyverse is a collection of packages that make the R language easier to use by introducing a more consistent grammar. It provides functions that are particularly useful for data manipulation and visualisation. It is the most common ‘dialect’ used among social scientists.\nInstall from within RStudio by executing in the Console:\ninstall.packages(\"tidyverse\")\n\n\n\nQuarto\n(scientific publishing system)\nEssential\nWe will be using Quarto markdown documents (.qmd) throughout the course to document our data analysis. .qmd files extend the plain-text Markdown mark-up language (.md) to allow for data analysis code to be executed and results presented alongside the main text. This is an essential requirement for analytical transparency, reliability and reproducibility.The assignment will also be completed in .qmd.\nIncluded by default in the latest RStudio release; no need to install separately.\nYou can check your installation by executing in the RStudio Terminal :\nquarto check\n\n\n\nZotero\n(reference manager)\nRecommended\nIf you are not yet using a reference manager, I recommend giving Zotero a try. It will make your work much more efficient and it integrates (relatively well) with RMarkdown and Quarto using the the Better BibTeX add-on.\nInstall the latest version and add-ons from here\n\n\n\n\n\n\nStudents with no previous experience using R and/or RStudio are advised to complete the self-paced free online training course R for Social Scientists provided by Data Carpentry at https://datacarpentry.org/r-socialsci/\n\n\n\nThere are several ways to get help with  outside class. If you encounter an error message or are looking for a function to perform a specific task that we have not covered in class, you can do a Google search; for best results, use the https://rseek.org/ search engine, which limits the results to those relating to the  language.\nYou can also search for answers on Stack Overflow, which is a popular help and discussion website for programmers. You can also post a question there, but make sure to follow community standards and advice on how to ask a good question and how to provide a minimal reproducible example. You will need some experience using the site before being able to ask a good question, but it’s more than certain that any question you have at this stage has already been asked and answered somewhere. Make sure you do a comprehensive search with various prompts before thinking about asking your question.\nIncreasingly, large language model-based chatbots such as the (in)famous ChatGPT can also provide good answers. You can use them efficiently, but make sure to always test out the responses, in the overwhelming majority of the cases the advice they give is unreliable, at least at first try."
  },
  {
    "objectID": "plan8.html",
    "href": "plan8.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "Week\nTW\nDate\nTopic\nInfo\nNotes\nLecture\nLabs\nHandouts\n\n\n\n\n\n22\n29 January\nIntroduction\n\n\n\n\n\n\n\nWeek 1\n22\n30 January\nMind your language  A brief introduction to R, RStudio, and other tools of the trade\n\n\n\n\n  \n\n\nWeek 2\n23\n06 February\nEscaping Flatland  Linear models and their limitations\n\n  \n\n\n  \n\n\nWeek 3\n24\n13 February\nCategories  Logistic regression and other generalised linear models\n\n\n\n\n  \n\n\nWeek 4\n25\n20 February\nInteractions  Estimating, graphing and interpreting interaction effects\n\n\n\n\n  \n\n\nWeek 5\n26\n27 February\nBiases  Considerations for causal analysis\n\n  \n\n\n  \n\n\nWeek 6\n27\n05 March\nHierarchies  Multilevel models\n\n\n\n\n  \n\n\nWeek 7\n28\n12 March\nTemporalities  Time series, panel and longitudinal data analysis\n\n\n\n\n  \n\n\nWeek 8\n29\n19 March\nStudy design  Simulation-based power analysis for study design\n\n\n\n\n  \n\n\n\n29\n22 March\nConclusions"
  },
  {
    "objectID": "materials/worksheets/worksheets_w07.html",
    "href": "materials/worksheets/worksheets_w07.html",
    "title": "Week 7 Worksheet Exercises",
    "section": "",
    "text": "By the end of the session you will learn how to:\n\nfit random-intercepts and random coefficients models to hierarchical data that contains a temporal dimension\nuse several R packages for modelling time-series data",
    "crumbs": [
      "Materials",
      "Week 7",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w07.html#aims",
    "href": "materials/worksheets/worksheets_w07.html#aims",
    "title": "Week 7 Worksheet Exercises",
    "section": "",
    "text": "By the end of the session you will learn how to:\n\nfit random-intercepts and random coefficients models to hierarchical data that contains a temporal dimension\nuse several R packages for modelling time-series data",
    "crumbs": [
      "Materials",
      "Week 7",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w07.html#setup",
    "href": "materials/worksheets/worksheets_w07.html#setup",
    "title": "Week 7 Worksheet Exercises",
    "section": "Setup",
    "text": "Setup\nCreate a worksheet document\nIn Week 1 you set up R and RStudio, and an RProject folder (we called it “HSS8005_labs”) with an .R script and a .qmd or .Rmd document in it (we called these “Lab_1”). Ideally, you saved this on a cloud drive so you can access it from any computer (e.g. OneDrive). You will be working in this folder. If it’s missing, complete Exercise 3 from the Week 1 Worksheet.\nCreate a new Quarto markdown file (.qmd) for this session (e.g. “Lab_7.qmd”) and work in it to complete the exercises and report on your final analysis.",
    "crumbs": [
      "Materials",
      "Week 7",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w07.html#r-packages",
    "href": "materials/worksheets/worksheets_w07.html#r-packages",
    "title": "Week 7 Worksheet Exercises",
    "section": "R packages",
    "text": "R packages\n\nCode# Just in case we get errors asking that the package repositories be explicitly set when installing new packages:\n\noptions(repos = list(CRAN = \"http://cran.rstudio.com/\"))\n\n# Install and load required packages\n\n# We can use the {pacman} package to easily install and load several packages:\n# ({pacman} itself may need installing if not yet installed)\n\npacman::p_load(\n  tidyverse, sjlabelled, easystats, \n  ggformula, ggeffects, marginaleffects, \n  modelsummary, gtsummary,\n  survey, sandwich, lmtest, lme4,            # for general hierarchical modelling\n  panelr, plm, pglm)                         # for time-series hierarchical data structures",
    "crumbs": [
      "Materials",
      "Week 7",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w07.html#exercise-1",
    "href": "materials/worksheets/worksheets_w07.html#exercise-1",
    "title": "Week 7 Worksheet Exercises",
    "section": "Exercise 1",
    "text": "Exercise 1\nFor this exercise, work through the modelling of the Mitchell (2021) dataset carried out in Example 2 in the Notes.\nSpend some time looking over the article and the dataset to understand the variables included.\nThe example in the Notes only focuses on specifying the different multilevel model specifications, but using the steps from the previous week and from Example 1 in the Notes, first create some summary descriptions of the data.",
    "crumbs": [
      "Materials",
      "Week 7",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w07.html#exercise-2",
    "href": "materials/worksheets/worksheets_w07.html#exercise-2",
    "title": "Week 7 Worksheet Exercises",
    "section": "Exercise 2",
    "text": "Exercise 2\nNo return to the models based on the Österman (2021) from the Week 6 worksheet and expand those models to also include the survey “round” variable (essround) as an additional level accounting for variation across rounds/time.\nFor this exercise, you cna combine the code from Exercise 1 above with that developed in Week 6.\nInclude these new models in a summary table to contract the results from the previous models and reflect on the differences.",
    "crumbs": [
      "Materials",
      "Week 7",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w07.html#exercise-3",
    "href": "materials/worksheets/worksheets_w07.html#exercise-3",
    "title": "Week 7 Worksheet Exercises",
    "section": "Exercise 3",
    "text": "Exercise 3\nUsing the hierarchical modelling functions from Exercise 1 above, develop an analysis using the simple toy dataset on student test scores from Example 1 in the Notes. You are free to construct your own model.",
    "crumbs": [
      "Materials",
      "Week 7",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w05.html",
    "href": "materials/worksheets/worksheets_w05.html",
    "title": "Week 5 Worksheet Exercises",
    "section": "",
    "text": "This session will help you think more carefully about the causal claims you can make from a regression-based analysis of observational (i.e. non-experimental) data. We will practice some more elementary methods for slicing data to assess group differences and relate them to the linear regression methods familiar from previous weeks. We will also take a step back from data to think more conceptually about some of the models we have encountered so far, and to begin thinking about the research questions and the theoretical and empirical estimands (quantities of interest) that you would like to investigate on a dataset of your choice. These will be the first steps towards the analysis you will be submitting for assessment in two months’ time.",
    "crumbs": [
      "Materials",
      "Week 5",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w05.html#aims",
    "href": "materials/worksheets/worksheets_w05.html#aims",
    "title": "Week 5 Worksheet Exercises",
    "section": "",
    "text": "This session will help you think more carefully about the causal claims you can make from a regression-based analysis of observational (i.e. non-experimental) data. We will practice some more elementary methods for slicing data to assess group differences and relate them to the linear regression methods familiar from previous weeks. We will also take a step back from data to think more conceptually about some of the models we have encountered so far, and to begin thinking about the research questions and the theoretical and empirical estimands (quantities of interest) that you would like to investigate on a dataset of your choice. These will be the first steps towards the analysis you will be submitting for assessment in two months’ time.",
    "crumbs": [
      "Materials",
      "Week 5",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w05.html#setup",
    "href": "materials/worksheets/worksheets_w05.html#setup",
    "title": "Week 5 Worksheet Exercises",
    "section": "Setup",
    "text": "Setup\nCreate a worksheet document\nIn Week 1 you set up R and RStudio, and an RProject folder (we called it “HSS8005_labs”) with an .R script and a .qmd or .Rmd document in it (we called these “Lab_1”). Ideally, you saved this on a cloud drive so you can access it from any computer (e.g. OneDrive). You will be working in this folder. If it’s missing, complete Exercise 3 from the Week 1 Worksheet.\nCreate a new Quarto markdown file (.qmd) for this session (e.g. “Lab_5.qmd”) and work in it to complete the exercises and report on your final analysis.\nLoad R packages\nUsing functions learnt in Week 1, load (and install, if needed) the following R packages:\n\ntidyverse\neasystats\ngtsummary\nggformula\nsjlabelled\nggeffects\nmarginaleffects",
    "crumbs": [
      "Materials",
      "Week 5",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w05.html#introduction",
    "href": "materials/worksheets/worksheets_w05.html#introduction",
    "title": "Week 5 Worksheet Exercises",
    "section": "Introduction",
    "text": "Introduction",
    "crumbs": [
      "Materials",
      "Week 5",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w05.html#exercise-1-estimating-the-persuasive-power-of-the-news-media",
    "href": "materials/worksheets/worksheets_w05.html#exercise-1-estimating-the-persuasive-power-of-the-news-media",
    "title": "Week 5 Worksheet Exercises",
    "section": "Exercise 1: Estimating the persuasive power of the news media",
    "text": "Exercise 1: Estimating the persuasive power of the news media\nIn this exercise we will focus on data from an article by Ladd and Lenz (2009) (follow the doi link in the citation to access the article). You can also download the article from here and download the article’s appendix from here). In this article the authors aim to estimate whether (print) media has the power to persuade people to vote differently. In general terms, this is a very interesting question, even though the power of print media has definitely weakened over the past few decades and measuring the effect of alternative media sources would present additional challenges. Nevertheless, the authors attempt to take advantage of a unique natural experiment that arguably facilitates tackling this causal question: between the 1992 and 1997 UK general elections, four newspapers (the Sun, Daily Star, Independent, and Financial Times) changed their editorial stance and tone from supporting the Conservative Party to supporting Tony Blair’s Labour Party. Such radical shifts editorial stance are extremely rare. The data they use come from several waves of the British Election Panel Study from between 1992 and 1997 and include variables on voting behaviour in 1992 and 1997, as well as whether the respondent was a reader of one of the “switching” newspapers. These are the main variables that are useful for tackling the causal effect involved in the research question, but there are several other variable that provide various controls.\nData\nWe can import the dataset (available in Stata’s.dta format) from the course website. For the purpose of this exercise, we select only three core variables of interest:\n\n# Let's call the data object \"news\" for simplicity\n\nnews &lt;- sjlabelled::read_stata(\"https://cgmoreh.github.io/HSS8005-data/LaddLenz.dta\") |&gt; \n  select(tolabor, vote_l_92, vote_l_97) |&gt; \n  # let's also rename the variable `tolabor` to `reader`, which sounds more intuitive, perhaps\n  rename(reader = tolabor)\n\n\ndata_codebook(news)\n\nComparing proportions\nThe aim of Ladd and Lenz (2009) is to estimate the effect of “reading a switching newspaper” on respondents’ voting behaviour change between the 1992 and 1997 elections. In terms of our variables in the dataset, they aim to estimate vote_l_97 (Voted Labour in 1997) from vote_l_92 (Prior Labour vote in 1992) as moderated by reader (treatment: indicator of whether reading a switching newspaper). All three variables are binary indicator variables.\nWe have data consisting of measurements on the same individuals at two different time points (1992 and 1997), which allows us to think in causal terms. But the question could be first broken down into two smaller questions exploring:\n\nthe average treatment effect of tolabour in a cross-sectional design (oblivious of prior vote)\na before/after comparison of the treated group, comparing their average vote in 1997 to their average vote in 1992\na differences-in-differences comparison of the average changes over time in the treatment group and average changes over time in the control group.\n\nOverall mean vote for Labour in 1997 and 1992\nWhat is the overall proportion of those voting Labour in the 1997 elections in the sample?\n\nmean(news$vote_l_97)\n\nAnd it 1992:\n\nmean(news$vote_l_92)\n\nAs with all proportions, these can be read as a percentage if multiplied by 100, and we can also round the numbers to one decimal point:\n\nround(mean(news$vote_l_97) * 100, digits = 1)\nround(mean(news$vote_l_92) * 100, 1) # we can even omit \"digits = \"\n\nSo the difference in the 1997 and 1992 Labour vote is:\n\nmean(news$vote_l_97 - news$vote_l_92)\n\nOr\n\nround(mean(news$vote_l_97 - news$vote_l_92) * 100, digits = 1)\n\npercentage points.\nTo get a better sense of the data that generates these averages, let’s tabulate the 97-92 Labour vote difference:\n\ndata_tabulate(news$vote_l_97 - news$vote_l_92)\n\n\nIt’s important to understand how these data come about.\nThink (look again) at the coding of the variables involved. What do you think the values in the table represent?\n\nWhich category are those who voted Labour in 1992 but did not vote Labour in 1997?\nWhich category are those who did not vote Labour in 1992, but voted Labour in 1997?\n\nWhat does the 0 category stand for here?\n\n\nConditional averages\nWhat about the proportion of Labour voters among those who read/not read papers that shifted their editorial support?\n\n# We can first break down the dataset into two:\nnot_reader &lt;- news |&gt;  filter(reader == 0) \nreader &lt;- news |&gt;  filter(reader == 1) \n\n# Then calculate means within each:\nnot_reader_97_lab_vote_mean &lt;- mean(not_reader$vote_l_97)\nreader_97_lab_vote_mean     &lt;- mean(reader$vote_l_97)\n\n# With the result:\nnot_reader_97_lab_vote_mean \nreader_97_lab_vote_mean \n\n\nnews |&gt;  \n  group_by(reader) |&gt;  \n  summarize(mean(vote_l_97, na.rm = TRUE))\n\n\nmean(news$vote_l_97[news$reader == 0], na.rm = TRUE)\nmean(news$vote_l_97[news$reader == 1], na.rm = TRUE)\n\nDifference between “treatment” groups in 1997: “Average Treatment Effect”\nThe average treatment effect would be the difference between the two groups in the 1997 vote share:\n\nbetween_97 &lt;- reader_97_lab_vote_mean - not_reader_97_lab_vote_mean\nbetween_97\nATE &lt;- between_97\nround(ATE * 100, 1)\n\nBetween in 1992\n\nnot_reader_92_lab_vote_mean &lt;- mean(not_reader$vote_l_92)\nreader_92_lab_vote_mean     &lt;- mean(reader$vote_l_92)\n\nnot_reader_92_lab_vote_mean\nreader_92_lab_vote_mean\n\n\nbetween_92 &lt;- reader_92_lab_vote_mean - not_reader_92_lab_vote_mean\nbetween_92\nround(between_92 * 100, 1)\n\nBefore/After difference within “treatment” groups\n\nmean(news$vote_l_92[news$reader == 0], na.rm = TRUE)\nmean(news$vote_l_92[news$reader == 1], na.rm = TRUE)\n\n\nwithin_nonreader  &lt;- not_reader_97_lab_vote_mean - not_reader_92_lab_vote_mean\nwithin_reader     &lt;- reader_97_lab_vote_mean - reader_92_lab_vote_mean\n\nwithin_nonreader\nwithin_reader\n\nDifferences-in-Differences\nWe can get the “difference in differences” effect in several ways:\n\nDiD &lt;- within_reader - within_nonreader\n\nDiD\n\n\nbetween_97 - between_92\n\nWe can also obtain the DiD estimate with a linear regression model, in which the outcome \\(y\\) is the within-treatment-group difference and the predictor \\(x\\) is the “treatment” (reader). We can calculate the \\(y\\) as part of the regression command, but to include a mathematical operation within the regression function, we need to “isolate” the mathematical operation using the I() function:\n\nDiD_reg &lt;- lm(I(vote_l_97 - vote_l_92) ~ reader, data = news)\nget_parameters(DiD_reg)\n\n\nLook back at the tabulation of the vote_l_97 - vote_l_92 difference from earlier to check again the values taken by \\(y\\) in this model.\n\nWhat does the (Intercept) term represent here?\n\n\nLinear probability model\nThe comparison of proportions that we calculated earlier relies on comparing average changes. We can also asses the effects involved using ordinary least squares (OLS) linear regression (a so-called “linear probability model” given that our outcome is binary). For example, we can check what the overall mean vote for Labour in 1997 was in the sample, and the average treatment effect we calculated earlier:\n\n## the overall mean of Labour vote in 1997\nmean_l_97 &lt;- lm(vote_l_97 ~ 1, data = news)\ncoefficients(mean_l_97)\n\nIn the above, we do not include any predictor \\(y\\) variables; instead, we specify a number 1 on the right hand side of the equation to get an “intercept”, an average of the entire sample.\nIncluding the “treatment” variable reader in the model gives us the average treatment effect form earlier:\n\nATE_reg &lt;- lm(vote_l_97 ~ reader, data = news)\ncoefficients(ATE_reg)\n\nThe “(Intercept)” here absorbs only one variable category - when the value of reader is 0 (i.e. when the respondent is a “non-reader”, or an “untreated” case) - and as such it tells us the proportion of the 1997 Labour vote among those who were not readers of one of the endorsement-shifting newspapers.\nIt can often be useful to know how to extract specific coefficients/parameters from regression model results, which allows us to perform further operations on them. Below we use both base-R functions and some equivalent - and simpler - functions from the insight package which is included as part of the easystats meta-package:\n\n## base R: extract intercept coefficient, turn into percetage and round down to 1 decimals\ncoefficients(ATE_reg)[\"(Intercept)\"]\ncoefficients(ATE_reg)[\"(Intercept)\"][[1]]\nround(coefficients(ATE_reg)[\"(Intercept)\"][[1]] * 100, 1)\n\n## Extracting the intercept value with vbase-R and formatting it using easystats {insight}\ncoefficients(ATE_reg)[\"(Intercept)\"][[1]] |&gt; format_percent(digits = 1)\n\n## Extracting the intercept value and formatting it using easystats {insight}\nget_intercept(ATE_reg) |&gt; format_percent(1)\nformat_percent(get_intercept(ATE_reg), 1)\n\nWhat happens if we add together the two coefficients from the ATE_reg model?\n\ncoefficients(ATE_reg)[\"(Intercept)\"] + coefficients(ATE_reg)[\"reader\"]\n\nWe can also use the the get_parameters() function from insight for this:\n\n# Extracting parameter values (including for the intercept) and manipulating them, using {insight}\nget_parameters(ATE_reg)\nget_parameters(ATE_reg)[2]\nget_parameters(ATE_reg)[2] |&gt; sum()\nget_parameters(ATE_reg)[[2]]\nget_parameters(ATE_reg)[[2]] |&gt; sum()\n\n\nWhat dos the combined (additive) parameter of the (Intercept) and reader from the model above represent?\n\nWe can also obtain this parameter directly from a regression specification that omits the intercept term from the model. It is almost never a good idea, in practice, to omit the intercept term from a model, but this example can provide an easy explanation of what happens if we do omit it. To leave out the intercept from a regression in R , we can replace the value of 1 on the right hand side of the equation (that value is always added into the regression model by default, even if we do not specify it) with either a 0 or a -1. W can check below whether the two procedures produce equivalent results:\n\n## the mean of Labour vote in 1997 among the \"treated\"\nreader_mean_l_97a &lt;- lm(vote_l_97 ~  0 + reader, data = news)\nreader_mean_l_97b &lt;- lm(vote_l_97 ~ -1 + reader, data = news)\n\nget_parameters(reader_mean_l_97a)\nget_parameters(reader_mean_l_97b)\n\n## Are the two coefficients for `reader` obtained above identical?\n\n### Extract coefficients with base-R\nidentical(coefficients(reader_mean_l_97a), \n          coefficients(reader_mean_l_97b)\n          )\n### Extract parameters (names and coefficients) with {insight}\nidentical(get_parameters(reader_mean_l_97a),\n          get_parameters(reader_mean_l_97b)\n          )\n\nIf we treat the reader variable as a factor (categorical) - instead of numeric -, we can see more clearly what the lack of an intercept means, and how the coefficient of reader changes meaning compared to the model with the intercept included:\n\nreader_mean_l_97c &lt;- lm(vote_l_97 ~  0 + as.factor(reader), data = news)\n\n## Pretty print parameters, keeping only the coefficients\nget_parameters(reader_mean_l_97c)\nmodel_parameters(reader_mean_l_97c) |&gt; print(select = c(\"Parameter\", \"Coefficient\"), digits = 3)\ncompare_parameters(reader_mean_l_97c, ci = NULL) |&gt; print(digits = 3)\n\ncompare_parameters(reader_mean_l_97a, \n                   reader_mean_l_97b, \n                   reader_mean_l_97c, \n                   ci = NULL) |&gt; print(digits = 3)\n\n\nCheck these regression results against the values for not_reader_97_lab_vote_mean and reader_97_lab_vote_mean obtained previously and attemt an interpretation.\n\n\nget_parameters(reader_mean_l_97a)\n\nWe can now add the third variable - Labour vote in 1992 - into the model:\n\nm1 &lt;- lm(vote_l_97 ~ reader + vote_l_92, data = news)\ncoefficients(m1)\n\n\nQuestions\nWhat does this simple model tell us?\n\nWhat about if we also include the interaction effect between the two predictors?\n\nm1_int &lt;- lm(vote_l_97 ~ factor(reader) * factor(vote_l_92), data = news)\nsummary(m1_int)\n\n\nQuestion: How do we interpret the coefficients on this simple interaction model?\nIf the interpretation of the interaction model proves difficult (as it should), maybe it’s better to visualise the model by plotting the coefficients. We can do that using the sjPlot::plot_model() function:\n\nggpredict(m1_int, terms = c(\"reader\", \"vote_l_92\")) |&gt; \n  plot(connect.lines = TRUE)\n\nTo make the meaning of the plot even more straightforward for our interpretative purposes, we can make some changes to the y-axis to display vertical lines at the probability-levels that we got from the model coefficients, and label them with the name of the regression terms. Check the code below against the information from the model summary:\n\nggpredict(m1_int, terms = c(\"reader\", \"vote_l_92\")) |&gt; \n  plot(connect.lines = TRUE, dodge = NULL) + \n  theme(panel.grid.minor = element_blank(),\n        axis.title.y = element_blank()) +\n  expand_limits(x = 0, y = 0) +\n  scale_y_continuous(breaks = c(0,\n                                0.20513, \n                                0.20513 + 0.15921, \n                                0.20513 + 0.69846, \n                                0.20513 + 0.15921 + 0.69846-0.13597,\n                                1),\n                     labels = c(\"0%\",\n                                \"92 Not-Lab Not-Reader \\n Intercept (20.5%)\",\n                                \"92 Not-Lab Reader\",\n                                \"92 Lab Not-Reader\",\n                                \"92 Lab Reader\",\n                                \"100%\")) +\n  scale_x_continuous(breaks = c(0, 1))\n\n\nggpredict(m1_int, terms = c(\"vote_l_92\",\"reader\")) |&gt; \n  plot(connect.lines = TRUE, dodge = NULL) + \n  theme(panel.grid.minor = element_blank(),\n        axis.title.y = element_blank()) +\n  expand_limits(x = 0, y = 0) +\n  scale_y_continuous(breaks = c(0,\n                                0.20513, \n                                0.20513 + 0.15921, \n                                0.20513 + 0.69846, \n                                0.20513 + 0.15921 + 0.69846-0.13597,\n                                1),\n                     labels = c(\"0%\",\n                                \"92 Not-Lab Not-Reader \\n Intercept (20.5%)\",\n                                \"92 Not-Lab Reader\",\n                                \"92 Lab Not-Reader\",\n                                \"92 Lab Reader\",\n                                \"100%\")) +\n  scale_x_continuous(breaks = c(0, 1))",
    "crumbs": [
      "Materials",
      "Week 5",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w03.html",
    "href": "materials/worksheets/worksheets_w03.html",
    "title": "Week 3 Worksheet Exercises",
    "section": "",
    "text": "This session introduces binary logistic regression models. These models are the simplest form of a broader class of models called generalised linear models, which are applicable when the outcome (“dependent”, “response”, “explained”, etc.) variable cannot be assumed to follow a Gaussian (i.e. “normal”) distribution, but it instead a bounded or discrete measurement (e.g. think of variables whose values cannot be negative - i.e. have a lower limit of 0 - or fall into discrete categories such as “yes”/“no”, “disagree”/“neither agree nor disagree”/“agree”, or “blue”/“green”/“black”/“brown”/“other”). Binary logistic regression is the simplest case, where the outcome can take only two values (therefore “binary”). However, the logic that underpins it is similar to that of other generalised linear models.\nBy the end of the session you will learn how to:\n\nFit and summarise logistic regression models in R\n\nInterpret results from logistic regression models\nManipulate the regression output to ease interpretation\nPlot and visualise results from logistic regression models to aid interpretation",
    "crumbs": [
      "Materials",
      "Week 3",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w03.html#aims",
    "href": "materials/worksheets/worksheets_w03.html#aims",
    "title": "Week 3 Worksheet Exercises",
    "section": "",
    "text": "This session introduces binary logistic regression models. These models are the simplest form of a broader class of models called generalised linear models, which are applicable when the outcome (“dependent”, “response”, “explained”, etc.) variable cannot be assumed to follow a Gaussian (i.e. “normal”) distribution, but it instead a bounded or discrete measurement (e.g. think of variables whose values cannot be negative - i.e. have a lower limit of 0 - or fall into discrete categories such as “yes”/“no”, “disagree”/“neither agree nor disagree”/“agree”, or “blue”/“green”/“black”/“brown”/“other”). Binary logistic regression is the simplest case, where the outcome can take only two values (therefore “binary”). However, the logic that underpins it is similar to that of other generalised linear models.\nBy the end of the session you will learn how to:\n\nFit and summarise logistic regression models in R\n\nInterpret results from logistic regression models\nManipulate the regression output to ease interpretation\nPlot and visualise results from logistic regression models to aid interpretation",
    "crumbs": [
      "Materials",
      "Week 3",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w03.html#setup",
    "href": "materials/worksheets/worksheets_w03.html#setup",
    "title": "Week 3 Worksheet Exercises",
    "section": "Setup",
    "text": "Setup\nIn Week 1 you set up R and RStudio, and an RProject folder (we called it “HSS8005_labs”) with an .R script and a .qmd or .Rmd document in it (we called these “Lab_1”). Ideally, you saved this on a cloud drive so you can access it from any computer (e.g. OneDrive). You will be working in this folder. If it’s missing, complete Exercise 3 from the Week 1 Worksheet.\nCreate a new Quarto markdown file (.qmd) for this session (e.g. “Lab_3.qmd”) and work in it to complete the exercises and report on your final analysis.",
    "crumbs": [
      "Materials",
      "Week 3",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w03.html#exercise-0-load-and-install-r-packages-needed-for-this-lab",
    "href": "materials/worksheets/worksheets_w03.html#exercise-0-load-and-install-r-packages-needed-for-this-lab",
    "title": "Week 3 Worksheet Exercises",
    "section": "Exercise 0: Load (and install) R packages needed for this lab",
    "text": "Exercise 0: Load (and install) R packages needed for this lab\nUsing functions learnt in Week 1, load (and install, if needed) the following R packages:\n\ntidyverse\neasystats\ngtsummary\nggformula\nsjlabelled\nggeffects\nmarginaleffects",
    "crumbs": [
      "Materials",
      "Week 3",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w03.html#exercise-1-modelling-social-trust-and-education",
    "href": "materials/worksheets/worksheets_w03.html#exercise-1-modelling-social-trust-and-education",
    "title": "Week 3 Worksheet Exercises",
    "section": "Exercise 1: Modelling social trust and education",
    "text": "Exercise 1: Modelling social trust and education\nIn this first exercise, follow the steps in the analysis carried out in the Notes to replicate the results presented in Model 1 in Appendix A. Table 2 in Wu (2021).\n\n\n\n\n\n\nTip\n\n\n\nYou can download the raw World Values Survey dataset and prepare it with the code used in the Notes, but you can also download the prepared wvs56 dataset from the Data page and from here",
    "crumbs": [
      "Materials",
      "Week 3",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w03.html#exercise-2-refit-the-model-for-two-single-countries",
    "href": "materials/worksheets/worksheets_w03.html#exercise-2-refit-the-model-for-two-single-countries",
    "title": "Week 3 Worksheet Exercises",
    "section": "Exercise 2: Refit the model for two single countries",
    "text": "Exercise 2: Refit the model for two single countries\nYou will carry out this exercise on your own, and you’ll make two adjustments compared to the previous exercise. Instead of treating the entire dataset as undifferentiated, originating from one single population, we will acknowledge the fact that the data originate from various countries and that the local socio-cultural context has an impact on social behaviours and attitudes. To account for this, re-fit the logistic regression model from the previous exercise in two different ways:\n1.  fit the same model as before, but add the *country* variable to the model as a covariate;\n2.  select *two* countries of your choice, reduce the dataset to that country and fit the model on that data;\nIn order to select countries from the data, you will need to use another function, filter(), which lets us select rows (cases) given some criteria.",
    "crumbs": [
      "Materials",
      "Week 3",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w03.html#exercise-3-advanced-religiosity-and-social-trust",
    "href": "materials/worksheets/worksheets_w03.html#exercise-3-advanced-religiosity-and-social-trust",
    "title": "Week 3 Worksheet Exercises",
    "section": "Exercise 3 (Advanced): Religiosity and social trust",
    "text": "Exercise 3 (Advanced): Religiosity and social trust\nRead through the article by (Dingemans and Van Ingen 2015) and replicate their Model 1 in Table 1. They use data from the European Values Study, which is also freely available to download from the EVS website. Rely on the code and steps undertaken in the analysis presented in the Notes.",
    "crumbs": [
      "Materials",
      "Week 3",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w01.html",
    "href": "materials/worksheets/worksheets_w01.html",
    "title": "Week 1 Worksheet Exercises",
    "section": "",
    "text": "By the end of the session, you will:\n\nunderstand how to use the most important panels in the RStudio interface\ncreate an RStudio Project to store your work throughout the course\nbegin using R scripts (.R) and Quarto notebooks (.qmd) to record and document your coding progress\nunderstand data types and basic operations in the R language\nunderstand the principles behind functions\n\nknow how to install, load and use functions from user-written packages\ngain familiarity with some useful functions from packages included in the tidyverse ecosystem",
    "crumbs": [
      "Materials",
      "Week 1",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w01.html#aims",
    "href": "materials/worksheets/worksheets_w01.html#aims",
    "title": "Week 1 Worksheet Exercises",
    "section": "",
    "text": "By the end of the session, you will:\n\nunderstand how to use the most important panels in the RStudio interface\ncreate an RStudio Project to store your work throughout the course\nbegin using R scripts (.R) and Quarto notebooks (.qmd) to record and document your coding progress\nunderstand data types and basic operations in the R language\nunderstand the principles behind functions\n\nknow how to install, load and use functions from user-written packages\ngain familiarity with some useful functions from packages included in the tidyverse ecosystem",
    "crumbs": [
      "Materials",
      "Week 1",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w01.html#exercise-1-install-r-and-rstudio-and-perform-basic-settings",
    "href": "materials/worksheets/worksheets_w01.html#exercise-1-install-r-and-rstudio-and-perform-basic-settings",
    "title": "Week 1 Worksheet Exercises",
    "section": "Exercise 1: Install R and RStudio, and perform basic settings",
    "text": "Exercise 1: Install R and RStudio, and perform basic settings\nTo install R and RStudio on your personal computers, follow the steps outlined here based on your operating system.\nAlthough you will only interact directly with RStudio in this module, R needs to be installed first so that RStudio can detect it and connect to it.\nOnce installed, open RStudio and explore its panes.\nMake the following changes to the RStudio settings in the Global options:\n\nset RStudio to never save your workspace as .RData upon exiting;\nset RStudio to insert the native “pipe operator” when typing the Ctrl+Shift+M keyboard shortcut.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w01.html#advanced-user-exercise-leap-year-functions",
    "href": "materials/worksheets/worksheets_w01.html#advanced-user-exercise-leap-year-functions",
    "title": "Week 1 Worksheet Exercises",
    "section": "Advanced user exercise: leap year functions",
    "text": "Advanced user exercise: leap year functions\n\nIf you have more advanced knowledge of R, here’s and exercise for you.\nSuppose you want to write a function that lists all the leap years between two specified years. How would you go about writing it? What are the information that you need first? What are the steps that you would take to build up the function? There are several ways of achieving such a function, and you can find three options at the bottom of this worksheet. Work individually or in a small group.\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nYou first need to check the definition of a leap year and how it is calculated (Google?)\nAsk R to tell you what the “%%” operator does. You can ask R for help using the help() function or ?....\nWhen you are done, you can check your results against the example solutions given at the bottom of this worksheet.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w01.html#exercise-2-use-r-as-a-simple-calculator",
    "href": "materials/worksheets/worksheets_w01.html#exercise-2-use-r-as-a-simple-calculator",
    "title": "Week 1 Worksheet Exercises",
    "section": "Exercise 2: Use R as a simple calculator",
    "text": "Exercise 2: Use R as a simple calculator\nThe most elementary yet still handy task you can use R for is to perform basic arithmetic operations. This is useful for getting a first experience doing things in the R language.\nLet’s have a look at a few operations using the Console directly. Let’s say we want to know the result of adding up three numbers: 1, 3 and 5. In the Console pane, type the command below and then click Enter:\n\n1 + 3 + 5\n\nThis will print out the result (9) in the Console:\n\n\n[1] 9\n\n\nThe [1] in the result is just the line number; in this case, our result only consists of a single line.\nWe can also save the result of this operation as an object, so we can use it for further operations. We create objects by using the so-called assignment operator consisting of the characters &lt;-.\nA command involving &lt;- can be read as “assign the value of the result from the operation on the right hand side (some expression) to the object on the left hand side (short name of object, single word, with no spaces)”.\nFor example, let’s save our result in an object called “nine”:\n\nnine &lt;- 1 + 3 + 5\n\nNotice that there is no output printed in the Console this time. But there are also no error messages, so the operation must have run without problems. Instead, if we look at the Environment pane, we notice that it is no longer empty, but contains an object called “nine” that stores the value “9” in it. We can now use this object for other operations, such as:\n\nnine - 3\nnine + 15\nnine / 3\nnine * 9\n\nWe see the results of these operations printed out in the Console.\nWe can also check results of so-called relational operations. There are several relational operators that allow us to compare objects in R. The most useful of these are the following:\n\n\n&gt; greater than, &gt;= greater than or equal to\n\n&lt; less than, &lt;= less than or equal to\n\n== equal to\n\n!= not equal to\n\nWhen we use these to compare two objects in R, we end up with a logical object.\nFor example, let’s check whether 9 is greater than 5, and whether it is lower than 8:\n\n9 &gt; 5\n9 &lt; 8\n\nR treats our inputs as statements that we are asking it to evaluate, and we get the answers “TRUE” and “FALSE”, respectively, as we would expect. Let’s now check whether our object “nine” is equal to the number 9. We may assume that we can achieve this by typing “nine = 9”, but let’s see what that results in:\n\nnine = 9\n\nDid we get the result we expected? Nothing was printed in the output, so seemingly nothing happened… That’s because the “=” sign is also used as an assignment operator in R, just like “&lt;-”. So we basically assigned the value “9” to the object “nine” again. To use the equal sign as a logical operator we must type it twice (==). Let’s see:\n\nnine == 9\n\nNow we get the answer “TRUE”, as expected.\nThis distinction between “=” and “==” is important to keep in mind. What would have happened if we had tried to test whether our object “nine” equals value “5” or not, and instead of the logical operator (==) we used the assignment operator (=)? Let’s see:\n\nnine = 5\n\nIn the Console we again see no results printed, but if we check our Environment, we see that the value of the object “nine” was changed to 5. So it can be a dangerous business. We’ll be using the “&lt;-” as assignment operator instead of “=” to avoid any confusion in this respect. The distinction between == and = will also emerge in other contexts later.\nSo, try out the following commands in turn now and check if the results are what you’d expect:\n\nnine == 9\nnine == 5\nfive &lt;- 9\nnine == five\nfive = nine\nnine == five\nnine + five &lt;= 10 # lower than or equal to ...\n\nThe text following the hashtag (#) in the last line is a comment. If you’d like to comment on any code you write just add a hash (#) or series of hashes in front of it so that R knows it should not evaluate it as a command. This will be useful when writing your commands in an R script that you can save for later, rather than interacting with R live in the Console.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w01.html#exercise-3-create-an-rstudio-project-containing-a-.r-and-a-.qmd-file",
    "href": "materials/worksheets/worksheets_w01.html#exercise-3-create-an-rstudio-project-containing-a-.r-and-a-.qmd-file",
    "title": "Week 1 Worksheet Exercises",
    "section": "Exercise 3: Create an RStudio Project containing a .R and a .qmd file",
    "text": "Exercise 3: Create an RStudio Project containing a .R and a .qmd file\n\nCreate a new folder set up as an R project; call the folder “HSS8005_labs”; when done, you should have an empty folder with a file called “HSS8005_labs.Rproj” in it\nCreate a new R script (.R); once created, save it as “Lab_1.R” within the “HSS8005_labs” folder\nCreate a new Quarto document (.qmd); once created, save it as “Lab_1.qmd” within the “HSS8005_labs” folder\n\nYou will work in each of these new documents in this lab to gain experience with them.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w01.html#exercise-4-vector-operations",
    "href": "materials/worksheets/worksheets_w01.html#exercise-4-vector-operations",
    "title": "Week 1 Worksheet Exercises",
    "section": "Exercise 4: Vector operations",
    "text": "Exercise 4: Vector operations\nLet’s learn a few vector operations. Type/copy the code below to the R script file your created earlier (“Lab_1.R”), and save it at the end for your records.\nFirst, let’s use the c() function to concatenate vector elements:\n\nx &lt;- c(2.2, 6.2, 1.2, 5.5, 20.1)\n\nTo run this line of code in an R script, place the cursor on the line you want to execute and either click on the small “Run” tab in the upper-right corner of the script’s task bar, or click Ctrl+Enter (on Windows PCs).\nThe vector called x that we just created appears in the Environment. We can examine some of its features:\n\nclass(x)\ntypeof(x)\nlength(x)\nattributes(x)\n\nThese tell us something about the characteristics of the object, but not much about its content (apart from the fact that it has a length of 5). Functions such as min, max, range, mean, median, sum or summary give us some summary statistics about the object:\n\nmin(x)\nmax(x)\nrange(x)\nmean(x)\nmedian(x)\nsum(x)\nsummary(x)\n\nThe seq() function lets us create a sequence from a starting point to an ending point. If you specify the by argument, you can skip values. For instance, if we wanted a vector of every 5th number between 0 and 100, we could write:\n\nnumbers &lt;- seq(from = 0, to = 100, by = 5)\n\nTo print out the result in the console, we can simply type the name of the object:\n\nnumbers\n\nA shorthand version to get a sequence between two numbers counting by 1s is to use the : sign. For example, print out all the numbers between 200 and 250:\n\n200:250\n\nTo access a single element of a vector by position in the vector, use the square brackets []:\n\nx[2]\n\nIf you want to access more than one element of a vector, put a vector of the positions you want to access in the brackets:\n\nx[c(2, 5)]\n\nIf you try to access an element past the length of the vector, it will return a missing value NA:\n\nx[10]\n\nIf you accidentally subset a vector by NA (the missing value), you get the vector back with all its entries replaced by NA:\n\nx[NA]\n\nLet’s say you want to modify one value in your vector. You can combine the square bracket subset [] with the assignment operator &lt;- to replace a particular value:\n\nx\nx[3] &lt;- 50.3\nx\n\nYou can replace multiple values at the same time by using a vector for subsetting:\n\nx\nx[1:2] &lt;- c(-1.3, 42)\nx\n\nIf the replacement vector (the right-hand side) is shorter than what you are assigning to (the left-hand side), the values will “recycle” or repeat as necessary:\n\nx[1:2] &lt;- 3.2\nx\n\nx[1:4] &lt;- c(1.2, 2.4)\nx\n\nYou can also create a vector of characters (words, letters, punctuation, etc):\n\njedi &lt;- c(\"Yoda\", \"Obi-Wan\", \"Luke\", \"Leia\", \"Rey\")\n\nNote for vectors, you cannot mix characters and numbers in the same vector. If you add a single character element, the whole vector gets converted.\n\n### output is numeric\nx\n\n### output is now character\nc(x, \"hey\")\n\nLogical vectors are just vectors that only contain the special R values TRUE or FALSE.\n\nlogical &lt;- c(TRUE, FALSE, TRUE, TRUE, FALSE)\nlogical\n\nYou could but never should shorten TRUE to T and FALSE to F. It’s easy for this shortening to go wrong so better just to spell out the full word. Also not that this is case-sensitive, and this will produce an error:\n\ntrue\nTrue\nfalse",
    "crumbs": [
      "Materials",
      "Week 1",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w01.html#exercise-5-data-frame-operations-on-built-in-datasets",
    "href": "materials/worksheets/worksheets_w01.html#exercise-5-data-frame-operations-on-built-in-datasets",
    "title": "Week 1 Worksheet Exercises",
    "section": "Exercise 5: Data-frame operations on built-in datasets",
    "text": "Exercise 5: Data-frame operations on built-in datasets\nThere are several toy data frames built into R, and we can have a look at one to see how it looks like.\n\nUse the data() command to get a list of available built-in datasets;\nChoose one of the available datasets and import it into the Rstudio Environment\nOpen the dataset in the Viewer to quickly inspect it visually\nCheck the following using the appropriate R functions:\n\nHow many cases (rows) are in the dataset?\nHow many variables (columns) are in the dataset?\nWhat is the type of the first variables in the dataset?\nPrint the first few and last few entries in the dataset.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w01.html#exercise-6-install-and-load-r-packages",
    "href": "materials/worksheets/worksheets_w01.html#exercise-6-install-and-load-r-packages",
    "title": "Week 1 Worksheet Exercises",
    "section": "Exercise 6: Install and load R packages",
    "text": "Exercise 6: Install and load R packages\nInstall and load the following R packages:\n\ntidyverse\neasystats\ngtsummary\nggformula\n\nSpend a bit of time reading about these packages on their website documentation.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w01.html#exercise-6-data-frame-operations-in-a-quarto-document",
    "href": "materials/worksheets/worksheets_w01.html#exercise-6-data-frame-operations-in-a-quarto-document",
    "title": "Week 1 Worksheet Exercises",
    "section": "Exercise 6: Data frame operations in a Quarto document",
    "text": "Exercise 6: Data frame operations in a Quarto document\nIn this task, let’s start using the other document we created, the .qmd file. This file format allows you to combine both longer written text (such as detailed descriptions of your data analysis process or the main body of a report or journal article) with code chunks. To get you started using this file format, read Chapter 3.2. in TSD. Below we will focus only on the code chunks.\nCompared to what you have done in the R script, in the main Quarto document a # refers to a heading level rather than a comment. If you want to include a code chunk, you can click on the +C tab in the upper-right corner of the .qmd document’s toolbar, or use the keyboard shortcut Ctrl+Alt+i. In the code chunk you would write in the same way as you did in the R script (they are basically mini-scripts). Within a code-chunk, therefore, the # still refers to a comment.\nTo execute a command withing a code chunk, you can either run each line/selection separately using Ctrl+Enter as in the R script, or you can run the entire content of the chunk with the green right-pointing triangle-arrow in the upper-right corner of the chunk.\nLet’s continue doing some operations on the mtcars dataset we looked at earlier, this time using some useful tidyverse functions.\nLet’s subset the data frame by selecting certain rows or columns. In tidyverse, you can do this with the filter() function for selecting rows and the select() function for selecting columns. Here we pipe the selections into head() to show the first few rows. You could also use the dplyr::slice_head function\n\nmtcars |&gt;\n  select(mpg, wt) |&gt;\n  head()\n\nTo select the cars with eight cylinders:\n\nmtcars |&gt;\n  filter(cyl == 8)\n\nWe can use the slice() function. For example, to get the 5th through 10th rows:\n\nmtcars |&gt;\n  slice(5:10)\n\nIf we pass a vector of integers to the select function, we will get the variables corresponding to those column positions. So to get the first through third columns:\n\nmtcars |&gt;\n  select(1:3) |&gt;\n  head()\n\nIf you call summary() a data frame, it produces applies the vector version of the summary command to each column:\n\nsummary(mtcars)\n\nThese few tasks should be enough to get you started with R and RStudio.\nIf this was your first encounter with R, you can complete the R for Social Scientists online training too sometime during the week.\nFrom next week we will begin working actively with real data and address specific data management challenges that arise from there.\nThose of you who have worked on the advanced user exercise can check some optional solutions below.\n\n\n\n\n\n\nSolutions to the advanced exercise: leap year functions\n\n\n\n\n\n\nleap_year_v1 &lt;- function(year1,year2) {\n    year &lt;- year1:year2\n    year[(year%%4==0 & year%%100!=0) | year%%400==0]\n}\n\n\nleap_year_v2 &lt;- function(year1,year2){\n    vector&lt;-c()\n    for(year in year1:year2){\n        if((year %% 4 == 0) & (year %% 100 != 0) | (year  %% 400 == 0)){\n            vector&lt;-c(vector,year)\n        }}\n    return(vector)}\n\n\nleap_year_v3 &lt;- function(year1,year2){\n    #make a vector of all years\n    year&lt;-year1:year2\n    #find the leap years (TRUE/FALSE)\n    leaps&lt;-ifelse((year %% 4 == 0) & (year %% 100 != 0) | (year  %% 400 == 0), TRUE, FALSE)\n    year[leaps] #return the leap years\n}",
    "crumbs": [
      "Materials",
      "Week 1",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/slides/w6.html#a-brief-review-of-single-level-regression-1",
    "href": "materials/slides/w6.html#a-brief-review-of-single-level-regression-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "A brief review of single-level regression",
    "text": "A brief review of single-level regression\nLet’s start with a very simple example\n\n\nWe aim to model an outcome measurement, our estimand: \\(\\color{green}{Y}\\)\n\nWe have data on a number \\((n)\\) of observations \\(({i})\\) (e.g. survey respondents; pupils; students; factory workers; events; etc.): \\({i}_{1\\dots{n}}\\)\n\nWe assume that observations are independent of each other (e.g. different respondents randomly sampled from a population)\nThe outcome measurement has a grand mean across all observations \\((\\mu)\\), and each observation \\((i)\\) has some deviation (error) from this mean \\((e_i)\\)\n\n\\[ y_i = \\mu + \\color{red}{e_i} \\]"
  },
  {
    "objectID": "materials/slides/w6.html#a-brief-review-of-single-level-regression-2",
    "href": "materials/slides/w6.html#a-brief-review-of-single-level-regression-2",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "A brief review of single-level regression",
    "text": "A brief review of single-level regression\n\n\nObserved part: our observation, outcome, estimate, etc.; the left-hand-side of the model\nFixed part: this can be a simple sample mean \\((\\mu)\\) of a single measurement as in our basic example (e.g. a social trust scale), but it can also be a regression equation containing several predictor variables, as we have seen in previous weeks (e.g. \\(b_0 + b_{1i}x_{1i} + b_{2i}x_{2i} \\cdots b_{pi}x_{pi}\\) for a model with \\(p\\) number of predictors/independent variables)\nRandom part: the deviations of the observations from the model mean"
  },
  {
    "objectID": "materials/slides/w6.html#a-brief-review-of-single-level-regression-3",
    "href": "materials/slides/w6.html#a-brief-review-of-single-level-regression-3",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "A brief review of single-level regression",
    "text": "A brief review of single-level regression\n\nWe also assume that the error term \\((e)\\) is Normally distributed around a mean of 0 and has some variance \\((\\sigma^2)\\) that we are estimating"
  },
  {
    "objectID": "materials/slides/w6.html#a-brief-review-of-single-level-regression-4",
    "href": "materials/slides/w6.html#a-brief-review-of-single-level-regression-4",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "A brief review of single-level regression",
    "text": "A brief review of single-level regression\nAn applied example\nData from the @Osterman2021CanWeTrustEducationFostering article Can We Trust Education for Fostering Trust? Quasi-experimental Evidence on the Effect of Education and Tracking on Social Trust:\n\n\n# Import the data\nosterman &lt;- data_read(\"https://cgmoreh.github.io/HSS8005-24/data/osterman.dta\")\n\n\n\n\n\n\ncumulative European Social Survey (ESS) data, consisting of nine rounds from 2002 to 2018\ndata are weighted using ESS design weights (we will disregard this, so we can expect our results to differ somewhat)\nfollows the established approach of using a validated three-item scale to study generalised social trust"
  },
  {
    "objectID": "materials/slides/w6.html#a-brief-review-of-single-level-regression-5",
    "href": "materials/slides/w6.html#a-brief-review-of-single-level-regression-5",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "A brief review of single-level regression",
    "text": "A brief review of single-level regression\nAn applied example\nThe outcome variable of interest is an eleven-point scale measure of social trust:\n\n\nThe scale consists of the classic trust question, an item on whether people try to be fair, and an item on whether people are helpful:\n\nGenerally speaking, would you say that most people can be trusted, or that you can’t be too careful in dealing with people?\n\nDo you think that most people would try to take advantage of you if they got the chance, or would they try to be fair?\n\nWould you say that most of the time people try to be helpful or that they are mostly looking out for themselves?\n\n\n\n\nAll of the items may be answered on a scale from 0 to 10 (where 10 represents the highest level of trust) and the scale is calculated as the mean of the three items\nThe three-item scale improves measurement reliability and cross-country validity compared to using a single item, such as the classic trust question."
  },
  {
    "objectID": "materials/slides/w6.html#a-brief-review-of-single-level-regression-6",
    "href": "materials/slides/w6.html#a-brief-review-of-single-level-regression-6",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "A brief review of single-level regression",
    "text": "A brief review of single-level regression\nAn applied example\nWe’ll select a few variables of interest to keep:\n\n\nosterman &lt;- osterman %&gt;%\n  select(\"trustindex3\", \"cntry\", \"facntr\", \"mocntr\", \"female\", \"agea\", \"eduyrs25\", \"paredu_a_high\")\n\n\n\n\n\nAnd we’ll do some data wrangling; we’ll also reduce the dataset for the purpose of our demonstrations to make it run faster.\n\n\nset.seed(1234)\n\nosterman &lt;- osterman %&gt;%\n  labelled::unlabelled() %&gt;% as_tibble() %&gt;%\n  filter(cntry %in% c(\"GB\", \"IE\", \"DE\", \"FR\", \"HU\", \"PL\", \"PT\", \"ES\")) %&gt;%  \n  group_by(cntry) %&gt;% slice_sample(n=50) %&gt;% ungroup() %&gt;%\n  mutate(cntry = as_factor(cntry),\n         fmnoncntr = ifelse(facntr==0 | mocntr==0, 1, 0)) %&gt;%\n  sjlabelled::var_labels( trustindex3 = \"Social trust scale\",\n                          eduyrs25 = \"Years of full-time education\",\n                          paredu_a_high = \"High parental education\",\n                          fmnoncntr = \"Least one parent born abroad\"\n                        )"
  },
  {
    "objectID": "materials/slides/w6.html#a-brief-review-of-single-level-regression-7",
    "href": "materials/slides/w6.html#a-brief-review-of-single-level-regression-7",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "A brief review of single-level regression",
    "text": "A brief review of single-level regression\nAn applied example\nOur variables of interest look like this:\n\n\n\n\n\n\nMean\nStd.Dev\nMedian\nMin\nMax\nN.Valid\n\n\n\nagea\n52.49\n12.89\n54.00\n25.00\n80.00\n400\n\n\neduyrs25\n12.63\n4.20\n12.00\n0.00\n24.00\n395\n\n\nfacntr\n0.96\n0.19\n1.00\n0.00\n1.00\n400\n\n\nfemale\n0.54\n0.50\n1.00\n0.00\n1.00\n400\n\n\nfmnoncntr\n0.05\n0.21\n0.00\n0.00\n1.00\n400\n\n\nmocntr\n0.97\n0.17\n1.00\n0.00\n1.00\n400\n\n\nparedu_a_high\n0.32\n0.47\n0.00\n0.00\n1.00\n379\n\n\ntrustindex3\n4.89\n1.79\n5.00\n0.00\n9.00\n400"
  },
  {
    "objectID": "materials/slides/w6.html#a-brief-review-of-single-level-regression-8",
    "href": "materials/slides/w6.html#a-brief-review-of-single-level-regression-8",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "A brief review of single-level regression",
    "text": "A brief review of single-level regression\nAn applied example\nThe country variable\n\n\n\n\n\n\n\n\n\n\nValid\nTotal\n\n\ncntry\nFreq\n%\n% Cum.\n%\n% Cum.\n\n\n\n\nDE\n50\n12.50\n12.50\n12.50\n12.50\n\n\nES\n50\n12.50\n25.00\n12.50\n25.00\n\n\nFR\n50\n12.50\n37.50\n12.50\n37.50\n\n\nGB\n50\n12.50\n50.00\n12.50\n50.00\n\n\nHU\n50\n12.50\n62.50\n12.50\n62.50\n\n\nIE\n50\n12.50\n75.00\n12.50\n75.00\n\n\nPL\n50\n12.50\n87.50\n12.50\n87.50\n\n\nPT\n50\n12.50\n100.00\n12.50\n100.00\n\n\n&lt;NA&gt;\n0\n\n\n0.00\n100.00\n\n\nTotal\n400\n100.00\n100.00\n100.00\n100.00"
  },
  {
    "objectID": "materials/slides/w6.html#a-brief-review-of-single-level-regression-9",
    "href": "materials/slides/w6.html#a-brief-review-of-single-level-regression-9",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "A brief review of single-level regression",
    "text": "A brief review of single-level regression\nAn applied example\nLet’s start by fitting a single-level model of social trust as a function of education, age, gender, parental education and whether either of the parents were born abroad (i.e. the variable we computed earlier).\nMathematically, we fit the following model:\n\\[trustindex3=\\beta_0+\\beta_1*eduyears25+\\beta_2*agea+\\beta_3*female+\\\\ +\\beta_4*{paredu}+\\beta_5*{fmnoncntr}+error\\]"
  },
  {
    "objectID": "materials/slides/w6.html#a-brief-review-of-single-level-regression-10",
    "href": "materials/slides/w6.html#a-brief-review-of-single-level-regression-10",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "A brief review of single-level regression",
    "text": "A brief review of single-level regression\nAn applied example\nModel summary:\n\n\n\n\n\nObservations\n376 (24 missing obs. deleted)\n\n\nDependent variable\ntrustindex3\n\n\nType\nOLS linear regression\n\n\n\n\n\n\nF(5,370)\n7.593\n\n\nR²\n0.093\n\n\nAdj. R²\n0.081\n\n\n\n\n\n\n\nEst.\n2.5%\n97.5%\nt val.\np\n\n\n\n(Intercept)\n2.551\n1.454\n3.648\n4.572\n0.000\n\n\neduyrs25\n0.110\n0.062\n0.157\n4.537\n0.000\n\n\nagea\n0.020\n0.005\n0.034\n2.656\n0.008\n\n\nfemale\n-0.204\n-0.559\n0.151\n-1.131\n0.259\n\n\nparedu_a_high\n0.229\n-0.185\n0.643\n1.088\n0.277\n\n\nfmnoncntr\n-0.954\n-1.833\n-0.075\n-2.134\n0.033\n\n\n\n\n Standard errors: OLS\n\n\n\n\n\n\n\n\n\n\nWe have interpreted this model in earlier weeks. Our interest now is in extending it to account for the nesting of cases within different countries."
  },
  {
    "objectID": "materials/slides/w6.html#multilevel-models-1",
    "href": "materials/slides/w6.html#multilevel-models-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Multilevel models",
    "text": "Multilevel models\nIn our dataset we cannot assume that the observations are fully independent (or that the errors are independently distributed). We know that observations were sampled from within selected countries, so the countries are cluster variables that may have a group-level influence on the behaviour, opinions, conditions etc. of our individual observations."
  },
  {
    "objectID": "materials/slides/w6.html#multilevel-models-2",
    "href": "materials/slides/w6.html#multilevel-models-2",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Multilevel models",
    "text": "Multilevel models\nIn our dataset we cannot assume that the observations are fully independent (or that the errors are independently distributed). We know that observations were sampled from within selected countries, so the countries are cluster variables that may have a group-level influence on the behaviour, opinions, conditions etc. of our individual observations."
  },
  {
    "objectID": "materials/slides/w6.html#multilevel-models-3",
    "href": "materials/slides/w6.html#multilevel-models-3",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Multilevel models",
    "text": "Multilevel models\nIn our dataset we cannot assume that the observations are fully independent (or that the errors are independently distributed). We know that observations were sampled from within selected countries, so the countries are cluster variables that may have a group-level influence on the behaviour, opinions, conditions etc. of our individual observations."
  },
  {
    "objectID": "materials/slides/w6.html#multilevel-models-4",
    "href": "materials/slides/w6.html#multilevel-models-4",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Multilevel models",
    "text": "Multilevel models\nIn our dataset we cannot assume that the observations are fully independent (or that the errors are independently distributed). We know that observations were sampled from within selected countries, so the countries are cluster variables that may have a group-level influence on the behaviour, opinions, conditions etc. of our individual observations."
  },
  {
    "objectID": "materials/slides/w6.html#multilevel-models-5",
    "href": "materials/slides/w6.html#multilevel-models-5",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Multilevel models",
    "text": "Multilevel models\nhttp://mfviz.com/hierarchical-models/"
  },
  {
    "objectID": "materials/slides/w6.html#multilevel-models-6",
    "href": "materials/slides/w6.html#multilevel-models-6",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Multilevel models",
    "text": "Multilevel models\nIn our dataset we cannot assume that the observations are fully independent (or that the errors are independently distributed). We know that observations were sampled from within selected countries, so the countries are cluster variables that may have a group-level influence on the behaviour, opinions, conditions etc. of our individual observations.\nWith such data, it makes sense to allow regression coefficients to vary by group.\nSuch variation can already be achieved by simply including group indicators in a least squares regression framework.\nIn other words, we could extend our previous model like such:\n\\[trustindex3=\\beta_0+\\beta_1*eduyears25+\\beta_2*agea+\\beta_3*female+\\\\ +\\beta_4*{paredu}+\\beta_5*{fmnoncntr}+\\color{red}{\\beta_6*{cntry}}+error\\]"
  },
  {
    "objectID": "materials/slides/w6.html#multilevel-models-7",
    "href": "materials/slides/w6.html#multilevel-models-7",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Multilevel models",
    "text": "Multilevel models\nVery often, simply including group indicators in a least squares regression gives unacceptably noisy estimates.\nInstead, we use multilevel regression, a method of partially pooling varying coefficients, equivalent to Bayesian regression where the variation in the data is used to estimate prior distribution on the variation of intercepts and slopes.\nThe terminology surrounding multilevel models can be confusing. Different disciplines use various names for them, for example:\n\nVariance components\nRandom intercepts and slopes\nRandom effects\nRandom coefficients\nVarying coefficients\nIntercepts- and/or slopes-as-outcomes\nHierarchical linear models\nMultilevel models (implies multiple levels of hierarchically clustered data)\nGrowth curve models (possibly Latent GCM)\nMixed effects models"
  },
  {
    "objectID": "materials/slides/w6.html#multilevel-models-8",
    "href": "materials/slides/w6.html#multilevel-models-8",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Multilevel models",
    "text": "Multilevel models\nSome of these terms might be more historical, others are more often seen in a specific discipline, others might refer to a certain data structure, and still others are special cases (e.g. null models with no explanatory variables).\nThough you will hear many definitions, random effects are simply those specific to an observational unit, however defined. In our examples We will mostly encounter the case where the observational unit is the level of some grouping factor, but this is only one possibility.\nMixed effects - or simply mixed - models generally refer to a mixture of fixed and random effects. This is probably the most general term, with no specific data structure implied."
  },
  {
    "objectID": "materials/slides/w6.html#fitting-multilevel-models",
    "href": "materials/slides/w6.html#fitting-multilevel-models",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Fitting multilevel models",
    "text": "Fitting multilevel models\nIn R we can fit multilevel models using the lmer function from the lme4 package.\nInitially, it is advisable to first fit some simple, preliminary models, in part to establish a baseline for evaluating larger models. Then, we can build toward a final model for description and inference by attempting to add important covariates, centering certain variables, and checking model assumptions.\nThe standard first step is to model only the outcome measurement, without any predictors, to get a sense for the effect of the clusters; this is often called a random intercepts model or null model:\n\n\nmod_null &lt;- lmer(trustindex3 ~ 1 + (1 | cntry), data = osterman)\n\n\n\n\n\nThe second step is then to fit the full covariate model:\n\n\nmod_mixed = lmer(trustindex3 ~ eduyrs25 + agea + female + paredu_a_high + fmnoncntr + (1 | cntry), data = osterman)"
  },
  {
    "objectID": "materials/slides/w6.html#fitting-multilevel-models-1",
    "href": "materials/slides/w6.html#fitting-multilevel-models-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Fitting multilevel models",
    "text": "Fitting multilevel models\nResults: null model:\n\n\n\n\n\nObservations\n400\n\n\nDependent variable\ntrustindex3\n\n\nType\nMixed effects linear regression\n\n\n\n\n\n\nAIC\n1590.16\n\n\nBIC\n1602.13\n\n\nPseudo-R² (fixed effects)\n0.00\n\n\nPseudo-R² (total)\n0.09\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFixed Effects\n\n\n\n\nEst.\nS.E.\nt val.\nd.f.\np\n\n\n\n(Intercept)\n4.89\n0.21\n23.39\n7.00\n0.00\n\n\n\n p values calculated using Satterthwaite d.f.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Effects\n\n\n\nGroup\nParameter\nStd. Dev.\n\n\n\n\ncntry\n(Intercept)\n0.54\n\n\nResidual\n\n1.72\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrouping Variables\n\n\n\nGroup\n# groups\nICC\n\n\n\ncntry\n8\n0.09\n\n\n\n\n\nThe intra-class correlation (ICC) tells us the percentage of variation in the outcome variable attributable to differences between countries."
  },
  {
    "objectID": "materials/slides/w6.html#fitting-multilevel-models-2",
    "href": "materials/slides/w6.html#fitting-multilevel-models-2",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Fitting multilevel models",
    "text": "Fitting multilevel models\nResults: Covariate model:\n\n\n\n\n\nObservations\n376\n\n\nDependent variable\ntrustindex3\n\n\nType\nMixed effects linear regression\n\n\n\n\n\n\nAIC\n1500.20\n\n\nBIC\n1531.64\n\n\nPseudo-R² (fixed effects)\n0.08\n\n\nPseudo-R² (total)\n0.15\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFixed Effects\n\n\n\n\nEst.\nS.E.\nt val.\nd.f.\np\n\n\n\n\n(Intercept)\n2.52\n0.62\n4.03\n184.00\n0.00\n\n\neduyrs25\n0.10\n0.02\n3.86\n364.33\n0.00\n\n\nagea\n0.02\n0.01\n2.81\n324.25\n0.01\n\n\nfemale\n-0.14\n0.18\n-0.77\n368.19\n0.44\n\n\nparedu_a_high\n0.23\n0.21\n1.09\n369.34\n0.28\n\n\nfmnoncntr\n-0.81\n0.44\n-1.85\n368.30\n0.06\n\n\n\n\n p values calculated using Satterthwaite d.f.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Effects\n\n\n\nGroup\nParameter\nStd. Dev.\n\n\n\n\ncntry\n(Intercept)\n0.49\n\n\nResidual\n\n1.69\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGrouping Variables\n\n\n\nGroup\n# groups\nICC\n\n\n\ncntry\n8\n0.08"
  },
  {
    "objectID": "materials/slides/w0.html#video",
    "href": "materials/slides/w0.html#video",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Video",
    "text": "Video"
  },
  {
    "objectID": "materials/slides-frame/index.html",
    "href": "materials/slides-frame/index.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n \n\n\n \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materials/notes/notes_w06.html",
    "href": "materials/notes/notes_w06.html",
    "title": "Week 6 Worksheet Notes",
    "section": "",
    "text": "By the end of the session you will learn how to:\n\nuse survey weights in single-level linear regression models\nestimate variance in hierarchical/clustered data using robust standard errors in a single-level modelling framework\nfit random intercept models to hierarchical/clustered data",
    "crumbs": [
      "Materials",
      "Week 6",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w06.html#aims",
    "href": "materials/notes/notes_w06.html#aims",
    "title": "Week 6 Worksheet Notes",
    "section": "",
    "text": "By the end of the session you will learn how to:\n\nuse survey weights in single-level linear regression models\nestimate variance in hierarchical/clustered data using robust standard errors in a single-level modelling framework\nfit random intercept models to hierarchical/clustered data",
    "crumbs": [
      "Materials",
      "Week 6",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w06.html#r-packages",
    "href": "materials/notes/notes_w06.html#r-packages",
    "title": "Week 6 Worksheet Notes",
    "section": "R packages",
    "text": "R packages\n\n# Just in case we get errors asking that the package repositories be explicitly set when installing new packages:\n\noptions(repos = list(CRAN = \"http://cran.rstudio.com/\"))\n\n# Install and load required packages\n\n# We can use the {pacman} package to easily install and load several packages:\n# ({pacman} itself may need installing if not yet installed)\n\npacman::p_load(\n  tidyverse, easystats, sjlabelled,\n  ggformula, ggeffects, marginaleffects, \n  modelsummary, gtsummary,\n  survey, sandwich, lmtest, lme4)            # new modelling packages",
    "crumbs": [
      "Materials",
      "Week 6",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w06.html#example-1.-osterman2021canwetrusteducationfostering",
    "href": "materials/notes/notes_w06.html#example-1.-osterman2021canwetrusteducationfostering",
    "title": "Week 6 Worksheet Notes",
    "section": "Example 1. Österman (2021)",
    "text": "Example 1. Österman (2021)\nIn Worksheet 4 we fitted versions of Models 1-3 reported in Table 3 of Österman (2021) (see also Table A.3. in their Appendix for a more complete reporting on the models).\nComparing the model we fitted to the one reported by the author, our results were very close, but not totally equivalent on several coefficients and standard errors. The main reasons for the divergence had to do with two aspects of the published model that we had disregarded: (1) we did not include survey weights to correct for sampling errors, and (2) we did not allow for intra-group correlation in the standard errors among respondents from the same country (and the same age cohort). We will first implement these two additional steps and compare our final results again to those reported in Österman (2021). Then, we will refit the model in a multilevel/hierarchical framework.\n\nData preparation\nAs a first step, let’s import the osterman dataset that underpins the Österman (2021) article (see the Data page on the course website for information about the datasets available in this course). We can download the data to a local folder and load it from there, or we can load it directly from the web (if it works…):\n\n# Import the data\nosterman &lt;- data_read(\"https://cgmoreh.github.io/HSS8005-24/data/osterman.dta\")\n\nIt’s always a good idea to inspect the dataset after importing, to identify any issues. One option is to check a codebook, for example:\n\n# `View` the codebook:\ndata_codebook(osterman) |&gt; View()\n\nRemember that some “tagged” NA values that were imported from the Stata data format need changing (see Week 2 worksheet):\n\nosterman &lt;- sjlabelled::zap_na_tags(osterman)\n\n\n\nModels 1 and 2\nIn Worksheet 4 we have already fit Models 1 and 2 and got results very similar - but not identical - to those reported in the published article. Here, let’s first refit these models:\n\nosterman_m1 &lt;- lm(trustindex3 ~ reform1_7 + female + blgetmg_d +                        \n                 fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) +       \n                 agea + yrbrn + I(agea^2) + I(yrbrn^2) +                                \n                 factor(reform_id_num) +                                                \n                 yrbrn:factor(reform_id_num) +                                          \n                 agea:factor(reform_id_num) +  I(agea^2):factor(reform_id_num),         \n              data = osterman)                                                         \n\n\n\nosterman_m2 &lt;- lm(trustindex3 ~ reform1_7 + paredu_a_high + reform1_7*paredu_a_high + female + blgetmg_d + \n                 fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) +       \n                 agea + yrbrn + I(agea^2) + I(yrbrn^2) +                                \n                 factor(reform_id_num) +                                                \n                 yrbrn:factor(reform_id_num) +                                          \n                 agea:factor(reform_id_num) +  I(agea^2):factor(reform_id_num),         \n              data = osterman)                                                          \n\n\n\nProblem 1: Survey weights\nOne of the differences between our coefficients and the ones in the published table is due to the fact that we did not account for survey weights, while in Österman (2021), p. 220:\n\nThe data are weighted using ESS design weights\n\nTo understand in more detail what this means, we need some understanding of how weights are constructed in the European Social Survey (ESS). In a nutshell, ESS data are distributed containing 3 types of weights:\n\ndweight: These are the so-called design weights. Quoting the ESS website: “the main purpose of the design weights is to correct for the fact that in some countries respondents have different probabilities to be part of the sample due to the sampling design used.” These weights have been built to correct for the coverage error, that is, the error created by the different chances that individuals from the target population are covered in the sample frame.\npspwght: These are the post-stratification weights. According the the ESS website, these “are a more sophisticated weighting strategy that uses auxiliary information to reduce the sampling error and potential non-response bias.” These weights have been computed after the data has been collected, to correct from differences between population frequencies observed in the sample and the “true” population frequencies (i.e. those provided by the Labour Force Survey funded by the EU and available on Eurostat). Unlike the design weights, which are based on the probability of inclusion of different groups of individuals in the sample frames, these have been calculated starting from variables that are there in the data, and are really an “adjustment” of the design weight made to reach observed frequencies that match those of the target population.\npweight: These are the population size weights. These weights have the purpose to match the numbers of observations collected in each country to the country populations. They are to be used only when we calculate statistics on multiple countries (for instance, unemployment in Scandinavia). Their value is the same for all observations within the same country.\n\nThere is a lot to be said about survey weights and options for dealing with them, which we will not cover in more detail in this course. But as part of this exercise we will get to know some functions that can help with including survey weights and can be extended to include more complex design weights as well. Specifically, we will look at the {survey} package\nWe start by creating a weighted data object using the svydesign() function from {survey}, which includes the dweight as used in the original article:\n\n## Create weighted data\nosterman_w &lt;- svydesign(id = ~1,                 # specifying cluster IDs is needed; ~0 or ~1 means no clusters\n                        weights = ~dweight,      # we apply the design weights\n                        data = osterman)\n\nWe then fit the model using the svyglm() function from the {survey} package and save the model object; note that we specify a design = option with the weighted data object we created earlier:\n\nosterman_m1_w &lt;- svyglm(trustindex3 ~ reform1_7 + female + blgetmg_d +                        \n                   fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) +       \n                   agea + yrbrn + I(agea^2) + I(yrbrn^2) +                                \n                   factor(reform_id_num) +                                                \n                   yrbrn:factor(reform_id_num) +                                          \n                   agea:factor(reform_id_num) +  I(agea^2):factor(reform_id_num),\n                 design = osterman_w, data = osterman) \n\n\nosterman_m2_w &lt;- svyglm(trustindex3 ~ reform1_7 + paredu_a_high + reform1_7*paredu_a_high + female + blgetmg_d + \n                   fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) +       \n                   agea + yrbrn + I(agea^2) + I(yrbrn^2) +                                \n                   factor(reform_id_num) +                                                \n                   yrbrn:factor(reform_id_num) +                                          \n                   agea:factor(reform_id_num) +  I(agea^2):factor(reform_id_num),    \n                 design = osterman_w, data = osterman) \n\nTo compare the results from the weighted model to the one we produced earlier, we can check them in a modelsummary() table; we can reuse the list of coefficients to display that we created earlier:\n\n# List and name the models\nmodels &lt;- list(\n  \"Unweighted M1\" = osterman_m1,\n  \"Unweighted M2\" = osterman_m2,\n  \"Weighted M1\" = osterman_m1_w,\n  \"Weighted M2\" = osterman_m2_w)\n\n# Select and name coefficients to be tabulated\ncoefs &lt;- c(\"reform1_7\" = \"Reform\",\n           \"paredu_a_high\" = \"High parental edu\",\n           \"reform1_7:paredu_a_high\" = \"Ref x High par edu\",\n           \"femaleFemale\" = \"Female\",\n           \"blgetmg_d\" = \"Ethnic minority\",\n           \"fbrneur\" = \"Foreign-born father, Europe\",\n           \"mbrneur\" = \"Foreign-born mother, Europe\",\n           \"fnotbrneur\" = \"Foreign-born father, outside Europe\",\n           \"mnotbrneur\" = \"Foreign-born mother, outside Europe\")\n\n# Tabulate the models\nmodelsummary::modelsummary(models, stars = TRUE, coef_map = coefs)\n\nWarning in logLik.svyglm(x): svyglm not fitted by maximum likelihood.\n\nWarning in logLik.svyglm(x): svyglm not fitted by maximum likelihood.\n\n\n\n\n\n\nUnweighted M1\n Unweighted M2\nWeighted M1\n Weighted M2\n\n\n\n\nReform\n0.063*\n0.081**\n0.063*\n0.083**\n\n\n\n(0.027)\n(0.029)\n(0.029)\n(0.031)\n\n\nHigh parental edu\n\n0.349***\n\n0.340***\n\n\n\n\n(0.020)\n\n(0.021)\n\n\nRef x High par edu\n\n−0.049+\n\n−0.043\n\n\n\n\n(0.029)\n\n(0.029)\n\n\nEthnic minority\n−0.241***\n−0.207***\n−0.261***\n−0.226**\n\n\n\n(0.054)\n(0.056)\n(0.066)\n(0.069)\n\n\nForeign-born father, Europe\n−0.111**\n−0.106*\n−0.090*\n−0.084+\n\n\n\n(0.042)\n(0.044)\n(0.046)\n(0.047)\n\n\nForeign-born mother, Europe\n−0.108*\n−0.115*\n−0.092*\n−0.103*\n\n\n\n(0.044)\n(0.046)\n(0.046)\n(0.048)\n\n\nForeign-born father, outside Europe\n−0.065\n−0.047\n−0.053\n−0.040\n\n\n\n(0.073)\n(0.076)\n(0.079)\n(0.080)\n\n\nForeign-born mother, outside Europe\n−0.110\n−0.135+\n−0.087\n−0.103\n\n\n\n(0.078)\n(0.081)\n(0.082)\n(0.083)\n\n\nNum.Obs.\n68796\n64960\n68796\n64960\n\n\nR2\n0.200\n0.209\n0.206\n0.215\n\n\nR2 Adj.\n0.198\n0.208\n0.204\n0.214\n\n\nAIC\n268913.8\n252985.1\n\n\n\n\nBIC\n270056.1\n254138.4\n305027.4\n286775.7\n\n\nLog.Lik.\n−134331.877\n−126365.537\n−151817.519\n−142684.156\n\n\nRMSE\n1.71\n1.69\n1.71\n1.69\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\n\nWe can check our results again to those published in Table 3 and Table A.3 in the Appendix to Österman (2021), and we will see that all the coefficients are now the same, with some minor divergences still in the standard errors, which are due to the fact that we did not use cluster robust standard errors to account for intra-group correlations within countries.\n\n\nProblem 2: Variance estimation using robust clustered errors\nÖsterman (2021:222) write that:\n\nAll models are estimated with OLS, … and apply country-by-birth year clustered robust standard errors. [Footnote: An alternative would be to cluster the standard errors on the country level but such an approach would risk to lead to biased standard errors because of too few clusters]\n\nWhen estimating observations that are structured within groups/clusters (e.g. individual respondents within countries; students within schools/classes; test results or pertaining to the same pupil over time), one of the central assumptions of ordinary least squares regression (OLS) - that our variables are “independent and identically distributed” (iid)) - is breached. Ignoring this hierarchical structure of the data can lead to misleadingly precise coefficient estimates, with inaccurately low standard errors, too narrow confidence intervals, very low p-values and therefore possibly wrong conclusions. Applying a statistical correction for clustered standard errors is a common approach to dealing with this problem. It is a more elementary (but less flexible) way to account for breaches of the iid assumption than fitting a multilevel/hierarchical model.\nWe will first fit our model using clustered robust standard errors, as done by Österman (2021), then we will check the results against those we would obtain from a multilevel model design to see how the risk related to the low number of country clusters affects the results. For simplicity, we will look at Model 1.\nUnfortunately, while estimating clustered robust errors in simple linear (OLS) regression models with software such as Stata is very easy, the lm() command in R was not designed to accommodate this procedure, and as such we need to rely on additional packages and functions. The standard way of applying error corrections is by using the {sandwich} and {lmtest} packages, but they do not handle well the summary objects produced by the {survey} package for weighted estimates. Using the unweighed model we fitted earlier, we could do the following:\n\n# extract variance-covariance matrix with clustered correction\nvc_cl &lt;- sandwich::vcovCL(osterman_m1, type='HC1', cluster=~cntry_cohort)\n\n# get coefficients\nosterman_m1_cl &lt;- coeftest(osterman_m1, vc_cl)\n\n## Or, the two steps above can be combined into one call:\n\nosterman_m1_cl2 &lt;- coeftest(osterman_m1, \n                          vcov = vcovCL, \n                          type='HC1', \n                          cluster = ~cntry_cohort)\n\n# And we can check that the two have the same result:\nall.equal(osterman_m1_cl, osterman_m1_cl2)\n\n[1] TRUE\n\n\nLet’s tabulate the results for comparison:\n\n# List and name the models\nmodels &lt;- list(\n  \"Unweighted model\" = osterman_m1,\n  \"Weighted model\" = osterman_m1_w,\n  \"Unweighted model with cluster-robust errors\" = osterman_m1_cl)\n\n# Tabulate the models\nmodelsummary::modelsummary(models, stars = TRUE, coef_map = coefs)\n\nWarning in logLik.svyglm(x): svyglm not fitted by maximum likelihood.\n\n\n\n\n\n\nUnweighted model\nWeighted model\nUnweighted model with cluster-robust errors\n\n\n\n\nReform\n0.063*\n0.063*\n0.063*\n\n\n\n(0.027)\n(0.029)\n(0.029)\n\n\nEthnic minority\n−0.241***\n−0.261***\n−0.241***\n\n\n\n(0.054)\n(0.066)\n(0.060)\n\n\nForeign-born father, Europe\n−0.111**\n−0.090*\n−0.111*\n\n\n\n(0.042)\n(0.046)\n(0.046)\n\n\nForeign-born mother, Europe\n−0.108*\n−0.092*\n−0.108*\n\n\n\n(0.044)\n(0.046)\n(0.047)\n\n\nForeign-born father, outside Europe\n−0.065\n−0.053\n−0.065\n\n\n\n(0.073)\n(0.079)\n(0.077)\n\n\nForeign-born mother, outside Europe\n−0.110\n−0.087\n−0.110\n\n\n\n(0.078)\n(0.082)\n(0.086)\n\n\nNum.Obs.\n68796\n68796\n68796\n\n\nR2\n0.200\n0.206\n\n\n\nR2 Adj.\n0.198\n0.204\n\n\n\nAIC\n268913.8\n\n406007.8\n\n\nBIC\n270056.1\n305027.4\n1033594.4\n\n\nLog.Lik.\n−134331.877\n−151817.519\n\n\n\nRMSE\n1.71\n1.71\n\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\nThe error-correction does not have an impact on the coefficients, but it did affect the standard errors. Notice that the standard errors came closer to those in the weighted model without any error correction, showing that the weighting procedure already applies an error correction, albeit not specifically on the cluster variable cntry_cohort.\nOne deficiency of coeftest()/vcovCL() is that it doesn’t automatically correct for cases when the number of clusters is small. In our case, the number of cluster-cohorts is sufficiently large, so the estimates are good. If that were not the case - if we only had a handful of countries as clusters in the dataset, for example - then one option would be to manually specify the “degrees of freedom” within the coeftest() function, which is the number of the clusters minus 1 (e.g. with five clusters, the DF would be 4, and we would add an additional specification saying df = 4 within coeftest().\nAnother option is to use the feols() function from the {fixest} package, which fits OLS models that have many fixed effects (i.e. indicator variables representing clusters/categories of a cluster/grouping variable). The function uses the same formula syntax as lm(), but with the extension that allows to specify the variables representing the “fixed effects” (indicator variables for the cluster variable) after a | sign. Apart from the advantage that we can do all the estimations in one step - as opposed to how coeftest() works, requiring an lm() model object as an input first -, another advantage is that the output automatically hides the “fixed effects”, so we do not need to be troubled about potentially very long lists of coefficients that we are not directly interested in when running a model summary(). The function includes a vcov argument for specifying how you want to handle the standard errors, just like in the case of coeftest() earlier. There are also a number of options to choose from, which may be worth reading up about in the function documentation.\nAn easy way to include information on the clustering directly in the svydesign() function is to add cluster IDs:\n\n# Re-specify the survey design\nosterman_w_cl &lt;- svydesign(id = ~cntry_cohort,        # This time we add cntry_cohort as id\n                         weights = ~dweight, \n                         data = osterman)\n\n# Re-fit the model with the new survey design\nm1_w_cl &lt;- svyglm(trustindex3 ~ reform1_7 + female + blgetmg_d + \n               fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) + \n               agea + yrbrn + I(agea^2) + I(yrbrn^2) +\n               factor(reform_id_num) +           \n               yrbrn:factor(reform_id_num) + agea:factor(reform_id_num) +  \n               I(agea^2):factor(reform_id_num),\n           design = osterman_w_cl, data = osterman) \n\n# Tabulate the models\n\n# Add the latest model to the existing list using the append() function to save typing\nmodels &lt;- append(models, \n                 list(\"Weighted with cluster IDs\" = m1_w_cl)\n                 )\n\n# Tabulate the models\nmodelsummary::modelsummary(models, stars = TRUE, coef_map = coefs)\n\nWarning in logLik.svyglm(x): svyglm not fitted by maximum likelihood.\n\nWarning in logLik.svyglm(x): svyglm not fitted by maximum likelihood.\n\n\n\n\n\n\nUnweighted model\nWeighted model\nUnweighted model with cluster-robust errors\n Weighted with cluster IDs\n\n\n\n\nReform\n0.063*\n0.063*\n0.063*\n0.063*\n\n\n\n(0.027)\n(0.029)\n(0.029)\n(0.030)\n\n\nEthnic minority\n−0.241***\n−0.261***\n−0.241***\n−0.261***\n\n\n\n(0.054)\n(0.066)\n(0.060)\n(0.067)\n\n\nForeign-born father, Europe\n−0.111**\n−0.090*\n−0.111*\n−0.090+\n\n\n\n(0.042)\n(0.046)\n(0.046)\n(0.047)\n\n\nForeign-born mother, Europe\n−0.108*\n−0.092*\n−0.108*\n−0.092+\n\n\n\n(0.044)\n(0.046)\n(0.047)\n(0.047)\n\n\nForeign-born father, outside Europe\n−0.065\n−0.053\n−0.065\n−0.053\n\n\n\n(0.073)\n(0.079)\n(0.077)\n(0.078)\n\n\nForeign-born mother, outside Europe\n−0.110\n−0.087\n−0.110\n−0.087\n\n\n\n(0.078)\n(0.082)\n(0.086)\n(0.081)\n\n\nNum.Obs.\n68796\n68796\n68796\n68796\n\n\nR2\n0.200\n0.206\n\n0.206\n\n\nR2 Adj.\n0.198\n0.204\n\n−209.204\n\n\nAIC\n268913.8\n\n406007.8\n\n\n\nBIC\n270056.1\n305027.4\n1033594.4\n7093411.5\n\n\nLog.Lik.\n−134331.877\n−151817.519\n\n−3546009.588\n\n\nRMSE\n1.71\n1.71\n\n1.71\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\n\nThis final model takes us very close to the model reported in Österman (2021).",
    "crumbs": [
      "Materials",
      "Week 6",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w06.html#example-3.-osterman2021canwetrusteducationfostering-random-intercept-model",
    "href": "materials/notes/notes_w06.html#example-3.-osterman2021canwetrusteducationfostering-random-intercept-model",
    "title": "Week 6 Worksheet Notes",
    "section": "Example 3. Österman (2021): Random intercept model",
    "text": "Example 3. Österman (2021): Random intercept model\nThere is a vast literature assessing whether one approach is better suited than the other in different contexts. To get a feel for the issues in question and for a deeper understanding of how these methods are useful, compare the analysis of Cheah (2009), whose results “suggest that modeling the clustering of the data using a multilevel methods is a better approach than fixing the standard errors of the OLS estimate”, to that of McNeish, Stapleton, and Silverman (2017), who discuss a number of cases (focusing on psychology literature) where cluster-robust standard error may be more advantageous than multilevel/hierarchical modelling.\nÖsterman (2021:222) write that “An alternative [to the model above] would be to cluster the standard errors on the country level but such an approach would risk to lead to biased standard errors because of too few clusters”. The number of clusters is an important consideration when choosing to go for a multilevel model. For our aims, we will disregard this warning and go ahead and fit a multilevel model on the osterman data regardless, and we can think about what the differences in the results mean.\nWe can fit the model in a multilevel framework using the {lme4} package and the lmer() function.\nBelow we begin by looking at the distribution of the cntry variable that codes the countries where respondents are from. Since the European Social Survey is a cross-national survey, it employs a random sampling approach within each participant country and the resulting cross-national dataset is therefore clustered at the country level.\n\ndata_tabulate(osterman, cntry)\n\nCountry (cntry) &lt;character&gt;\n# total N=68796 valid N=68796\n\nValue |    N | Raw % | Valid % | Cumulative %\n------+------+-------+---------+-------------\nAT    | 2387 |  3.47 |    3.47 |         3.47\nBE    | 5220 |  7.59 |    7.59 |        11.06\nDE    | 3035 |  4.41 |    4.41 |        15.47\nDK    | 3979 |  5.78 |    5.78 |        21.25\nES    | 6062 |  8.81 |    8.81 |        30.06\nFI    | 2505 |  3.64 |    3.64 |        33.71\nFR    | 6942 | 10.09 |   10.09 |        43.80\nGB    | 5494 |  7.99 |    7.99 |        51.78\nGR    | 2065 |  3.00 |    3.00 |        54.78\nHU    | 3101 |  4.51 |    4.51 |        59.29\nIE    | 6086 |  8.85 |    8.85 |        68.14\nIT    | 1502 |  2.18 |    2.18 |        70.32\nNL    | 6063 |  8.81 |    8.81 |        79.13\nPL    | 5372 |  7.81 |    7.81 |        86.94\nPT    | 5987 |  8.70 |    8.70 |        95.65\nSE    | 2996 |  4.35 |    4.35 |       100.00\n&lt;NA&gt;  |    0 |  0.00 |    &lt;NA&gt; |         &lt;NA&gt;\n\n\nThere are 16 countries in the data.\nInitially, it is advisable to first fit some simple, preliminary models, in part to establish a baseline for evaluating larger models. Since in the multilevel framework we are interested in understanding the effect that the clusters have in the data, the simplest model we can fit is a so-called random intercepts model or null model, which models the outcome without any predictors. In the single-level framework, this is equivalent to estimating the overall mean of the outcome variable; in the hierarchical framework, we are modelling the mean of the outcome within each category/cluster of the grouping variable. With lmer() this means a simple addition of a specification of the form (1 | cluster) to the model code we are already familiar with, where cluster is the name of the clustering variable, in our case cntry:\n\nmod_null &lt;- lmer(trustindex3 ~ 1 + (1 | cntry), data = osterman)\n\nThe result is the following:\n\nmodel_parameters(mod_null)\n\n# Fixed Effects\n\nParameter   | Coefficient |   SE |       95% CI | t(68793) |      p\n-------------------------------------------------------------------\n(Intercept) |        5.23 | 0.23 | [4.78, 5.69] |    22.47 | &lt; .001\n\n# Random Effects\n\nParameter             | Coefficient\n-----------------------------------\nSD (Intercept: cntry) |        0.93\nSD (Residual)         |        1.71\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation. Uncertainty intervals for\n  random effect variances computed using a Wald z-distribution\n  approximation.\n\nrandom_parameters(mod_null)\n\n# Random Effects\n\nWithin-Group Variance        2.94 (1.71)\nBetween-Group Variance\n  Random Intercept (cntry)   0.87 (0.93)\nN (groups per factor)\n  cntry                        16\nObservations                68796\n\n\nBelow we fit a random intercept model with cntry_cohort as the single grouping variable and disregarding survey weights:\n\n# Fit a random intercept model with `cntry_cohort` as the grouping variable\nm2 &lt;- lmer(trustindex3 ~ reform1_7 + female + blgetmg_d + \n               fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) + \n               agea + yrbrn + I(agea^2) + I(yrbrn^2) +\n               factor(reform_id_num) +           \n               yrbrn:factor(reform_id_num) + agea:factor(reform_id_num) +  \n               I(agea^2):factor(reform_id_num) +\n               (1|cntry_cohort),\n           data = osterman)\n\nWarning: Some predictor variables are on very different scales: consider\nrescaling\n\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00384146 (tol = 0.002, component 1)\n\n# Fit a random intercept model with only `cntry` as the grouping variable\nm2_cntry &lt;- lmer(trustindex3 ~ reform1_7 + female + blgetmg_d + \n               fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) + \n               agea + yrbrn + I(agea^2) + I(yrbrn^2) +\n               factor(reform_id_num) +           \n               yrbrn:factor(reform_id_num) + agea:factor(reform_id_num) +  \n               I(agea^2):factor(reform_id_num) +\n               (1|cntry),\n           data = osterman)\n\nWarning: Some predictor variables are on very different scales: consider\nrescaling\n\n# Add the latest models to the existing list using the append() function\nmodels &lt;- append(models, \n                 list(\"Random intercepts (cntry_cohort)\" = m2,\n                      \"Random intercepts (cntry)\" = m2_cntry)\n                 )\n\n# Tabulate and compare the models\nmodelsummary::modelsummary(models, stars = TRUE, coef_map = coefs)\n\nWarning in logLik.svyglm(x): svyglm not fitted by maximum likelihood.\n\n\nWarning in logLik.svyglm(x): svyglm not fitted by maximum likelihood.\n\n\n\n\n\n\nUnweighted model\nWeighted model\nUnweighted model with cluster-robust errors\n Weighted with cluster IDs\nRandom intercepts (cntry_cohort)\nRandom intercepts (cntry)\n\n\n\n\nReform\n0.063*\n0.063*\n0.063*\n0.063*\n0.064*\n0.063*\n\n\n\n(0.027)\n(0.029)\n(0.029)\n(0.030)\n(0.028)\n(0.027)\n\n\nEthnic minority\n−0.241***\n−0.261***\n−0.241***\n−0.261***\n−0.241***\n−0.241***\n\n\n\n(0.054)\n(0.066)\n(0.060)\n(0.067)\n(0.054)\n(0.054)\n\n\nForeign-born father, Europe\n−0.111**\n−0.090*\n−0.111*\n−0.090+\n−0.111**\n−0.111**\n\n\n\n(0.042)\n(0.046)\n(0.046)\n(0.047)\n(0.042)\n(0.042)\n\n\nForeign-born mother, Europe\n−0.108*\n−0.092*\n−0.108*\n−0.092+\n−0.108*\n−0.108*\n\n\n\n(0.044)\n(0.046)\n(0.047)\n(0.047)\n(0.044)\n(0.044)\n\n\nForeign-born father, outside Europe\n−0.065\n−0.053\n−0.065\n−0.053\n−0.064\n−0.065\n\n\n\n(0.073)\n(0.079)\n(0.077)\n(0.078)\n(0.073)\n(0.073)\n\n\nForeign-born mother, outside Europe\n−0.110\n−0.087\n−0.110\n−0.087\n−0.110\n−0.110\n\n\n\n(0.078)\n(0.082)\n(0.086)\n(0.081)\n(0.078)\n(0.078)\n\n\nNum.Obs.\n68796\n68796\n68796\n68796\n68796\n68796\n\n\nR2\n0.200\n0.206\n\n0.206\n\n\n\n\nR2 Adj.\n0.198\n0.204\n\n−209.204\n\n\n\n\nR2 Marg.\n\n\n\n\n0.199\n0.126\n\n\nR2 Cond.\n\n\n\n\n0.200\n0.494\n\n\nAIC\n268913.8\n\n406007.8\n\n269877.8\n269878.2\n\n\nBIC\n270056.1\n305027.4\n1033594.4\n7093411.5\n271029.3\n271029.7\n\n\nICC\n\n\n\n\n0.0\n0.4\n\n\nLog.Lik.\n−134331.877\n−151817.519\n\n−3546009.588\n\n\n\n\nRMSE\n1.71\n1.71\n\n1.71\n1.70\n1.71\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001",
    "crumbs": [
      "Materials",
      "Week 6",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w03.html",
    "href": "materials/notes/notes_w03.html",
    "title": "Week 3 Worksheet Notes",
    "section": "",
    "text": "This session introduces binary logistic regression models. These models are the simplest form of a broader class of models called generalised linear models, which are applicable when the outcome (“dependent”, “response”, “explained”, etc.) variable cannot be assumed to follow a Gaussian (i.e. “normal”) distribution, but it instead a bounded or discrete measurement (e.g. think of variables whose values cannot be negative - i.e. have a lower limit of 0 - or fall into discrete categories such as “yes”/“no”, “disagree”/“neither agree nor disagree”/“agree”, or “blue”/“green”/“black”/“brown”/“other”). Binary logistic regression is the simplest case, where the outcome can take only two values (therefore “binary”). However, the logic that underpins it is similar to that of other generalised linear models.\nBy the end of the session you will learn how to:\n\nFit and summarise logistic regression models in R\nInterpret results from logistic regression models\nManipulate the regression output to ease interpretation\nPlot and visualise results from logistic regression models to aid interpretation",
    "crumbs": [
      "Materials",
      "Week 3",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w03.html#aims",
    "href": "materials/notes/notes_w03.html#aims",
    "title": "Week 3 Worksheet Notes",
    "section": "",
    "text": "This session introduces binary logistic regression models. These models are the simplest form of a broader class of models called generalised linear models, which are applicable when the outcome (“dependent”, “response”, “explained”, etc.) variable cannot be assumed to follow a Gaussian (i.e. “normal”) distribution, but it instead a bounded or discrete measurement (e.g. think of variables whose values cannot be negative - i.e. have a lower limit of 0 - or fall into discrete categories such as “yes”/“no”, “disagree”/“neither agree nor disagree”/“agree”, or “blue”/“green”/“black”/“brown”/“other”). Binary logistic regression is the simplest case, where the outcome can take only two values (therefore “binary”). However, the logic that underpins it is similar to that of other generalised linear models.\nBy the end of the session you will learn how to:\n\nFit and summarise logistic regression models in R\nInterpret results from logistic regression models\nManipulate the regression output to ease interpretation\nPlot and visualise results from logistic regression models to aid interpretation",
    "crumbs": [
      "Materials",
      "Week 3",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w03.html#r-packages",
    "href": "materials/notes/notes_w03.html#r-packages",
    "title": "Week 3 Worksheet Notes",
    "section": "R packages",
    "text": "R packages\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(gtsummary)\nlibrary(ggformula)\nlibrary(sjlabelled)\nlibrary(ggeffects)\nlibrary(marginaleffects)",
    "crumbs": [
      "Materials",
      "Week 3",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w03.html#introduction",
    "href": "materials/notes/notes_w03.html#introduction",
    "title": "Week 3 Worksheet Notes",
    "section": "Introduction",
    "text": "Introduction\nTo introduce logistic regression, we replicate part of the results presented in Wu (2021), specifically a simpler version of their Model 1 in Appendix A. Table 2, with only individual-level variables and pooled data that disregards the hierarchical nature of the dataset. The main problem addressed by Wu (2021) is the relationship between education and social trust at a global level, and for this they partially use data from Waves 5 and 6 of the World Values Survey.\nThe WVS measures social trust with a binary question:\n\n\n\n\n\n\nGenerally speaking, would you say that most people can be trusted or that you need to be very careful in dealing with people?:\n1 = Most people can be trusted\n2 = Need to be very careful\n\n\n\nThis variable will serve as the outcome variable.\nPrevious research had generally concluded that “there is a strong and positive relation between education level and trust” (Wu 2021:1167). However,\n\n“several studies have shown that education might yield differential impacts on trust in different societies. In Sweden, Sven Oskarsson et al. (2017) show that education has little impact on trust. In China, Cary Wu and Zhilei Shi (2020) suggest that education has a negative impact on people’s trust. Several cross-national studies have also shown that the education and trust association can vary from positive to negative depending on the specific institutional contexts … For example, the effect of education is found to be negative in highly corrupt countries such as Serbia, Turkey, Hungary, Slovakia, Bulgaria, Croatia, Kosovo, and Ukraine” (p. 1167).\n\nWu (2021) investigates how individual-level (micro) factors (such as education level and risk-taking propensity) may have different effects on trust depending on country-level (macro) factors (such as sociopolitical risk). We will focus on the individual (micro) level in this exercise, using measurements of education level and risk-taking propensity as our main explanatory variables. Following Wu (2021:1172), we will also control for a number of demographic variables at the individual level (“gender, age, income, marital status, and occupational status”).",
    "crumbs": [
      "Materials",
      "Week 3",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w03.html#data",
    "href": "materials/notes/notes_w03.html#data",
    "title": "Week 3 Worksheet Notes",
    "section": "Data",
    "text": "Data\nThe data required for this analysis can be downloaded freely from the World Values Survey website. We download Wave 5 (2005-2009) and Wave 6 (2010-2014) data. These are the only waves that measured risk-taking propensity using Schwartz’s value item,\n\n“where respondents were asked to report their similarity to a hypothetical individual: “Adventure and taking risks are important to this person; to have an exciting life.” Respondents rated the statement using a 6-point scale (1 = very much like me, 6 = not at all like me)” (Wu 2021:1172).\n\nThe latest wave of the WVS does not include this variable. Wu (2021) describe the other variables they use\n\nFor the WVS, I measure educational attainment using respondents’ highest education level attained with eight categories, namely, 1 = no formal education or inadequately completed elementary education, 2 = completed (compulsory) elementary education, 3 = incomplete secondary school: technical/vocational, 4 = complete secondary school: technical/vocational, 5 = incomplete secondary: university, 6 = complete secondary: university, 7 = some university without degree, and 8 = university with degree/higher education.\n\n\nIn some analyses, I treat education as a categorical variable. To reduce the number of categories, I recode respondents’ education into Primary, Secondary, Post-secondary, and Tertiary. This is also consistent with the most recent wave of the WVS coding (p. 1171)\n\n\nI also control for relevant demographic covariates such as gender, age, income, marital status, and occupational status at the individual level (p. 1172)\n\nWe can also find the questionnaires and the codebooks on the survey website, which will help identify the relevant variables.\nThe code below imports and selects the data from the original WVS dataset and creates a data-frame called wvs56 that contains all the variables needed:\n\n## Paths to files --------------------------------------------------------------------------------------------------------------\n\n### Data was downloaded in SPSS (.sav) format from the WVS website (https://www.worldvaluessurvey.org/WVSContents.jsp)\n### Downloaded data files were extracted and saved in the folder \"raw\" within the folder \"data\"\n### Create paths to the data files are created from the RProject root folder; cross-check the created path string variable:\n\nwvs5_path &lt;- here::here(\"data\", \"raw\", \"WV5_Data_Spss_v20180912.sav\")\nwvs6_path &lt;- here::here(\"data\", \"raw\", \"WV6_Data_sav_v20201117.sav\")\n\n\n## Select variables ------------------------------------------------------------------------------------------------------------\n\n### Create a vector storing names for the variables that will be used, based on Wu (2021: 1170-1172):\n\nwu_vars &lt;- c(\"country\", \"year\", \"trust\", \"risktaker\", \"education\", \"sex\", \"age\", \"income\", \"marstat\", \"employment\")\n\n### Create vectors storing the original names of the relevant variables in the WVS5 and WVS6 datasets:\n\nwvs5_vars &lt;- c(\"V2\", \"V260\", \"V23\", \"V86\", \"V238\", \"V235\", \"V237\", \"V253\", \"V55\", \"V241\")\nwvs6_vars &lt;- c(\"V2\", \"V262\", \"V24\", \"V76\", \"V248\", \"V240\", \"V242\", \"V239\", \"V57\", \"V229\")\n\n\n## Read in the data files -----------------------------------------------------------------------------------------------------\n\nwvs5 &lt;- read_spss(wvs5_path) |&gt; \n  data_select(select = c(wvs5_vars)) \n\nwvs6 &lt;- read_spss(wvs6_path) |&gt; \n  data_select(select = c(wvs6_vars))\n\n\n## Read in the data files -----------------------------------------------------------------------------------------------------\n\n### Create codebooks to check variables\n### Comparing the codebooks we see that the coding of all the variables is similar\n### WVS6 has shorter value labels on some variables\n\nwvs5_codebook &lt;- wvs5 |&gt; \n  data_codebook()\n\nwvs6_codebook &lt;- wvs6 |&gt; \n  data_codebook() \n\n \n## Rename variables -----------------------------------------------------------------------------------------------------------\n\n### It's safe to replace the original var names with more human-readable names; we use `datawizard::data_rename()`\n### Replace the value codes of `country` and `year` with the labels; will make merging datasets less error-prone\n\nwvs5 &lt;- wvs5 |&gt; \n  data_rename(c(wvs5_vars), c(wu_vars)) |&gt; \n  labels_to_levels(c(\"country\", \"year\"))\n\nwvs6 &lt;- wvs6 |&gt; \n  data_rename(c(wvs6_vars), c(wu_vars)) |&gt; \n  labels_to_levels(c(\"country\", \"year\"))\n\n## Merge data files -----------------------------------------------------------------------------------------------------------\n\n### Now variable names are the same in both datasets, the two can be joined\n### `datawizard::data_merge(..., join = \"bind\")` is similar to `dplyr::bind_rows()` but also copies value labels from the first-mentioned dataset\n### We mention the `wvs6` dataset first to keep its (shorter) version of value labels\n\nwvs56 &lt;- data_merge(wvs6, wvs5, join = \"bind\")\n\n## Create new `country_year` variable -----------------------------------------------------------------------------------------\n\nwvs56 &lt;- data_unite(wvs56, new_column = \"country_year\", c(\"country\", \"year\"), append = TRUE)",
    "crumbs": [
      "Materials",
      "Week 3",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w03.html#recoding-variables",
    "href": "materials/notes/notes_w03.html#recoding-variables",
    "title": "Week 3 Worksheet Notes",
    "section": "Recoding variables",
    "text": "Recoding variables\nThere are a few final alterations that need to be made to the variables:\n\ntrust will serve as our response (dependent) variable - the one we want to explain/model. We can see from the codebook that it has two valid categories (“1” and “2”), referring to “Most people can be trusted” and “Need to be very careful”, respectively. Given that it is a binary (dichotomous) variable, we will use binary logistic regression to model it. When we enter a variable into a logistic regression model as dependent variable in R, the first category/level will be automatically recoded internally to the value “0” and be used as the reference category; the latter category/level will be recoded to “1”, and it will be the indicator category that the model predicts in contrast to the reference category. In our case, that will mean that the category referring to “Need to be very careful” will be treated as the indicator variable by default, so effectively the coefficients of the explanatory (predictor, independent) variables will be estimating the propensity towards “distrust”. If we first reversed the order of the categories in the dependent variable, the output would be estimating “trust”, which is conceptually cleaner and more straightforward to interpret;\nFollowing Wu (2021), we can treat our main explanatory variable - education (Highest educational level attained) - as numeric. But in the dataset it is coded as factor, so we will have to either change it to numeric in the dataset, or force it to be treated as numeric by R when fitting the model. Technically, education is categorical in nature, but given that the categories are ordinal in their substantive meaning (increasing from no/less education to more) and there are more than just a handful of levels/categories (there are 9), we can technically treat it as a short numeric scale, while keeping in mind that descriptive statistics such as the mean do not make much sense in this case;\nWu (2021) also noted that in some models (including in Model 1, Appendix A. Table 2) they use a recoded categorical version of the education, collapsed over 4 categories: “Primary”, “Secondary”, “Post-secondary”, and “Tertiary” education. We can also create this variable to potentially include it in our models.\n\nWe can make the required transformations in a single call to the {datawizard} function data_modify() like so:\n\nwvs56 &lt;- wvs56 |&gt;                                                                         # (1)\n  data_modify(trusting = recode_values(trust,\n                                       recode = list(\"0\" = 2)),                           # (2)\n              educ_num = as_numeric(education),                                           # (3)\n              educ_cat_1 = recode_values(education,                                       # (4)\n                                         recode = list(\"1\" = (\"1, 2, 3\"), \n                                                       \"2\" = (\"4, 5, 6, 7\"), \n                                                       \"3\" = (\"8\"),\n                                                       \"4\" = (\"9\"))),                     # (4.1)\n              educ_cat_2 = recode_values(education,                                       # (5)\n                                         recode = list(\"1\" = (\"1, 2\"),\n                                                       \"2\" = (\"3\"), \n                                                       \"3\" = (\"4, 5\"), \n                                                       \"4\" = (\"6, 7\"),\n                                                       \"5\" = (\"8\"),\n                                                       \"6\" = (\"9\")))\n              ) |&gt;                                                                        # (6)\n  set_labels(trusting, labels = c(\"Not trusting\", \"Trusting\")) |&gt;                         # (7)\n  set_labels(educ_cat_1, labels = c(\"Primary\", \n                                    \"Secondary\", \n                                    \"Post-secondary\", \n                                    \"Tertiary\")) |&gt; \n  set_labels(educ_cat_2, labels = c(\"Less than primary\", \n                                    \"Primary\", \n                                    \"Secondary-vocational\", \n                                    \"Secondary-preparatory\", \n                                    \"Post-secondary\", \n                                    \"Tertiary\"))\n  \n# Code explanation:\n# (1) overwrite the data object with the changes\n# (2) reverse the category order of \"trust\" and save it as a new variable called \"trusting\" to make the indicator meaning clearer\n# (3) change the type of variable \"education\" to numeric and save it as the new variable \"educ_num\"\n# (4) recode the \"education\" variable into 4 larger categories and save the new variable as \"educ_cat_1\"\n# (4.1) make sure to close all the brackets under `recode_values()`\n# (5) alternative recode of \"education\" into 6 categories as \"educ_cat_2\"\n# (6) remember to close the brackets under `data_modify()`\n# (7) add value labels\n\nOf course, we could do all the changes one-by-one, but because we can achieve everything we wanted using the data_modify() option, it’s easier to do it all at once. When you are experimenting with recoding, it is probably a good idea to do it one-by-one and check the results at each step to catch out any errors more easily.\nLet’s have a look at the recoded dataset; because we did not overwrite any of the original variables, we will have both the old and the newly recoded/renamed variable in the dataset:\n\nwvs56_codebook &lt;- data_codebook(wvs56)\n\n\nView(wvs56_codebook)\n\nThe newly created variables look like this:\n\n# Showing values:\ndata_tabulate(wvs56, trusting:educ_cat_2)\n\n# Showing value labels:\nwvs56 |&gt; data_select(trusting:educ_cat_2) |&gt; labels_to_levels() |&gt; data_tabulate()",
    "crumbs": [
      "Materials",
      "Week 3",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w03.html#describing-the-relationship-between-the-main-variables-of-interest",
    "href": "materials/notes/notes_w03.html#describing-the-relationship-between-the-main-variables-of-interest",
    "title": "Week 3 Worksheet Notes",
    "section": "Describing the relationship between the main variables of interest",
    "text": "Describing the relationship between the main variables of interest\nNow that the data has been recoded, we can have a closer look at the relationship between our two main variables: trusting and educ_num. Since the education variable is now recorded as numeric, we can make use of a boxplot for visualisation. In Week 2 we practiced building {ggplot2} plots incrementally, and the boxplot could be coded like this:\n\nggplot(wvs56) +\n  aes(trusting, educ_num) +\n  geom_boxplot()\n\nWe could also set the value labels as the values to plot, and we could remove the missing values:\n\nwvs56 |&gt; \n  labels_to_levels(trusting) |&gt; \n  remove_missing() |&gt; \n  ggplot() +\n    aes(trusting, educ_num) +\n    geom_boxplot()\n\nWhile ggplot2::ggplot() is flexible and useful for expanding the plots and adding various embellishments, the {ggformula} package simplifies its syntax by making it similar to the formula syntax used in common modelling functions (such as lm()). All the {ggformula} commands begin with gf_ followed by the type of the plot. The command for a boxplot would be as simple as:\n\ngf_boxplot(educ_num ~ trusting, data = wvs56)\n\nIt also complies with pipe workflows, like for example:\n\nwvs56 |&gt; \n  labels_to_levels(trusting) |&gt; \n  remove_missing() |&gt; \n  gf_boxplot(educ_num ~ trusting)\n\nLooking at the boxplots, we can see a slightly higher median education level among those in the “Trusting” category (those who responded that “Most people can be trusted” in the survey). For a more detailed numerical summary of this association, we can use another function from the {datawizard} package, means_by_group():\n\nwvs56 |&gt; means_by_group(\"educ_num\", \"trusting\")\n\nHere we can see more clearly the difference in average education levels between those with high trust levels and those with low trust levels. This table is equivalent to the results from a linear regression model in which the numeric variable educ_num is the dependent variable and trusting is the explanatory (independent) variable. We should keep in mind, however, that while our educ_num variable is treated as numeric, it is in fact an ordinal categorical variable, and a mean value of 5.88 over trusting cannot be interpreted meaningfully. If we are interested in only in differences, we can calculate the median educ_num - and any other statistics - over trusting manually:\n\nwvs56 |&gt; \n  labels_to_levels(trusting) |&gt; \n  remove_missing() |&gt; \n  data_group(trusting) |&gt; \n  summarize(mean_educ = mean(educ_num),\n            median_educ = median(educ_num))\n\nOut interest, however, is in modelling the trusting variable as a function of education, while also accounting for the other demographic covariates. For this, we turn to a logistic regression model.",
    "crumbs": [
      "Materials",
      "Week 3",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w03.html#simple-bivariate-logistic-regression-model",
    "href": "materials/notes/notes_w03.html#simple-bivariate-logistic-regression-model",
    "title": "Week 3 Worksheet Notes",
    "section": "Simple bivariate logistic regression model",
    "text": "Simple bivariate logistic regression model\nFitting a logistic regression model in R is fairly straightforward. We can use the base R glm() function and would write the following code:\n\nmodel_1 &lt;- glm(trusting ~ educ_num, family = binomial(link = \"logit\"), data = wvs56)\n\nIn the code above, instead of the linear model function (lm()) we used the generalised linear model function (glm()), and because glm() is a larger family of models, we need to also specify which “family” we are fitting; since our dependent variable is binary variable, we are calling the “binomial” family. We also need to specify a “link function” to be used, but the “logit” is the default link for the binomial distribution family, so we could have ommitted it and simply written glm(..., family = binomial).\nIn all other aspects the formula is the same as the one we already know from linear regression.\nLet’s look at the model parameters:\n\nmodel_parameters(model_1)\n\nIt is at the stage of interpretation that logistic regression models become difficult. The coefficients that we obtain in the standard output are similar to those from a linear regression in that they summarise a linear and additive relationship between the independent and dependent variables. The difference is that the dependent variable has been transformed to a logit or logged odds scale. We could say - following the logic of linear regression - that each unit difference in one’s education level is associated with a 0.18-point positive difference in the logged odds/logit value of trusting. But this doesn’t make much sense, because the logit scale is difficult to comprehend.\nIt would be more intuitive to see the results on a different scale. A simple and commonly used transformation is from log-odds to odds ratios. If we exponentiate the logistic regression log-odds coefficients, we could say that the independent variables relate to the odds of the dependent variable, rather than the logged odds, which is somewhat easier to relate to. The model_parameters() function can do that for us in exchange of some additional specification:\n\nmodel_parameters(model_1, exponentiate = TRUE)\n\nThe odds ratios that we find in this table are somewhat easier to interpret, but we need to understand how odds work. By having exponentiated the coefficients, we have moved from an additive scale to a multiplicative scale. Basically, what this means is that while on an additive scale the value “0” means no change (because by adding 0 to a number we do not alter that number), on a multiplicative scale that role is taken over by “1” (when we multiply a number by “1”, we keep it as it is). Consequently, a coefficient of “1” on the exponentiated scale means no difference, while values between 0 and 1 represent a negative difference and values greater than 1 a positive difference.\nI our case, the OR of 1.10 means that a difference of one degree in education level is associated with a positive difference of 1.10 in the odds of being a trusting person. We could further translate this into a percentage: if we subtract 1 from the exponentiated coefficient and multiply it by 100, we get the percentage difference due to a unit change in the independent variable.\n\\[\n\\% \\Delta _{odds} = 100\\times(OR-1)\n\\]\nFor values grater than 1 this calculation is straightforward. In our case, this translates to a 10% increase in the odds of being a trusting person.\nIt doesn’t add much to our understanding to plot the regression results from a model with a single predictor, but knowing how to plot results will be particularly useful once we expand the model with further explanatory variables. To create a plot of the results, we can simply take the output from the model_parameters() function and pass it on to the plot() function included in {easystats}:\n\nparameters(model_1, exponentiate = TRUE) |&gt; plot()\n\nHowever, the fact that the exponentiated coefficients are measured on a multiplicative scale poses some difficulties and it makes it easy to fall into the trap of interpreting these odds as probabilities.\nThe issue is that odds can range from 0 to infinity, so the scale is far from standard. Probabilities, on the other hand, have the nice feature of being constrained between 0 and 1, so a percentage change has much more meaning.\nThere are several packages that help us compute various comparative statistics on the probability scale from logistic models.\nBelow, we will use the avg_slopes() function from the {marginaleffects} package to compute the average difference in the probability of being trusting based on a one-unit difference in education level:\n\navg_slopes(model_1)\n\nThe result indicates the change in the predicted probability that the outcome (trusting) equals 1. On average, a unit-change in educ_num changes the predicted probability that the outcome equals 1 by 1.8%.\nThis “average marginal” effect represents the average slope of the predictor, and as such it can be considered as an “adjusted regression coefficient”. However, because the effect is no longer fixed across the values of the predictor variable, it is still less intuitive to talk about an “average” effect in the case of logistic regression.\nTo make these numerical results easier to visualise, we can plot the result.There are several options, but probably the most straightforward approach is to estimate the probabilities of being trusting at each level of the predictor variable (educ_num), then plot the results. The plot_predictions() function from the {marginaleffects} package or the plot() function of {ggeffects} can be used here. Below, we’ll use the latter:\n\nggpredict(model_1, \"educ_num\") |&gt; \n  plot()\n\nThis code first calculates predictions of the outcome probability for each level of the explanatory variable using the ggpredict() function (we could save these results as a data-frame), then passes those results on to the plot() function. To remove the overlapping value labels on the horizontal axis, we could add something like the following to the command:\n\nggpredict(model_1, \"educ_num\") |&gt; \n  plot() +\n    scale_x_continuous()\n\nThis graph makes it a lot clearer how education is associated with trust in our model, and if education is our main variable of interest, we can plot its effect even from a larger model that contains other covariates.",
    "crumbs": [
      "Materials",
      "Week 3",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w03.html#expanding-the-logistic-regression-model",
    "href": "materials/notes/notes_w03.html#expanding-the-logistic-regression-model",
    "title": "Week 3 Worksheet Notes",
    "section": "Expanding the logistic regression model",
    "text": "Expanding the logistic regression model\nThis step does not contain anything new compared to what we already know from multiple linear regression and what we have learnt in the previous step about the logistic regression model.\nWe can add the other relevant variables using the + sign, and we can change the variable measuring “education” for the categorical version. We also specify risktaker and income as numeric variables:\n\nmodel_2 &lt;- glm(trusting ~ as.numeric(risktaker) + educ_cat_1 + sex + age + as.numeric(income) + marstat + employment, family = binomial, data = wvs56)\n\nTabulate the model parameters; to make the calculation of the confidence intervals faster, we can add ci_method=\"wald\" to the command:\n\nmodel_parameters(model_2, exponentiate = TRUE, ci_method = \"wald\")\n\nPlot the model parameters on the log-odds scale:\n\nmodel_parameters(model_2, ci_method = \"wald\") |&gt; plot()\n\nThe plotted results are much more informative in the case of the multiple regression model. We find that higher education, being a female, higher age and higher income brackets all have a positive association with trust, while being other than married and in non-full-time employment show a negative association with trust.\nWe can plot the exponentiated coefficients to interpret odds instead:\n\nmodel_parameters(model_2, exponentiate = TRUE,  ci_method = \"wald\") |&gt; plot()\n\nPlot predicted probabilities of trusting based on education, adjusted for the effect of the other covariates in the model:\n\nggpredict(model_2, c(\"educ_cat_1\")) |&gt; \n  plot() +\n    scale_x_continuous()\n\nGiven the multiple explanatory variables included in the model, we can further break down the effects. For example, we can plot the effect of education on trust by sex within each marital status.\n\nggpredict(model_2, c(\"educ_cat_1\", \"sex\", \"marstat\")) |&gt; \n  plot() +\n    scale_x_continuous()\n\nIt looks like the effect of education on trust is stronger among those married, or single or cohabitating than among the separated or widowed, for both men and women.\nThis is a rather complex finding, and we can explore this model in much more depth, as well as thinking about developing it or specifying it further.",
    "crumbs": [
      "Materials",
      "Week 3",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/index.html",
    "href": "materials/notes/index.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\nReading Time\n\n\n\n\n\n\nWeek 2 Worksheet Notes\n\n\n \n\n\n7 min\n\n\n\n\nBiases\n\n\n?var:topic-abstract.w5\n\n\n1 min\n\n\n\n\nStudy design\n\n\n?var:topic-abstract.w8\n\n\n1 min\n\n\n\n\nWeek 1 Worksheet Notes\n\n\n \n\n\n30 min\n\n\n\n\nWeek 3 Worksheet Notes\n\n\n \n\n\n25 min\n\n\n\n\nWeek 4 Worksheet Notes\n\n\n \n\n\n39 min\n\n\n\n\nWeek 6 Worksheet Notes\n\n\n \n\n\n23 min\n\n\n\n\nWeek 7 Worksheet Notes\n\n\n \n\n\n11 min\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materials/info/info_w08.html",
    "href": "materials/info/info_w08.html",
    "title": "Week 8  Study design",
    "section": "",
    "text": "We have known ever since science-fiction author Philip K. Dick’s memorable “Metz address” of 1977 that our world is a computer simulation. Of course, like some common-currency theories in the social sciences, this knowledge will never be truly verified. We won’t even attempt to get to the bottom of it in class; instead, we’ll practice some basic methods of computer simulation for statistical inference and for generating data that has some idealised characteristics. Such methods play an increasingly important role in computational statistics and are extremely useful for designing robust data collection and analysis plans. If you make a mistake in the code and end up in an infinite loop, but you’re afraid that stopping the process may cause the known universe to implode, you can watch Dick on YouTube while you wait. If something like this can happen to our data, who says it couldn’t happen to us?\n\nReadings\n\nROS: Chapters 5 (pp. 69-76) and 16 (pp. 291-310)\nTSD: TDS makes extensive use of simulation methods for various purposes at different stages of a research project (e.g. from data preparation through statistical inference to sharing results and data openly). A search on a keyword stub “simulat” can point you various sections of interest that are all worth reading.",
    "crumbs": [
      "Materials",
      "Week 8"
    ]
  },
  {
    "objectID": "materials/info/info_w06.html",
    "href": "materials/info/info_w06.html",
    "title": "Week 6  Hierarchies",
    "section": "",
    "text": "Hierarchical data are ubiquitous in the social and human sciences (and beyond). In fact, almost all the application articles we have engaged with so far in previous labs modelled hierarchical data., and almost all modelled them explicitly as such, applying some multilevel modelling technique. In some cases the hierarchies themselves were of central theoretical importance and played a crucial role in the stated estimand (i.e. “the object of inquiry—(…) the precise quantity about which we marshal data to draw an inference” (see Lundberg, Johnson, and Stewart 2021:532). In others, taking into account the hierarchical nature of the data was meant to improve the precision of the main effect estimates. The importance of accounting for hierarchical dependencies in our models is emphasised by no one else more than Richard McElreath, who, in his important introductory-level book to Bayesian statistics, wants “to convince the reader of something that appears unreasonable: multilevel regression deserves to be the default form of regression” (McElreath 2020:15). According to him, “papers that do not use multilevel models should have to justify not using a multilevel approach”. In this session, we will learn how to think about and fit hierarchical models in R, and we’ll discuss some of the challenges of multilevel modelling and the possible justifications not to use them in certain contexts.\n\nReadings\nTextbook\n\nARM: Chapters 11 (pp. 237-249) and 12 (pp. 251-278)\nTSD: Chapter section 15.2\n\nApplication\n\nÖsterman, Marcus. 2021. ‘Can We Trust Education for Fostering Trust? Quasi-Experimental Evidence on the Effect of Education and Tracking on Social Trust’. Social Indicators Research 154(1):211–33 - (online)\nMitchell, Jeffrey. 2021. “Social Trust and Anti-immigrant Attitudes in Europe: A Longitudinal Multi-Level Analysis.” Frontiers in Sociology 6 (April): 604884 - (online)\nAkaeda, Naoki. 2023. “Trust and the Educational Gap in the Demand for Redistribution: Evidence from the World Values Survey and the European Value Study.” International Sociology 38(3): 290–310 Library access\nWu, Cary. 2021. ‘Education and Social Trust in Global Perspective’. Sociological Perspectives 64(6):1166–86. Available here: Library access\nDingemans, Ellen, and Erik Van Ingen. 2015. ‘Does Religion Breed Trust? A Cross-National Study of the Effects of Religious Involvement, Religious Faith, and Religious Context on Social Trust’. Journal for the Scientific Study of Religion 54(4):739–55. Library access\n\n\n\nFurther readings\n\nARM: Chapters 13 (pp. 279-299), 14 (pp. 301-323) and 15 (pp. 325-342)\n\n\n\n\n\n\nReferences\n\nLundberg, Ian, Rebecca Johnson, and Brandon M. Stewart. 2021. “What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory.” American Sociological Review 86(3):532–65. doi: 10.1177/00031224211004187.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. Second. Boca Raton: Taylor and Francis, CRC Press.",
    "crumbs": [
      "Materials",
      "Week 6"
    ]
  },
  {
    "objectID": "materials/info/info_w04.html",
    "href": "materials/info/info_w04.html",
    "title": "Week 4  Interactions",
    "section": "",
    "text": "Description\nThis week we will return to some of the models we fit over the past two weeks and turn our attention to the right-hand side of the regression equations. We will explore interaction effects, which allow for the association between a predictor and an outcome to depend upon the value of another predictor. Understanding interaction effects - and the concept of conditioning more broadly - can help avoid serious misrepresentations and misunderstandings of our data. Some famous statistical “paradoxes” can highlight these dangers, and the lecture will build on these conceptual examples before moving on to questions of model-building. It is technically very simple to fit models with complex interactions, however, their interpretation can be very difficult. As with the logistic regression model we covered in Week 3, we will explore ways to present and visualise results from interaction models, which make their interpretation easier. Exploring interactions also allows us to begin thinking about causality and causal modelling, a topic that we will expand upon in Week 5.\n\n\nReadings\nStatistics\n\nROS: Chapters 10-12\n\nAdvanced statistics readings\n\nBrambor, T., W. R. Clark, and M. Golder. 2006. “Understanding Interaction Models: Improving Empirical Analyses.” Political Analysis 14(1): 63–82. https://doi.org/10.1093/pan/mpi014\nHainmueller, J., J. Mummolo, and Y. Q. Xu. 2019. “How Much Should We Trust Estimates from Multiplicative Interaction Models? Simple Tools to Improve Empirical Practice.” Political Analysis 27(2): 163–92 Library access here\nRohrer, Julia M., and Ruben C. Arslan. 2021. “Precise Answers to Vague Questions: Issues With Interactions.” Advances in Methods and Practices in Psychological Science 4(2): 25152459211007368 Library access here\n\nCoding\n\nTSD: Chapter 15\n\nApplication\n\nAkaeda, Naoki. 2023. “Trust and the Educational Gap in the Demand for Redistribution: Evidence from the World Values Survey and the European Value Study.” International Sociology 38(3): 290–310 Library access\nÖsterman, Marcus. 2021. ‘Can We Trust Education for Fostering Trust? Quasi-Experimental Evidence on the Effect of Education and Tracking on Social Trust’. Social Indicators Research 154(1):211–33 - (online)\nLadd, Jonathan McDonald, and Gabriel S. Lenz. 2009. ‘Exploiting a Rare Communication Shift to Document the Persuasive Power of the News Media’. American Journal of Political Science 53(2):394–410. doi: 10.1111/j.1540-5907.2009.00377.x.(published version should be accessible with university login; additional Appendix available here)",
    "crumbs": [
      "Materials",
      "Week 4"
    ]
  },
  {
    "objectID": "materials/info/info_w02.html",
    "href": "materials/info/info_w02.html",
    "title": "Week 2  Escaping Flatland",
    "section": "",
    "text": "Description\nIn Edwin Abbott’s 1884 novella, the inhabitants of Flatland are geometric shapes living in a two-dimensional world, incapable of imagining the existence of higher dimensions. A sphere passing through the plain of their world is a fascinating but incomprehensible event: Flatlanders can only see a dot becoming a circle, increasing in circumference, then shrinking back in size and disappearing. There are, in this universe, worlds with even more limited views, like the one-dimensional Lineland and the zero-dimensional Pointland. Any attempt to expand the perspective of their inhabitant(s) is doomed to failure. But as in any good adventure story, a chosen Flatland native embarks on a journey of discovery and revelation - and ostracism and imprisonment. The story is interpreted as an allegorical criticism of Victorian-age social structure, but can equally describe the limitations of inhabiting uncritically a methodological world in which all data are ‘normal’ and all relationships are linear. Moving beyond linearity and acquiring the statistical intuition needed to think in higher dimensions and perceive more complex relationships is indeed a matter of practice-induced revelation. It’s unlikely that we will reach statistical nirvana in this short course, but we’ll attempt to build some more substantial structures upon the arid plains of linear regression. We start by looking around in the Flat-, Line- and Point-lands of quantitative analysis. Incorrigible procrastinators may want to check out a full-length computer animated film version of Flatland on YouTube. Others may be better served by this brief TED-Ed animation.\n\n\nReadings\nStatistics\n\nROS: Chapters 3, 4, 6-12\nTSD: Chapter 12 (“Linear models”)\n\nCoding\n\nTSD: Chapters 9 and 11\nR4DS: Chapters 11, 12\n\nApplication\n\nChapter 4 in Wilkinson, Richard G., and Kate Pickett. 2010. The Spirit Level: Why Greater Equality Makes Societies Stronger. New York: Bloomsbury Press.\nÖsterman, Marcus. 2021. ‘Can We Trust Education for Fostering Trust? Quasi-Experimental Evidence on the Effect of Education and Tracking on Social Trust’. Social Indicators Research 154(1):211–33 - (online)\nMitchell, Jeffrey. 2021. “Social Trust and Anti-immigrant Attitudes in Europe: A Longitudinal Multi-Level Analysis.” Frontiers in Sociology 6 (April): 604884 - (online)",
    "crumbs": [
      "Materials",
      "Week 2"
    ]
  },
  {
    "objectID": "materials/handouts/index.html",
    "href": "materials/handouts/index.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "Title\n\n\nDescription\n\n\nReading Time\n\n\n\n\n\n\nWeek 1 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 2 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 3 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 4 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 5 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 6 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 7 handout\n\n\n \n\n\n1 min\n\n\n\n\nWeek 8 handout\n\n\n \n\n\n1 min\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "data/index.html",
    "href": "data/index.html",
    "title": "Data documentation",
    "section": "",
    "text": "File name\n\n\nType\n\n\nDescription\n\n\nLink to source\n\n\n\n\n\n\nevs2017\n\n\n.Rds\n\n\nEuropean Values Study; Wave 5 (2017-2021)\n\n\nSource\n\n\n\n\nwvs56\n\n\n.Rds\n\n\nWorlds Values Survey; combined Wave 5 and 6\n\n\nSource\n\n\n\n\nosterman\n\n\n.dta\n\n\nReplication data for Österman (2021), based on European Social Survey Rounds 1-9 data\n\n\nData source  Open access article  Supplementary materials\n\n\n\n\nLaddLenz\n\n\n.dta\n\n\nReplication data for Ladd and Lenz (2009), based on British Election Panel Study data. Included in Hainmueller (2012)\n\n\nSource\n\n\n\n\nEverydayTrust\n\n\n.Rds\n\n\nReplication data for Weiss et al. (2021)\n\n\nSource\n\n\n\n\nValentino17\n\n\n.dta\n\n\nReplication data for Valentino et al. (2019), based on original data collected through YouGov in 11 countries. The original dataset provided by the authors is called imm.bjpols.dta and the original analysis was performed in Stata.\n\n\nData source  Open access article  Supplementary materials\n\n\n\n\nEjrnaes21\n\n\n.dta\n\n\nReplication data for Ejrnæs and Jensen (2021), based on data from the European Social Survey Round 8. The original dataset provided by the authors is called G&O_Final.tab and the original analysis was performed in Stata.\n\n\nData source  Open access article  Supplementary materials\n\n\n\n\nworkout\n\n\n.Rds\n\n\nExample dataset from Mehmetoglu and Mittner (2021); a combined version of the original workout2 and workout3 datasets included in the {astatur} package\n\n\nData source\n\n\n\n\ngaltonpeas\n\n\n.Rds\n\n\nData underpinning a paper presented by Sir Francis Galton to the Royal Institute on February 9, 1877, summarising his experiments on sweet peas in which he compared the size of peas produced by parent plants to those produced by offspring plants.\n\n\nSource\n\n\n\n\ngalton1886\n\n\n.dta\n\n\nSir Francis Galton’s famous data on the heights or parents and their children underpinning his 1886 paper (Galton 1886).\n\n\nSource and more info\n\n\n\n\nberkeley\n\n\n.csv\n\n\nData underpinning the classic Sex Bias in Graduate Admissions: Data from Berkeley paper by Bickel, Hammel and O’Connell (1975).\n\n\nData source  Original article\n\n\n\n\n\n\n\n\n\n\nReferences\n\nEjrnæs, Anders, and Mads Dagnis Jensen. 2021. “Go Your Own Way: The Pathways to Exiting the European Union.” Government and Opposition, February, 1–23. https://doi.org/10.1017/gov.2020.37.\n\n\nGalton, Francis. 1886. “Regression Towards Mediocrity in Hereditary Stature.” The Journal of the Anthropological Institute of Great Britain and Ireland 15: 246–63. https://doi.org/10.2307/2841583.\n\n\nHainmueller, Jens. 2012. “Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies.” Political Analysis 20 (1): 25–46. https://doi.org/10.1093/pan/mpr025.\n\n\nLadd, Jonathan McDonald, and Gabriel S. Lenz. 2009. “Exploiting a Rare Communication Shift to Document the Persuasive Power of the News Media.” American Journal of Political Science 53 (2): 394–410. https://doi.org/10.1111/j.1540-5907.2009.00377.x.\n\n\nMehmetoglu, Mehmet, and Matthias Mittner. 2021. Applied Statistics Using R: A Guide for the Social & Natural Sciences. First. Thousand Oaks: SAGE Publications.\n\n\nÖsterman, Marcus. 2021. “Can We Trust Education for Fostering Trust? Quasi-experimental Evidence on the Effect of Education and Tracking on Social Trust.” Social Indicators Research 154 (1): 211–33. https://doi.org/10.1007/s11205-020-02529-y.\n\n\nValentino, Nicholas A., Stuart N. Soroka, Shanto Iyengar, Toril Aalberg, Raymond Duch, Marta Fraile, Kyu S. Hahn, et al. 2019. “Economic and Cultural Drivers of Immigrant Support Worldwide.” British Journal of Political Science 49 (4): 1201–26. https://doi.org/10.1017/S000712341700031X.\n\n\nWeiss, Alexa, Corinna Michels, Pascal Burgmer, Thomas Mussweiler, Axel Ockenfels, and Wilhelm Hofmann. 2021. “Trust in Everyday Life.” Journal of Personality and Social Psychology 121: 95–114. https://doi.org/10.1037/pspi0000334."
  },
  {
    "objectID": "assessment/index.html",
    "href": "assessment/index.html",
    "title": "Assessment",
    "section": "",
    "text": "3,500-word long data analysis report\n   12:00 (noon) on 24th April 2024\n   Submit to Turnitin via Canvas\n\nMore detailed information is available on Canvas"
  },
  {
    "objectID": "data/data-documentation.html",
    "href": "data/data-documentation.html",
    "title": "Data documentation",
    "section": "",
    "text": "The datasets used in this course and available for download from the course website are the following:\n\n\n\nFile name\nOriginal name\nType\nVersion\nSurvey\nLinks\n\n\n\n\neb89.1\nZA6963_v1-0-0\n.dta\n.sav\n1.0.0\nEurobarometer; 89.1 (March 2018)\nSource\nQuestionnaire\nCodebook\n\n\ness9\nESS9e03_1\n.dta\n.sav\n3.1\nEuropean Social Survey; Integrated file, Round 9 (2018)\nSource\nQuestionnaire\nCodebook\n\n\nevs5\nZA7500_v4-0-0\n.dta\n.sav\n4.0.0\nEuropean Values Study; Wave 5 (2017-2020)\nSource\nQuestionnaire\nCodebook\n\n\nEUinUK2018\nEUinUK2018_Polish\n.dta\n-\nSurvey data collected by McGhee and Moreh (2018), ESRC Centre for Population Change\nSource\nQuestionnaire\nCodebook\n\n\nLaddLenz\nLaddLenz\n.dta\n-\nReplication data for Ladd and Lenz (2009), based on British Election Panel Study data\nSource\nQuestionnaire\nCodebook\n\n\nosterman\nReplication_data_ESS1-9_20201113\n.dta\n-\nReplication data for Österman (2020), based on European Social Survey Rounds 1-9 data\nSource\nQuestionnaire\nCodebook\n\n\n\nThe datasets can be read into R from \"https://cgmoreh.github.io/SSC7001M/data/FILE_NAME\" using an appropriate command from the haven package or other importing function.\n\n\n\n\n\nFile\n\n\nOriginal name\n\n\nType\n\n\nVersion\n\n\nOrigin\n\n\nAccess\n\n\n\n\n\n\nosterman\n\n\nReplication_data_ESS1-9_20201113\n\n\n.dta\n\n\nNA\n\n\nReplication data for Österman (2021), based on European Social Survey Rounds 1-9 data\n\n\nSource  Questionnaire  Codebook\n\n\n\n\nLaddLenz\n\n\nLaddLenz\n\n\n.dta\n\n\nNA\n\n\nReplication data for Ladd and Lenz (2009), based on British Election Panel Study data. Included in Hainmueller (2012)\n\n\nSource  Questionnaire  Codebook\n\n\n\n\n\n\n\n\n\nReferences\n\nHainmueller, Jens. 2012. “Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies.” Political Analysis 20 (1): 25–46. https://doi.org/10.1093/pan/mpr025.\n\n\nLadd, Jonathan McDonald, and Gabriel S. Lenz. 2009. “Exploiting a Rare Communication Shift to Document the Persuasive Power of the News Media.” American Journal of Political Science 53 (2): 394–410. https://doi.org/10.1111/j.1540-5907.2009.00377.x.\n\n\nÖsterman, Marcus. 2021. “Can We Trust Education for Fostering Trust? Quasi-experimental Evidence on the Effect of Education and Tracking on Social Trust.” Social Indicators Research 154 (1): 211–33. https://doi.org/10.1007/s11205-020-02529-y."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Quantitative analysis \n        ",
    "section": "",
    "text": "Quantitative analysis \n        \n        \n            HSS8005 • Intermediate stream • 2023/2024 Winter/Spring\nNewcastle University (UK)\n        \n        \n            A second course in applied statistics and probability for the understanding of society and culture. It is aimed at an interdisciplinary postgraduate audience in the social sciences and humanities. Focusing on real-life examples from published research, the course emphasizes the scientific application of regression models, the practice of reproducible research workflows, and the communication of statistical results to diverse audiences. It prioritises understanding through modern computational techniques over mathematical abstraction.\n        \n    \n\n\n\n\n\n\nModule leader\n\n   Dr. Chris Moreh\n   HDB.4.106\n   chris.moreh at newcastle dot ac dot uk\n   Tutorial booker\n \n\n\n\nTeaching Assistants\n\n   Cafer Deniz\n   Minki Sung\n\n\n\n\n\nTimetable\n\n   Tuesdays, Timetable Weeks 22-29\n    HDB.6.19 PGR Learning Lab\n   Lectures: 10:00-11:30\n   Labs: 12:00-13:30 and 13:30-15:00  \n\n\n\nAssessment\n\n   3,500-word long data analysis report\n   Submit by 12:00 (noon) on 24th April 2024\n   Submit to Turnitin via Canvas\n\n\n\n\n\n\nModule overview\nThis module is offered by School X - Researcher Education and Development to postgraduate students within the Faculty of Humanities and Social Sciences at Newcastle University. The module aims to provide a broad applied introduction to more advanced methods in quantitative analysis for students from various disciplinary backgrounds. See the module plan page for details about the methods covered. The course content consists of eight lectures (1.5 hours each) and eight IT labs (1.5 hours) . The course stands on three pillars: application, reproducibility and computation.\nApplication: we will work with real data originating from large-scale representative surveys or published research, with the aim of applying methods to concrete research scenarios. IT lab exercises will involve reproducing small bits of published research, using the data and (critically) the modelling approaches used by the authors. The aim is to see how methods have been used in practice in various disciplines and learn how to reproduce (and potentially improve) those analyses. This will then enable students to apply this knowledge to their own research questions. The data used in IT labs may be cleansed to allow focusing more on modelling tasks than on data wrangling, but exercises will address some of the more common data manipulation challenges and will cover essential functions. Data cleansing scripts will also be provided so that interested students can use them in their own work.\nReproducibility: developing a reproducible workflow that allows your future self or a reviewer of your work to understand your process of analysis and reproduce your results is essential for reliable and collaborative scientific research. We enforce the ideas and procedures of reproducible research both through replicating published research (see above) and in our practice (in the IT labs and the assignment). For an overview of why it’s important to develop a reproducible workflow early on in your research career and how to do it using (some) of the tools used in this module, read Chapter 3 of TSD (see Resources&gt;Readings). It’s also worth reading through Kieran Healy’s The Plain Person’s Guide to Plain Text Social Science, although there are now better software options than those discussed there. In this course, we will be using a suite of well-integrated free and open-source software to aid our reproducible workflow: the  statistical programming language and its currently most popular dialect – the {tidyverse} – via the \n\n\n\n\n\n\n\t\n\t\t\n\t\t\t\n\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\n\t\t\n\t\t\t\n\t\t\n\t\t\n\t\t\t\n\t\t\t\n\t\t\n\t\n\n\n\n\n\n IDE for data analysis, and  for scientific writing and publishing (see Resources&gt;Software).\nComputation: the development of computational methods underpins the application of the most important statistical ideas of the past 50 years (see Andrew Gelman’s article on these developments here or an online workshop talk here; Richard McElreath’s great talk on Science as Amateur Software Development is well worth watching too). This module aims to develop basic computational skills that allow the application of complex statistical models to practical scientific problems without advanced mathematical knowledge, and which lay the foundation on which students can then pursue further learning and research in computational humanities and social sciences.\n\n\nPrerequisites\nTo benefit the most from this module, students are expected to have a foundational level of knowledge in quantitative methods: a good understanding of data types and distributions, familiarity with inferential statistics, and some exposure to linear regression. This is roughly equivalent to the content covered in a textbook such as OpenIntro Statistics (you can download it for free).\nThose who don’t feel completely up to date with linear regression but are determined to advance more quickly and read/practice beyond the compulsory material during weeks 1-3 are also encouraged to sign up.\nThose with a stronger background in multiple linear regression (e.g. students with undergraduate-level training in econometrics) will still benefit from weeks 1-3 as the approach we are taking is probably different from the one they are familiar with.\nNo previous knowledge of  or command-based statistical analysis software is needed. Gaining experience with using statistical software is part of the skills development aims of the module. However, it is not a general data science module, and the IT labs will cover a very limited number of functions (from both base , the tidyverse and other reliable user-written packages) that are most useful for tackling specific analysis tasks. Students are advised to complete some additional self-paced free online training in the use of the software, such as Data Carpentry’s R for Social Scientists, and to consult Wickham, Çetinkaya-Rundel and Grolemund’s R for Data Science) online book.\n\n\n\nThe course and the website were written and are maintained by Chris Moreh."
  },
  {
    "objectID": "materials/index.html",
    "href": "materials/index.html",
    "title": "Materials",
    "section": "",
    "text": "Materials for each week are available from the side menu. The table below outlines the weekly topics.\n\n\n\n\n\nWeekly topics\n\n\n\n\n\n\n\n\nWeek 1  Mind your language\n\n\nA brief introduction to R, RStudio, and other tools of the trade\n\n\n\n\nWeek 2  Escaping Flatland\n\n\nLinear models and their limitations\n\n\n\n\nWeek 3  Categories\n\n\nLogistic regression and other generalised linear models\n\n\n\n\nWeek 4  Interactions\n\n\nEstimating, graphing and interpreting interaction effects\n\n\n\n\nWeek 5  Biases\n\n\nConsiderations for causal analysis\n\n\n\n\nWeek 6  Hierarchies\n\n\nMultilevel models\n\n\n\n\nWeek 7  Temporalities\n\n\nTime series, panel and longitudinal data analysis\n\n\n\n\nWeek 8  Study design\n\n\nSimulation-based power analysis for study design\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Materials",
      "Weekly materials"
    ]
  },
  {
    "objectID": "materials/info/info_w01.html",
    "href": "materials/info/info_w01.html",
    "title": "Week 1  Mind your language",
    "section": "",
    "text": "Description\nWe start the module with an applied introduction to the programming language R and the various tools that we will use to enhance its application to empirical research work in the social sciences. You will only gain a very basic and generic understanding of these software in this first week, but you will learn more throughout the semester, in the form of coding tasks associated with specific data analysis exercises.\n\n\nReadings\nTextbook readings\n\nR4DS: Chapters 1-10 (“Whole game”)\n\nFurther training\nFor further structured training in the use of R, RStudio and RMarkdown/Quarto, see the R for Social Scientists online course provided by Data Carpentry at https://datacarpentry.org/r-socialsci/\nJenny Bryan’s (RStudio/Posit) university-course-originated online book Stat545 is also a great resource for learning R and RStudio in more depth.\nFor a very different approach emphasising the value of learning ‘base’ R over the RStudio + {tidyverse} utility combo, see Norm Matloff’s course fasteR: Fast Lane to Learning R!.",
    "crumbs": [
      "Materials",
      "Week 1"
    ]
  },
  {
    "objectID": "materials/info/info_w03.html",
    "href": "materials/info/info_w03.html",
    "title": "Week 3  Categories",
    "section": "",
    "text": "Description\nIt wasn’t until the last quarter of the 20th century that a unified vision of statistical modelling emerged, allowing practitioners to see how the general linear model we have explored so far is only a specific case of a more general class of models. We could have had a fancy, memorable name for this class of models - as John Nelder, one of its inventors, acknowledged later in life (Senn 2003, 127) - but back then academics were not required to undertake marketing training on the tweetabilty-factor of the chosen names for their theories; so we ended up with “generalised linear models”. These models can be applied to explananda (“explained”, “response”, “outcome”, “dependent” etc. variables, our ys) whose possible values have certain constraints (such as being limited by a lower bound or constrained to discreet choices) that makes the parameters of the Gaussian (‘normal’) distribution inefficient in describing them. Instead, they follow some of the other “exponential distributions” (and not only the exponential: cf. Gelman, Hill, and Vehtari (2020, 264)), of which the Poisson, gamma, beta, binomial and multinomial are probably the most common in human and social sciences research. Their “generalised linear modelling” involves mapping them unto a linear model using a so-called “link function”. We will explore what all of this means in practice and how it can be applied to data that we are interested in most in our respective fields of study.\n\n\nReadings\nStatistics\n\nROS: Chapters 13-15\nConnelly, Roxanne, Vernon Gayle, and Paul S. Lambert. 2016. ‘Statistical Modelling of Key Variables in Social Survey Data Analysis’. Methodological Innovations 9:205979911663800. Library access\n\nCoding\n\nTSD: Chapter 13\n\nApplication\n\nWu, Cary. 2021. ‘Education and Social Trust in Global Perspective’. Sociological Perspectives 64(6):1166–86. Available here: Library access\nDingemans, Ellen, and Erik Van Ingen. 2015. ‘Does Religion Breed Trust? A Cross-National Study of the Effects of Religious Involvement, Religious Faith, and Religious Context on Social Trust’. Journal for the Scientific Study of Religion 54(4):739–55. Library access\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and other stories. Cambridge: Cambridge University Press. https://doi.org/10.1017/9781139161879.\n\n\nSenn, Stephen. 2003. “A Conversation with John Nelder.” Statistical Science 18 (1): 118–31. https://doi.org/10.1214/ss/1056397489.",
    "crumbs": [
      "Materials",
      "Week 3"
    ]
  },
  {
    "objectID": "materials/info/info_w05.html",
    "href": "materials/info/info_w05.html",
    "title": "Week 5  Biases",
    "section": "",
    "text": "Before exploring more complex data structures, this week we pause to ask some essential conceptual questions that can clarify various stated and unstated assumptions about our empirical data, theoretical questions and the models we aim to fit to them. We’ll explore the possibilities and challenges of asking causal questions of observational data, and we’ll think about ways to avoid what evolutionary anthropologist Richard McElreath calls ‘causal salad’. More generally, we explore ways of thinking about and dealing with the various biases that affect quantitative analyses.\n\nReadings\nStatistics\n\nCinelli, Carlos, Andrew Forney, and Judea Pearl. 2022. “A Crash Course in Good and Bad Controls.” Sociological Methods & Research https://journals.sagepub.com/doi/full/10.1177/00491241221099552\nLundberg, Ian, Rebecca Johnson, and Brandon M. Stewart. 2021. “What Is Your Estimand? Defining the Target Quantity Connects Statistical Evidence to Theory.” American Sociological Review 86(3): 532–65. https://doi.org/10.1177/00031224211004187\nROS: Chapters 18-20\n\nApplication\n\nGriffith, Gareth J., Tim T. Morris, Matthew J. Tudball, Annie Herbert, Giulia Mancano, Lindsey Pike, Gemma C. Sharp, Jonathan Sterne, Tom M. Palmer, George Davey Smith, Kate Tilling, Luisa Zuccolo, Neil M. Davies, and Gibran Hemani. 2020. “Collider Bias Undermines Our Understanding of COVID-19 Disease Risk and Severity.” Nature Communications 11(1): 5749. https://www.nature.com/articles/s41467-020-19478-2\nBreen, Richard. 2018. “Some Methodological Problems in the Study of Multigenerational Mobility.” European Sociological Review 34(6): 603–11. https://doi.org/10.1093/esr/jcy037",
    "crumbs": [
      "Materials",
      "Week 5"
    ]
  },
  {
    "objectID": "materials/info/info_w07.html",
    "href": "materials/info/info_w07.html",
    "title": "Week 7  Temporalities",
    "section": "",
    "text": "We continue exploring hierarchical data structures, but now considering “temporal” aspects of data more closely and the opportunities (and challenges) the pose. The special kind of multilevel data structure we consider here involves repeated measurements on persons (or other units); measurements are therefore clustered within persons (or other units), and predictors can be available at the measurement or person level. Such datasets are often called panel or longitudinal. In settings where overall time trends are important, repeated measurement data are sometimes called time-series cross-sectional. Time-series cross-sectional data typically contain observations at regular time interval, and they commonly exhibit overall time patterns. In many such contexts one must consider how measurements cluster not only in the “temporal” variable but also in the “spatial” variable (e.g. country-year-level observations clustered within countries as well as years), with the potential for predictors at three levels (individual, temporal and spatial). We will consider such three (and higher)-level hierarchical analyses.\n\nReadings\nTextbook\n\nARM: Chapters 11 (pp. 237-249) and 12 (pp. 251-278)\n\nApplication\n\nMitchell, Jeffrey. 2021. “Social Trust and Anti-immigrant Attitudes in Europe: A Longitudinal Multi-Level Analysis.” Frontiers in Sociology 6 (April): 604884 - (online)\nKumove, Michael. 2024. “Take Five? Testing the Cultural and Experiential Theories of Generalised Trust Against Five Criteria.” Political Studies (online)\nDawson, Chris. 2019. “How Persistent Is Generalised Trust?” Sociology 53(3): 590–99. (online)\nBotzen, Katrin. 2015. “Are Joiners Trusters? A Panel Analysis of Participation and Generalized Trust.” Zeitschrift für Soziologie 44(5): 314–29. (online)\nSturgis, Patrick, Roger Patulny, Nick Allum, and Franz Buscha. 2012. Social Connectedness and Generalized Trust: A Longitudinal Perspective. Working Paper. ISER Working Paper Series. (online)",
    "crumbs": [
      "Materials",
      "Week 7"
    ]
  },
  {
    "objectID": "materials/notes/draft-notes_w02.html",
    "href": "materials/notes/draft-notes_w02.html",
    "title": "Week 2 Worksheet Notes",
    "section": "",
    "text": "So far we have looked at toy datasets included with R itself. In your own research - and in later weeks in this module - you will be using real data. But how do we get these data into RStudio? It depends, of course, on the format of the data you need to import.\nR’s native data format carries the extension .rds. The base-R function to load .rds datasets into R is readRDS().\nBut we can import data stored in other formats too, such as the generic comma separated values (.csv) format or the various formats used by other proprietary statistical analysis packages (e.g. SPSS, Stata, SAS).\nMany social science surveys are distributed in one of the proprietary formats mentioned, because those have been designed specifically to manage “labelled” data (i.e. variables that need to have longer descriptive labels and consist of many categorical variables whose categories/levels only make sense if they are themselves meaningfully “labelled”).\nFor example, the The World Values Survey (WVS) provides the greatest number of options for data download formats, including .rds and even .RData. However, most other large-scale cross-national surveys provide their data either in .csv, .sav (SPSS) or .dta (Stata).\nWhen you have the option, my advice is to download the .sav (SPSS) version of the data whenever possible, just because SPSS allows the longest variable and value labels and therefore that data labelling may be the most complete. It’s then easier to transport that to R than having to type everything in from a survey questionnaire when that information is needed.\nTraditionally, one of the most severe shortcomings of R compared to other proprietary statistical analysis packages has been it’s very limited and cumbersome support of labelling. This has changed significantly over the past few years. The suite of packages developed or contributed to by sociologist Daniel Lüdecke of the University of Hamburg are among the best available tools for this purpose - including the packages making up the {easystats} ecosystem.\nAs an example, let’s import a dataset from the latest wave of the World Values Survey (Wave 7). Two versions of the dataset are available via the module website (.rds and .sav), but you can download the data in other formats directly from the survey website: https://www.worldvaluessurvey.org/WVSDocumentationWV7.jsp.\nDownload the .rds version of the data file form here: https://cgmoreh.github.io/HSS8005-24/data/wvs7.rds\n\n\n\n\n\n\nImportant\n\n\n\nMake sure to download the file in the same folder where your R script/Quarto file is located, so you can import it easily, without complications cause by directory paths (see below)\n\n\nOnce the dataset is downloaded, you can import it into R. Because the downloaded data file is in the .rds format, you can navigate to the file either from within RStudio’s Files pane, or manually in Windows Explorer, and double-click the file to open. However, this is not a recommended way of opening a file, because you want to have a record of the action in your R script for the future.\nYou can load datasets saved in the .rds format using the readRDS() command. If your dataset is in another format, you can check out the {readr} package (for rectangular data such as .csv (comma separated values) or .tsv (tab separated values)), {readxl} (for Excel data), and {sjlabelled} (for SPSS, Stata and SAS formats).\nThe more generic function data_read() from {easystats}’s {datawizard} package loads data from various formats based on the source files extension, including files from internet sources or compressed files. It relies on the {rio} package, which provides similar functionality.\n\n\n\n\n\n\nNote\n\n\n\nIt’s important to note that by default the data_read() function assumes that numeric variables where all values have a value label are categorical and will convert them into factors. That means that all the numeric “values” will be replaced by the “value labels” (e.g. 1=“Yes”/ 2=“No” will become simply “Yes”/“No”). This is usually a reasonable default behaviour, because the majority of functions in R do not handle “value labels” and working with textual (character string) values can be more explicit. However, this may be less appropriate when the dataset contains many long ordered variables (such as 0-10 scale items), as we will most likely want to treat such variables as numeric in statistical models. To cancel this default behaviour, we can add the additional argument convert_factors = FALSE. This is also the format that gets imported when using readRDS(). However, most of the common tabulation and graphing functions will not show the category “labels” in the output either, and for that purpose having variables “converted to factors” (with the original “Values” overwritten by the “Value labels”) may be a better option. Below we will import the data with factors converted, as we will focus on tabulation and plotting.\n\n\nIf you have saved the dataset into the same folder where your analysis script/Quarto file lives, you can import it by specifying just the name of the dataset. If it’s in a sub-folder or a different location on the computer, you need to include a full path to the dataset, like in the example below:\n\nwvs7data &lt;- readRDS(\"D:/HSS8005/MyData/wvs7.rds\")\n\nIn the code above, I am assigning (with the assignment operator &lt;-) the data to an object I called “wvs7data”, but I could have given it any other name as long as it follows R’s naming conventions (no spaces, avoid special characters; see also recommended naming strategies in the tidyverse style guide). The object will appear in the Environment tab (on the bottom right pane).\n\n\n\n\n\n\nWarning\n\n\n\nWorking with folders and paths\nIf the data file is not in the folder where you main script (the one that does the importing) is, you will need to specify either a relative path from the script to the data file, or an absolute path from the home/working directory.\nCopy/pasting paths on Windows computers\nAn easy way to get the path to the data file is to navigate there on your computer, copy the path, and paste it into your R script. However, there are some complications with this procedure when using a Windows PC. My path above would have copied as D:\\HSS8005\\MyData\\wvs7.rds, but R does not recognise back-slashes as path elements because in R the backslash has a special meaning. You must manually replace backslashes with either forward slashes or double-backslashes (D:\\\\HSS8005\\\\MyData\\\\wvs7.rds).\nAnother option is to use the function readClipboard(), which pastes into R whatever text you have on your clipboard (after copying it) using double backslashes. For example, you can copy a path to the folder where the data is located, then add the filename to the end of the text string using the paste0() function to get a working path to the file you want to load.\nYou can check:\n\n# First, copy the path to your data folder on your computer\n# Check the output:\n\npaste0(readClipboard(), \"/wvs7.rds\")\n\nThe file in the path can then be imported as normal:\n\nwvs7data &lt;- data_read(paste0(readClipboard(), \"/wvs7.rds\"))\n\nUsing the {here} package\nWorking with paths, folders, directories in a sustainable and robust way can be a challenge. The {here} package provides some useful options if you are working within R project directories. By loading the here library, you establish the working directory to be the root folder of your R project (i.e. the folder where the .Rproj file is located), and you can easily construct paths to any file within that project by listing the folders that contain it relative to the project root. This works similarly on all operating systems, and it’s as easy as:\n\nlibrary(here)\n\nwvs7data &lt;- readRDS(here(\"HSS8005\", \"MyData\", \"wvs7.rds\"))\n\nYou can read more about the package in the “R for Social Scientists” course.\n\n\nWe can look at the dataset object in the Environment pane. If we click on the blue button with the white arrow before the name of the object, a list of variables and other information about them will roll down. If we click on the object’s name or info, the dataset will open in the Sources pane, just next to the R script file. This is equivalent to having run the following command:\n\nView(wvs7data)    \n\nNote the capital “V”; R is case-sensitive, so always pay attention; view(wvs7data) won’t work.\nYou can explore the dataset a bit. Only the first 50 columns (i.e. variables) are displayed, to see the next 50 you can click on arrow (&gt;) in the dataset window’s toolbar. Once you’ve had a quick look, you can close that view or return to the R script."
  },
  {
    "objectID": "materials/notes/draft-notes_w02.html#importing-external-data-into-rstudio",
    "href": "materials/notes/draft-notes_w02.html#importing-external-data-into-rstudio",
    "title": "Week 2 Worksheet Notes",
    "section": "",
    "text": "So far we have looked at toy datasets included with R itself. In your own research - and in later weeks in this module - you will be using real data. But how do we get these data into RStudio? It depends, of course, on the format of the data you need to import.\nR’s native data format carries the extension .rds. The base-R function to load .rds datasets into R is readRDS().\nBut we can import data stored in other formats too, such as the generic comma separated values (.csv) format or the various formats used by other proprietary statistical analysis packages (e.g. SPSS, Stata, SAS).\nMany social science surveys are distributed in one of the proprietary formats mentioned, because those have been designed specifically to manage “labelled” data (i.e. variables that need to have longer descriptive labels and consist of many categorical variables whose categories/levels only make sense if they are themselves meaningfully “labelled”).\nFor example, the The World Values Survey (WVS) provides the greatest number of options for data download formats, including .rds and even .RData. However, most other large-scale cross-national surveys provide their data either in .csv, .sav (SPSS) or .dta (Stata).\nWhen you have the option, my advice is to download the .sav (SPSS) version of the data whenever possible, just because SPSS allows the longest variable and value labels and therefore that data labelling may be the most complete. It’s then easier to transport that to R than having to type everything in from a survey questionnaire when that information is needed.\nTraditionally, one of the most severe shortcomings of R compared to other proprietary statistical analysis packages has been it’s very limited and cumbersome support of labelling. This has changed significantly over the past few years. The suite of packages developed or contributed to by sociologist Daniel Lüdecke of the University of Hamburg are among the best available tools for this purpose - including the packages making up the {easystats} ecosystem.\nAs an example, let’s import a dataset from the latest wave of the World Values Survey (Wave 7). Two versions of the dataset are available via the module website (.rds and .sav), but you can download the data in other formats directly from the survey website: https://www.worldvaluessurvey.org/WVSDocumentationWV7.jsp.\nDownload the .rds version of the data file form here: https://cgmoreh.github.io/HSS8005-24/data/wvs7.rds\n\n\n\n\n\n\nImportant\n\n\n\nMake sure to download the file in the same folder where your R script/Quarto file is located, so you can import it easily, without complications cause by directory paths (see below)\n\n\nOnce the dataset is downloaded, you can import it into R. Because the downloaded data file is in the .rds format, you can navigate to the file either from within RStudio’s Files pane, or manually in Windows Explorer, and double-click the file to open. However, this is not a recommended way of opening a file, because you want to have a record of the action in your R script for the future.\nYou can load datasets saved in the .rds format using the readRDS() command. If your dataset is in another format, you can check out the {readr} package (for rectangular data such as .csv (comma separated values) or .tsv (tab separated values)), {readxl} (for Excel data), and {sjlabelled} (for SPSS, Stata and SAS formats).\nThe more generic function data_read() from {easystats}’s {datawizard} package loads data from various formats based on the source files extension, including files from internet sources or compressed files. It relies on the {rio} package, which provides similar functionality.\n\n\n\n\n\n\nNote\n\n\n\nIt’s important to note that by default the data_read() function assumes that numeric variables where all values have a value label are categorical and will convert them into factors. That means that all the numeric “values” will be replaced by the “value labels” (e.g. 1=“Yes”/ 2=“No” will become simply “Yes”/“No”). This is usually a reasonable default behaviour, because the majority of functions in R do not handle “value labels” and working with textual (character string) values can be more explicit. However, this may be less appropriate when the dataset contains many long ordered variables (such as 0-10 scale items), as we will most likely want to treat such variables as numeric in statistical models. To cancel this default behaviour, we can add the additional argument convert_factors = FALSE. This is also the format that gets imported when using readRDS(). However, most of the common tabulation and graphing functions will not show the category “labels” in the output either, and for that purpose having variables “converted to factors” (with the original “Values” overwritten by the “Value labels”) may be a better option. Below we will import the data with factors converted, as we will focus on tabulation and plotting.\n\n\nIf you have saved the dataset into the same folder where your analysis script/Quarto file lives, you can import it by specifying just the name of the dataset. If it’s in a sub-folder or a different location on the computer, you need to include a full path to the dataset, like in the example below:\n\nwvs7data &lt;- readRDS(\"D:/HSS8005/MyData/wvs7.rds\")\n\nIn the code above, I am assigning (with the assignment operator &lt;-) the data to an object I called “wvs7data”, but I could have given it any other name as long as it follows R’s naming conventions (no spaces, avoid special characters; see also recommended naming strategies in the tidyverse style guide). The object will appear in the Environment tab (on the bottom right pane).\n\n\n\n\n\n\nWarning\n\n\n\nWorking with folders and paths\nIf the data file is not in the folder where you main script (the one that does the importing) is, you will need to specify either a relative path from the script to the data file, or an absolute path from the home/working directory.\nCopy/pasting paths on Windows computers\nAn easy way to get the path to the data file is to navigate there on your computer, copy the path, and paste it into your R script. However, there are some complications with this procedure when using a Windows PC. My path above would have copied as D:\\HSS8005\\MyData\\wvs7.rds, but R does not recognise back-slashes as path elements because in R the backslash has a special meaning. You must manually replace backslashes with either forward slashes or double-backslashes (D:\\\\HSS8005\\\\MyData\\\\wvs7.rds).\nAnother option is to use the function readClipboard(), which pastes into R whatever text you have on your clipboard (after copying it) using double backslashes. For example, you can copy a path to the folder where the data is located, then add the filename to the end of the text string using the paste0() function to get a working path to the file you want to load.\nYou can check:\n\n# First, copy the path to your data folder on your computer\n# Check the output:\n\npaste0(readClipboard(), \"/wvs7.rds\")\n\nThe file in the path can then be imported as normal:\n\nwvs7data &lt;- data_read(paste0(readClipboard(), \"/wvs7.rds\"))\n\nUsing the {here} package\nWorking with paths, folders, directories in a sustainable and robust way can be a challenge. The {here} package provides some useful options if you are working within R project directories. By loading the here library, you establish the working directory to be the root folder of your R project (i.e. the folder where the .Rproj file is located), and you can easily construct paths to any file within that project by listing the folders that contain it relative to the project root. This works similarly on all operating systems, and it’s as easy as:\n\nlibrary(here)\n\nwvs7data &lt;- readRDS(here(\"HSS8005\", \"MyData\", \"wvs7.rds\"))\n\nYou can read more about the package in the “R for Social Scientists” course.\n\n\nWe can look at the dataset object in the Environment pane. If we click on the blue button with the white arrow before the name of the object, a list of variables and other information about them will roll down. If we click on the object’s name or info, the dataset will open in the Sources pane, just next to the R script file. This is equivalent to having run the following command:\n\nView(wvs7data)    \n\nNote the capital “V”; R is case-sensitive, so always pay attention; view(wvs7data) won’t work.\nYou can explore the dataset a bit. Only the first 50 columns (i.e. variables) are displayed, to see the next 50 you can click on arrow (&gt;) in the dataset window’s toolbar. Once you’ve had a quick look, you can close that view or return to the R script."
  },
  {
    "objectID": "materials/notes/notes_w01.html",
    "href": "materials/notes/notes_w01.html",
    "title": "Week 1 Worksheet Notes",
    "section": "",
    "text": "By the end of the session, you will:\n\nunderstand how to use the most important panels in the RStudio interface\ncreate an RStudio Project to store your work throughout the course\nbegin using R scripts (.R) and Quarto notebooks (.qmd) to record and document your coding progress\nunderstand data types and basic operations in the R language\nunderstand the principles behind functions\nknow how to install, load and use functions from user-written packages\ngain familiarity with some useful functions from packages included in the {tidyverse} ecosystem.\n\nThis lab is an introduction to R and RStudio for the purposes of this module. Those new to R should also complete the R for Social Scientists online training course on their own (estimated to take around 5-6 hours), as well as read through the assigned chapters from the R4DS textbook.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w01.html#aims",
    "href": "materials/notes/notes_w01.html#aims",
    "title": "Week 1 Worksheet Notes",
    "section": "",
    "text": "By the end of the session, you will:\n\nunderstand how to use the most important panels in the RStudio interface\ncreate an RStudio Project to store your work throughout the course\nbegin using R scripts (.R) and Quarto notebooks (.qmd) to record and document your coding progress\nunderstand data types and basic operations in the R language\nunderstand the principles behind functions\nknow how to install, load and use functions from user-written packages\ngain familiarity with some useful functions from packages included in the {tidyverse} ecosystem.\n\nThis lab is an introduction to R and RStudio for the purposes of this module. Those new to R should also complete the R for Social Scientists online training course on their own (estimated to take around 5-6 hours), as well as read through the assigned chapters from the R4DS textbook.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w01.html#r-and-rstudio",
    "href": "materials/notes/notes_w01.html#r-and-rstudio",
    "title": "Week 1 Worksheet Notes",
    "section": "R and RStudio",
    "text": "R and RStudio\nTo install R and RStudio on your personal computers, follow the steps outlined here based on your operating system.\nAlthough you will only interact directly with RStudio in this module, R needs to be installed first.\nThink of the relationship between the two as that between the engine of a car (R) and the dashboard of a car (RStudio):\n\nOr perhaps imagine driving the car on the left vs. the one on the right:\n\n\n\n\n\n\n \n\n\n\n\nThe RStudio interface\nThe RStudio interface consists of four main panes (which can be customised to some degree):\n\nThe R Console Pane\nThe R Console, by default the left or lower-left pane in R Studio, is the home of the R “engine”. This is where the commands are actually run and non-graphic outputs and error/warning messages appear. The Console is the direct interface to the R software itself; it’s what we get if instead of RStudio we open the R software: a direct interface to the R programming language, where we can type commands and where results/messages are printed.\nYou can directly enter and run commands in the R Console, but realize that these commands are not saved as they are when running commands from a script. For this reason, we should not use the Console pane directly too much, ad reserve it only for quick and dirty calculations and checks. For typing commands that we want R to execute, we should instead use an R script file, where everything we type can be saved for later and complex analyses can be built up.\nThe Source Pane\nThis pane, by default in the upper-left, is a space to work with scripts and other text files. This pane is also where datasets (data frames) open up for viewing.\n\n\n\n\n\n\nNote\n\n\n\nIf your RStudio displays only one pane on the left, it is because you have no scripts open yet. We can open an existing one or create a new one. We’ll do that a bit later.\n\n\nThe Environment Pane\nThis pane, by default in the upper-right, is most often used to see brief summaries of “objects” that are available in an active session. Datasets loaded for analysis would appear here.\n\n\n\n\n\n\nNote\n\n\n\nIf your Environment is empty, it means that you don’t have any “objects” loaded or created yet. We will be creating some objects later and we will also import an example dataset.\n\n\nFiles, Plots, Packages, Help, etc. The lower-right pane includes several tabs including plots (display of graphics including maps), help, a file library, and available R packages (including installation/update options).\n\n\n\n\n\n\nTip\n\n\n\nYou can arrange the panes in various ways, depending on your preferences, using Tools &gt; Global Options in the top menu. So the arrangement of panes may look different on different computers.\n\n\n\n\nGeneral settings\nYou can personalise the look and feel of your RStudio setup in various ways using Tools &gt; Global Options from the top menu, but setting some options as default from the very start is highly recommended. You can see these in the pictures below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe most important setting in the picture on the left is the one to restore .RData at startup and saving the workspace as .RData on exit. Make sure these are un-ticked and set to ‘Never’, respectively, as shown in the picture. It’s always safer to start each RStudio session in a clean state, without anything automatically pre-loaded from a previous session. That could lead to serious and hard to trace complications.\nIn the picture on the right, you have the option to select that the new native pipe operator (|&gt;) (we’ll talk about it later!) be inserted using the Ctrl+Shift+M keyboard shortcut instead of the older version of the pipe (%&gt;%).\n\nThese settings will make more sense later, but it’s a good idea to have them sorted at the very beginning.\n\n\nScripts, markdown documents and projects\nWriting brief commands that you want to test out in the Console is okay, but what you really want is to save your commands as part of a workflow in a dedicated file that you can reuse, extend and share with others.\nIn every quantitative analysis, we need to ensure that each step in our analysis is traceable and reproducible. This is increasingly a professional standard expected of all data analysts in the social sciences. This means that we need to have an efficient way in which to share our analysis code, as well as our outputs and interpretations of our findings. RStudio has an efficient way of handling this requirement with the use of R script files and versions of the Markdown markup language that allow the efficient combining of plain text (as in the main body of an article) with analysis code and outputs produced in R. The table below lists the main characteristics of these file types:\n\n\n\nFormat\nExtension\nDescription\n\n\n\n\nR Script\n.R\nUse an R script if you want to document a large amount of code used for a particular analysis project. Scripts should contain working R commands and human-readable comments explaining the code. Commands can be run line-by-line, or the whole R script can be run at once. For example, one can write an R script containing a few hundred or thousands of lines of code that gathers and prepares raw, unruly data for analysis; if this script can run without any errors, then it can be saved and sourced from within another script that contains code that undertakes the analysis using the cleansed dataset. Comments can be added by appending them with a hashtag (#).\n\n\nR Markdown\n.Rmd\nMarkdown is a simple markup language that allows the formatting of plain text documents. R Markdown is a version of this language written by the R Studio team, which also allows for R code to be included. Plain text documents having the .Rmd extension and containing R Markdown-specific code can be “knitted” (exported) directly into published output document formats such as HTML, PDF or Microsoft Word, which contain both normal text as well as tables and charts produced with the embedded R code. The code itself can also be printed to the output documents.\n\n\nQuarto document\n.qmd\nQuarto is a newer version of R Markdown which allows better compatibility with other programming languages. It is a broader ecosystem design for academic publishing and communication (for example, the course website was built using quarto), but you will be using only Quarto documents in this module. There isn’t much difference between .Rmd and .qmd documents for their uses-cases on this module, so one could easily change and .Rmd extension to .qmd and still produce the same output. .qmd documents are “rendered” instead of “knitted”, but for RStudio users the underlying engine doing the conversion from Quarto/R Markdown to standard Markdown to output file (HTML, PDF, Word, etc.) is the same. Read more about Quarto document in the TSD textbook.\n\n\n\nCreating new files can be done easily via the options File &gt; New File &gt; from the top RStudio menu.\nThe best way to use these files are as part of R project folders, which allow for cross-references to documents and datasets to be made relative to the path of the project folder root. This makes sure that no absolute paths to files (i.e. things like “C:/Documents/Chris/my_article/data_files/my_dataset.rds”) need to be used (instead, you would write something like “~/data_files/my_dataset.rds” if the “my_article” folder was set up as an R Project). This allows for the same code file to be run on another computer too without an error, ensuring a minimal expected level of reproducibility in your workflow.\nSetting up an existing or a new folder as an R Project involves having a file with the extension .RProj saved in it. This can be done easily via the options File &gt; New Project from the top RStudio menu.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w01.html#r-data-types-and-structures",
    "href": "materials/notes/notes_w01.html#r-data-types-and-structures",
    "title": "Week 1 Worksheet Notes",
    "section": "R data types and structures",
    "text": "R data types and structures\nThe basic elements of data in R are called vectors. R has 6 basic data types that you should be aware of:\n\ncharacter: a text string, e.g. “name”\nnumeric: a real or decimal number\ninteger: non-decimal number; often represented by a number followed by the letter “L”, e.g. 5L\nlogical: TRUE or FALSE\ncomplex: complex numbers with real and imaginary parts\n\nR provides several functions to examine features of vectors and other objects, for example:\n\nclass() - what kind of object is it (high-level)?\ntypeof() - what is the object’s data type (low-level)?\nlength() - how long is it? What about two dimensional objects?\nattributes() - does it have any metadata?\n\nYou can explore some basic vector operations in Exercise 4 of the lab worksheet.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w01.html#data-frames",
    "href": "materials/notes/notes_w01.html#data-frames",
    "title": "Week 1 Worksheet Notes",
    "section": "Data frames",
    "text": "Data frames\nIt is useful to know about vectors, but we will use them primarily as part of larger data frames. Data frames are objects that contain several vectors of similar length. In a data frame each column is a variable and each row is a case. They look like spreadsheets containing data.\nThere are several toy data frames built into R, and we can have a look at one to see how it looks like. You can get a list of the available built-in datasets and their brief descriptions with the data() command.\nFor example, the mtcars data frame is built into R and so you can access it without loading any files. To get the dimensions, you can use dim(), nrow(), and ncol().\n\ndim(mtcars)\n\n[1] 32 11\n\nnrow(mtcars)\n\n[1] 32\n\nncol(mtcars)\n\n[1] 11\n\n\nWe can also load the dataset into our Environment and look at it manually:\n\nmtcars &lt;- mtcars\n\nThe new object has appeared in the Environment under a new section called Data. We can click on it and the dataset will open up in the Source pane. What do you think this dataset is about?\nYou can select each column/variable from the data frame use the $, turning it into a vector:\n\nmtcars$wt\n\n [1] 2.620 2.875 2.320 3.215 3.440 3.460 3.570 3.190 3.150 3.440 3.440 4.070\n[13] 3.730 3.780 5.250 5.424 5.345 2.200 1.615 1.835 2.465 3.520 3.435 3.840\n[25] 3.845 1.935 2.140 1.513 3.170 2.770 3.570 2.780\n\n\nYou can now treat this just like a vector, with the subsets and all.\n\nmtcars$wt[1]\n\n[1] 2.62\n\n\nWe can subset to the first/last k rows of a data frame\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\ntail(mtcars)\n\n                mpg cyl  disp  hp drat    wt qsec vs am gear carb\nPorsche 914-2  26.0   4 120.3  91 4.43 2.140 16.7  0  1    5    2\nLotus Europa   30.4   4  95.1 113 3.77 1.513 16.9  1  1    5    2\nFord Pantera L 15.8   8 351.0 264 4.22 3.170 14.5  0  1    5    4\nFerrari Dino   19.7   6 145.0 175 3.62 2.770 15.5  0  1    5    6\nMaserati Bora  15.0   8 301.0 335 3.54 3.570 14.6  0  1    5    8\nVolvo 142E     21.4   4 121.0 109 4.11 2.780 18.6  1  1    4    2\n\n\nThere are various ways in which one can further subset and wrangle vectors and data frames using base R functions, but the {tidyverse} and other user-written packages provide more functionality and ease of use. In this course, we will rely mostly on these.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w01.html#functions",
    "href": "materials/notes/notes_w01.html#functions",
    "title": "Week 1 Worksheet Notes",
    "section": "Functions",
    "text": "Functions\nMost of the work in R is done using functions. It’s possible to create your own functions. This makes R extremely powerful and extendible. We’re not going to cover making your own functions in this course, but it’s important to be aware of this capability. There are plenty of good resources online for learning how to do this, including this one.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w01.html#packages",
    "href": "materials/notes/notes_w01.html#packages",
    "title": "Week 1 Worksheet Notes",
    "section": "Packages",
    "text": "Packages\nInstead of programming your own functions in the R language, you can rely on functions written by other people and bundled within a package that performs some set task.\nWhen you install R, a set of “packages” containing various functions are also installed by default. These packages make up what is colloquially referred to as base R. Functions from these packages can be used straight away and they cannot be deleted or installed separately. The functionality of these base R packages is updated with each new edition of R, but not in between new releases of the software. The code below lists the names of all the packages in base R:\n\nnames(which(installed.packages()[ ,\"Priority\"] == \"base\", ))\n\n [1] \"base\"      \"compiler\"  \"datasets\"  \"graphics\"  \"grDevices\" \"grid\"     \n [7] \"methods\"   \"parallel\"  \"splines\"   \"stats\"     \"stats4\"    \"tcltk\"    \n[13] \"tools\"     \"utils\"    \n\n\nWe see in the list that there is also a package called “base”, which contains 1273 elementary functions. However, when we refer to base R, we usually mean the functions from all the 14 packages listed above.\nApart from these packages that come pre-installed and pre-loaded with our R installation, there are also a number of “recommended” packages, which can be thought of as an extended base R. These packages also come pre-installed in binary distributions of R, but they need to be loaded in order to make their functions available for use. These “recommended” packages are:\n\nnames(which(installed.packages()[ ,\"Priority\"] == \"recommended\", ))\n\n [1] \"Matrix\"     \"mgcv\"       \"nlme\"       \"boot\"       \"class\"     \n [6] \"cluster\"    \"codetools\"  \"foreign\"    \"KernSmooth\" \"lattice\"   \n[11] \"MASS\"       \"Matrix\"     \"mgcv\"       \"nlme\"       \"nnet\"      \n[16] \"rpart\"      \"spatial\"    \"survival\"  \n\n\nApart from these “recommended” packages, there is a great - and ever increasing - number of user-written packages that satisfy various programming needs. Some packages contain functions that are particularly useful for social scientists. Sometimes a number of packages that contain complementary functionality and are designed to work well together are brought under one meta-package, which allows for all those packages to be installed and loaded at once. The most popular such meta-package is the {tidyverse}, which includes such packages as {dplyr} (for data manipulation), {readr} (for reading in rectangular data like .csv files), {tidyr} (for cleaning datasets), {stringr} (for working with “strings”, that is, textual data), {forcats} (for managing “factors”, that is, categorical variables) or {ggplot2} (for data visualisation), among [several others](https://www.tidyverse.org/packages/.\nThe {tidyverse} packages have been developed around a coding philosophy that is very different from that of “base R”. It is sometimes referred to as a special “dialect” of the R language and has greatly contributed to popularising R and making it more easily available to practising social scientists who do not have a programming background, by designing code whose “grammar” is somewhat closer to that of “human” languages such as English. This is generally thought to lower the entry barriers to R for new users, although there isn’t a clear consensus on that.\nAnother recently developed meta-package, which was specifically designed with non-programmer social scientists in mind, is the {easystats} bundle. We will be relying on {easystats} packages quite a lot in this module, as they provide a very coherent set of functions that improve on the {tidyverse}.\nBoth of these meta-packages and thousands of other packages are available from the Comprehensive R Archive Network (CRAN). Many more packages are distributed as repositories on code-sharing platforms such as GitHub or R Universe.\nPackages made available on CRAN can be installed using the command install.packages(\"packagename\"). Once the package/library is installed (i.e. it is sitting somewhere on your computer), we can then load functions from that package using the :: operator (e.g. package::function()), or we can make all the functions from a package available by attaching that package with the library() function (e.g. library(package)).\nSo using a package/library is a two-stage process. We:\n\n **Install** the package/library onto your computer (from CRAN or another repository)\n2.a. Load functions from the package as you use them, or: 2.b. Attach the whole package to R’s search path, making all functions available to use by name\n\nLet’s start by installing the tidyverse meta-package, and then attach it:\n\ninstall.packages(\"tidyverse\")  ## this command installs packages from CRAN; note the quotation marks around the package name\n\nYou can check the suite of packages that are available when you attach the tidyverse library using a command from the tidyverse itself:\n\ntidyverse_packages()\n\n\nQuestion\nWhy do you think we got an error message when we tried to run the above command?\n\nBecause tidyverse_packages() is itself a function from the tidyverse, in order to use that function we need not only to install the tidyverse but also to make its functions available. In other words, we did not yet attach the tidyverse for use in our R session, we only just installed it on our computers.\nIf we don’t want to attach a package that we have downloaded - because maybe we only want to use a single function once and we don’t want to burden our computer’s memory, we can load explicitly given functions from a package in the following way:\n\ntidyverse::tidyverse_packages()  # Here we state the package followed by two colons, then followed by the function we want\n\nBut in many cases we do want to use several functions at various points in an analysis session, so it is often useful to attach the entire package or set of packages:\n\nlibrary(tidyverse)\n\nNow we can use functions from that package without having to explicitly state the name of the package. We can still state the name explicitly, and that may be useful for readers of our code to understand what package a function come from. Also, it may happen that different packages have similarly named functions, and if all those packages are attached, then the functions from a package attached later will override that in the package attached earlier. R will note in a comment whether any functions from a package are masked by another, so it’s worth paying attention to the comments and warnings printed by R when we attach packages.\n\nInstalling and attaching packages\nBoth install.packages() and library() are base R functions, but there are several other user-written packages that provide additional functionality to make it easier and more efficient to install, attach and manage packages. For example, the pacman package contains a function p_load() that allows us to attach several packages at once and install them from CRAN on the fly if they are not yet installed. The sister function p_load_gh() does the same for packages not published on CRAN but stored on personal repositories on GitHub. The {librarian} package does the same with the shelf() function, which installs missing packages from CRAN as well as GitHub.\nFor example, we can download and attach a number of packages in one go with the command below:\n\n# First, install {librarian} itself if not yet installed:\n\nif (!require(\"librarian\")) install.packages(\"librarian\") \n\nLoading required package: librarian\n\n# Then attach/install other packages using `librarian::shelf()`:\n\nlibrarian::shelf(\n  tidyverse,\n  easystats,\n  sjlabelled,\n  gtsummary,\n  ggformula\n  )\n\nThese are some useful packages that we will be using in this module. You can read more about the (meta)packages we have just installed here:\n\ntidyverse\neasystats\nsjlabelled\ngtsummary\nggformula",
    "crumbs": [
      "Materials",
      "Week 1",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w01.html#about-the-tidyverse",
    "href": "materials/notes/notes_w01.html#about-the-tidyverse",
    "title": "Week 1 Worksheet Notes",
    "section": "About the Tidyverse",
    "text": "About the Tidyverse\n\nData frames and ‘tibbles’\nThe Tidyverse is built around the basic concept that data in a table should have one observation per row, one variable per column, and only one value per cell. Once data is in this ‘tidy’ format, it can be transformed, visualized and modelled for an analysis.\nWhen using functions in the Tidyverse ecosystem, most data is returned as a tibble object. Tibbles are very similar to the data.frames (which are the basic types of object storing datasets in base R) and it is perfectly fine to use Tidyverse functions on a data.frame object. Just be aware that in most cases, the Tidyverse function will transform your data into a tibble. If you are unobservant, you won’t even notice a difference. However, there are a few differences between the two data types, most of which are just designed to make your life easier. For more info, check R4DS.\n\n\nSelected dplyr functions\nThe dplyr package is designed to make it easier to manipulate flat (2-D) data (i.e. the type of datasets we are most likely to use, which are laid out as in a standard spreadsheet, with rows referring to cases (observations; respondents) and columns referring to variables. dplyr provides simple “verbs”, functions that correspond to the most common data manipulation tasks, to help you translate your thoughts into code. Here are some of the most common functions in dplyr:\n\nfilter() chooses rows based on column values.\narrange() changes the order of the rows.\nselect() changes whether or not a column is included.\nrename() changes the name of columns.\nmutate()/transmute() changes the values of columns and creates new columns (variables)\nsummarise() compute statistical summaries (e.g., computing the mean or the sum)\ngroup_by() group data into rows with the same values\nungroup() remove grouping information from data frame.\ndistinct() remove duplicate rows.\n\nAll these functions work similarly as follows:\n\nThe first argument is a data frame/tibble\nThe subsequent arguments are comma separated list of unquoted variable names and the specification of what you want to do\nThe result is a new data frame\n\nFor more info, check R for Social Scientists\nMost of the {dplyr} verbs perform tasks that can also be done in base R, but they provide more convenience. The table below lists a rough equivalence between dplyr and base R functionality:\n\n\n\n\n\n\n\ndplyr\nbase\n\n\n\n\narrange(df, x)\ndf[order(x), , drop = FALSE]\n\n\ndistinct(df, x)\ndf[!duplicated(x), , drop = FALSE], unique()\n\n\nfilter(df, x)\ndf[which(x), , drop = FALSE], subset()\n\n\nmutate(df, z = x + y)\ndf$z &lt;- df$x + df$y, transform()\n\n\npull(df, 1)\ndf[[1]]\n\n\npull(df, x)\ndf$x\n\n\nrename(df, y = x)\nnames(df)[names(df) == \"x\"] &lt;- \"y\"\n\n\nrelocate(df, y)\ndf[union(\"y\", names(df))]\n\n\nselect(df, x, y)\ndf[c(\"x\", \"y\")], subset()\n\n\nselect(df, starts_with(\"x\"))\ndf[grepl(\"^x\", names(df))]\n\n\nsummarise(df, mean(x))\nmean(df$x), tapply(), aggregate(), by()\n\n\nslice(df, c(1, 2, 5))\ndf[c(1, 2, 5), , drop = FALSE]\n\n\n\nThe above functions allow us to manage single data-frames. A set of other functions (sometimes called “two-table verbs”) make it possible to combine columns, rows, or both, from two or more data-frames. In base-R, much of this can be achieved with the merge() function, while in dplyr the join() function makes this possible, extending some further functionality that is not easily available in base-R. The table below lists these dplyr functions and their base-R equivalents:\n\n\n\ndplyr\nbase\n\n\n\n\ninner_join(df1, df2)\nmerge(df1, df2)\n\n\nleft_join(df1, df2)\nmerge(df1, df2, all.x = TRUE)\n\n\nright_join(df1, df2)\nmerge(df1, df2, all.y = TRUE)\n\n\nfull_join(df1, df2)\nmerge(df1, df2, all = TRUE)\n\n\nsemi_join(df1, df2)\ndf1[df1$x %in% df2$x, , drop = FALSE]\n\n\nanti_join(df1, df2)\ndf1[!df1$x %in% df2$x, , drop = FALSE]\n\n\n\n\n\nThe forward-pipe (%&gt;%/|&gt;) workflow\nAll of the dplyr functions take a data frame or tibble as the first argument. Rather than forcing the user to either save intermediate objects or nest functions, dplyr provides the forward-pipe operator %&gt;% from the magrittr package. This operator allows us to combine multiple operations into a single sequential chain of actions. As of R 4.1.0 there is also a native pipe operator in R (|&gt;), and in RStudio one can set the shortcut to paste the new pipe operator instead (as we have done at the beginning of the lab). Going forward, we’ll use this version of the pipe operator for simplicity, but it’s likely that you will encounter the older version of the operator too in various scripts.\nLet’s start with a hypothetical example. Say you would like to perform a sequence of operations on data frame x using hypothetical functions f(), g(), and h():\n\nTake x then\nUse x as an input to a function f() then\nUse the output of f(x) as an input to a function g() then\nUse the output of g(f(x)) as an input to a function h()\n\nOne way to achieve this sequence of operations is by using nesting parentheses as follows:\nh(g(f(x)))\nThis code isn’t so hard to read since we are applying only three functions: f(), then g(), then h() and each of the functions is short in its name. Further, each of these functions also only has one argument. However, you can imagine that this will get progressively harder to read as the number of functions applied in your sequence increases and the arguments in each function increase as well. This is where the pipe operator |&gt; comes in handy. |&gt; takes the output of one function and then “pipes” it to be the input of the next function. Furthermore, a helpful trick is to read |&gt; as “then” or “and then.” For example, you can obtain the same output as the hypothetical sequence of functions as follows:\nx |&gt; \n  f() |&gt; \n  g() |&gt; \n  h()\nYou would read this sequence as:\n\nTake x then\nUse this output as the input to the next function f() then\nUse this output as the input to the next function g() then\nUse this output as the input to the next function h()\n\nSo while both approaches achieve the same goal, the latter is much more human-readable because you can clearly read the sequence of operations line-by-line. Instead of typing out the three strange characters of the operator, one can use the keyboard shortcut Ctrl + Shift + M (Windows) or Cmd + Shift + M (MacOS) to paste the operator.",
    "crumbs": [
      "Materials",
      "Week 1",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w04.html",
    "href": "materials/notes/notes_w04.html",
    "title": "Week 4 Worksheet Notes",
    "section": "",
    "text": "By the end of the session you will learn how to:\n\nfit, visualise and interpret results from regression models that include interaction terms",
    "crumbs": [
      "Materials",
      "Week 4",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w04.html#aims",
    "href": "materials/notes/notes_w04.html#aims",
    "title": "Week 4 Worksheet Notes",
    "section": "",
    "text": "By the end of the session you will learn how to:\n\nfit, visualise and interpret results from regression models that include interaction terms",
    "crumbs": [
      "Materials",
      "Week 4",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w04.html#r-packages",
    "href": "materials/notes/notes_w04.html#r-packages",
    "title": "Week 4 Worksheet Notes",
    "section": "R packages",
    "text": "R packages\n\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(gtsummary)\nlibrary(ggformula)\nlibrary(sjlabelled)\nlibrary(ggeffects)\nlibrary(marginaleffects)",
    "crumbs": [
      "Materials",
      "Week 4",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w04.html#introduction",
    "href": "materials/notes/notes_w04.html#introduction",
    "title": "Week 4 Worksheet Notes",
    "section": "Introduction",
    "text": "Introduction\nThis session explores examples of interactions in regression models. We will look more closely at some of the multiple regression models we have fit in previous labs and ask whether the effects of core explanatory variables could be said to depend on (or are conditioned on) the values of other explanatory variables included in the model. In practice, this will involve including the product of two explanatory variables in the model. Thus, taking a regression model of the generic form \\(y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\epsilon\\), we ask whether there is an interaction between variables \\(X_1\\) and \\(X_2\\) (i.e. whether the effect of one depends on the values of the other) by fitting a model of the form \\(y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\color{green}{\\beta_3(X_1 \\times X_2)} + \\epsilon\\), where we are interested in the “interaction effect” represented by \\(\\beta_3\\).\nWhile fitting such interaction models is simple in practice, understanding when they are needed, interpreting, and communicating their results can be challenging, and a growing literature in the social sciences has explored best practices in relation to such models (Berry, Golder, and Milton 2012; Brambor, Clark, and Golder 2006; Clark and Golder 2023; Hainmueller, Mummolo, and Xu 2019). Advancements in software have also made it easier to interpret and present results from interaction models, with some notable R packages entering this space over the past few years; we have already encountered the {marginaleffects} and {ggeffects} packages when visualising results from logistic regression models, and examining results from interaction models presents very similar challenges. In this week’s lab we will use some of these tools to undertake comprehensive analyses of interaction effects.\nWe have already encountered interactions in all of the application readings we have engaged with so far. However, they mostly involved more complex cases of interactions, whose understanding will first require a more basic knowledge of how interaction effects work and how they can be implemented in practice. Wu (2021) and Dingemans and Van Ingen (2015) make use of “cross-level” interactions, which we will revisit when learning about multilevel models (Week 6). Mitchell (2021) uses higher-level interactions on data aggregated at country level as an additional analysis to their main models, while Österman (2021) operates with a quasi-experimental design in which the interaction effect is taken to divulge a more directly causal effect the data. This latter example is “more complex” only at a conceptual and study design level, and we will replicate it in the lab exercises. However, we begin by looking at a conceptually less involved example where interaction effects are at the core of the analysis, also from the field of social trust research.",
    "crumbs": [
      "Materials",
      "Week 4",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w04.html#example-1.-akaeda2023trusteducationalgap-are-preferences-for-redistribution-associated-with-education-in-european-countries-and-is-the-association-moderated-by-social-trust",
    "href": "materials/notes/notes_w04.html#example-1.-akaeda2023trusteducationalgap-are-preferences-for-redistribution-associated-with-education-in-european-countries-and-is-the-association-moderated-by-social-trust",
    "title": "Week 4 Worksheet Notes",
    "section": "Example 1. Akaeda (2023): Are preferences for redistribution associated with education in European countries, and is the association moderated by social trust?",
    "text": "Example 1. Akaeda (2023): Are preferences for redistribution associated with education in European countries, and is the association moderated by social trust?\nThe research question in the title of this exercise relates directly to the research reported by Akaeda (2023). Following a detailed review of the literature on the relationship between attitudes towards redistribution, education, and social- and institutional trust, the author derives a hypothesis they want to investigate: “trust decreases the gap in preferences for redistribution due to education” (p. 296). They break down the hypothesis into two parts, one relating to social trust and the other to institutional trust.\nAkaeda (2023) combine data from several waves of the World Values Survey (WVS) and the European Values Study (EVS) to test this research hypothesis. Their combined dataset contains data on “74 countries, 26 years, 259 country-years, and 254,214 individuals”. Their interest is in modelling the hypothesised relationship on a global level, accounting both for various individual explanatory variables as well as macro-societal factors at the level of countries and country-years (i.e. change over time within countries).\nHere we will attempt to fit a simpler version of their “Model 3” (reported in Table 2). In terms of data, we focus specifically on “European” countries; for this purpose, we will use data from the latest wave of the European Values Study survey. In terms of variable selection and transformations, we will roughly follow Akaeda (2023), with some adjustments for convenience. Akaeda (2023:297–98) describe their variable selection procedure in these words:\n\n\nthe dependent variable is the score of preferences for redistribution. This score is based on a question … that asks respondents to indicate on a scale from 1 to 10 whether ‘Incomes should be made more equal (1)’ or ‘We need larger income differences as incentives for individual effort (10)’. In accordance with previous research, the scores were reversed such that a higher score indicates stronger support for redistribution;\nthe level of education is a key independent variable because the association between education and support for redistribution is a main focus of this study. Because previous studies have shed light on the mechanisms of university education related to a conservative view of redistribution, this analysis adopts the dummy for university or higher degree as an independent variable;\nas a key moderator variable … social trust as measured by the question, ‘Generally speaking, would you say that most people can be trusted or that you need to be very careful in dealing with people?’, which had the following two potential responses: ‘1. Most people can be trusted’, ‘2. Need to be very careful’. Based on previous research involving social trust, this analysis employs the dummy for social trust (1 = ‘Most people can be trusted’);\nthe following individual-level controls: gender (1 = female, 0= male), age, age squared, employment status (employed, self-employed, unemployed, retired, other), household income (z scored for country-year units, marital status (married = 1), child (having child = 1), and political orientation (1 = right to 10 = left)\n\n\n\nData preparation\nThe original data is freely accessible from the European Values Study website in various formats. For the purposes of this lab, we can also access a lightly edited dataset in native .Rds format from the Data page (evs2017.rds). We can either download the dataset to a local data folder and load it from there, or loaded directly from the web:\n\nevs &lt;- datawizard::data_read(\"https://cgmoreh.github.io/HSS8005-24/data/evs2017.rds\")\n\nReading data...\n\n\nVariables where all values have associated labels are now converted into\n  factors. If this is not intended, use `convert_factors = FALSE`.\n\n\n210 out of 266 variables were fully labelled and converted into factors.\n\n\nFollowing 8 variables are empty:\n  v72_DE, v73_DE, v74_DE, v75_DE, v76_DE, v77_DE, v78_DE and v79_DE\n  \nUse `remove_empty_columns()` to remove them from the data frame.\n\n\nOnce the data is loaded in the workspace environment, we can select the variables that we are interested in, inspect them in a codebook and apply any necessary transformations:\n\n# Select the variables needed:\n\nevs &lt;- evs |&gt; \n  select(v106,      # redistribution pref.\n         v243_r,    # education\n         v31,       # social trust\n         v225,      # sex/gender\n         age,\n         v244,      # employment status\n         v261_ppp,  # household income (corrected)\n         v234,      # marital status\n         v239_r,    # number of children\n         v102,      # political orientation (1=left...10=right)\n         )\n\nView the codebook for the selected variables:\n\ndata_codebook(evs) |&gt; View()\n\nRecode variables to match Akaeda (2023) as closely as possible:\n\nakaeda &lt;- evs |&gt; \n  data_modify(redistribute = reverse(v106),\n              # recode education to a binary; \n              # treat the original variable as a numeric variable in the process to allow referring to numeric codes rather than the long text labels\n              educ_univ = recode_values(as_numeric(v243_r),\n                                   recode = list(\"1\" = 3,\n                                                 \"0\" = c(1, 2, 4))),\n              # inverse to make \"most people can be trusted\" the second (indicator) category\n              trusting = recode_values(as_numeric(v31),\n                                       recode = list(\"1\" = 1,\n                                                     \"0\" = 2)),\n              # just rename as \"female\" is already the second category\n              female = v225,\n              # recode \"employment\" as a factor/categorical (without treating it as numeric and adding labels later)\n              employment = recode_values(v244,\n                                         recode = list(\"Employed\" = c(\"30h a week or more\", \n                                                                      \"less then 30h a week\"), \n                                                       \"Self-employed\" = \"self employed\", \n                                                       \"Unemployed\" = \"unemployed\", \n                                                       \"Retired\" = \"retired/pensioned\", \n                                                       \"Other\" = c(\"military service\", \n                                                                   \"homemaker not otherwise employed\", \n                                                                   \"student\", \n                                                                   \"disabled\", \n                                                                   \"other\"))),\n              hh_income = v261_ppp,\n              # recoding marital status as numeric\n              married = recode_values(as_numeric(v234),\n                                      recode = list(\"1\" = 1,\n                                                    \"0\" = 2:6)),\n              \n              child = recode_values(v239_r,\n                                    recode = list(\"0\" = 1,\n                                                  \"1\" = 2:6)),\n              politics = reverse(v102)\n              ) |&gt; \n  set_labels(married, labels = c(\"Not married\", \"Maried\")) |&gt; \n  set_labels(trusting, labels = c(\"Not trusting\", \"Trusting\")) |&gt; \n  set_labels(educ_univ, labels = c(\"No university education\", \"University education\")) |&gt; \n  set_labels(child, labels = c(\"No children\", \"Has children\")) |&gt; \n  # Treat them as factors again for better reporting of labels\n  to_label(married, trusting, educ_univ, child, married)\n\nView the codebook for the recoded dataset:\n\ndata_codebook(akaeda) |&gt; View()\n\n\n\nRelationships between the main variables of interest\nFollowing Akaeda (2023), the main variables of interest are redistribute, educ_univ and trusting. We can inspect some basic relationships between them using boxplots and cross-tabulations:\n\n# Boxplots:\n\ngf_boxplot(redistribute ~ educ_univ, data = akaeda)\n\nWarning: Removed 1335 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\ngf_boxplot(redistribute ~ trusting, data = akaeda)\n\nWarning: Removed 1335 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n# Cross-tabulations:\n\n# To check the values of a categorical variable by another categorical variable, a contingency table (cross-tabulation) is preferable.\n# Native R is not very good at cross-tabulations; there are some better user-written functions, but only relying on packages we have already used so far,\n# some options are:\n\n## In base R (table):\n### Simple frequencies\ntable(akaeda$educ_univ, akaeda$trusting)\n\n                         \n                          Not trusting Trusting\n  No university education        26838    11319\n  University education           10153     9416\n\n### Frequencies with added row marginal totals\ntable(akaeda$educ_univ, akaeda$trusting) |&gt; addmargins(margin = 2)\n\n                         \n                          Not trusting Trusting   Sum\n  No university education        26838    11319 38157\n  University education           10153     9416 19569\n\n### Proportions, by row\ntable(akaeda$educ_univ, akaeda$trusting) |&gt; prop.table(margin = 1)\n\n                         \n                          Not trusting  Trusting\n  No university education    0.7033572 0.2966428\n  University education       0.5188308 0.4811692\n\n### Proportions, by column with added column marginal totals\ntable(akaeda$educ_univ, akaeda$trusting) |&gt; prop.table(margin = 2) |&gt; addmargins(margin = 1)\n\n                         \n                          Not trusting  Trusting\n  No university education    0.7255278 0.5458886\n  University education       0.2744722 0.4541114\n  Sum                        1.0000000 1.0000000\n\n## In base R (xtabs - formula style):\nxtabs(~ educ_univ + trusting, data = akaeda)\n\n                         trusting\neduc_univ                 Not trusting Trusting\n  No university education        26838    11319\n  University education           10153     9416\n\n#### Proportions by column, rounded to 2 decimals, added column marginal totals\nxtabs(~ educ_univ + trusting, data = akaeda)|&gt; prop.table(margin = 2) |&gt; round(2) |&gt; addmargins(margin = 1)\n\n                         trusting\neduc_univ                 Not trusting Trusting\n  No university education         0.73     0.55\n  University education            0.27     0.45\n  Sum                             1.00     1.00\n\n## In tidyverse (dplyr + tidyr)\n### Frequencies\nakaeda |&gt; \n  group_by(educ_univ, trusting) |&gt; \n  summarise(n=n()) |&gt; \n  spread(trusting, n)\n\n`summarise()` has grouped output by 'educ_univ'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 4\n# Groups:   educ_univ [3]\n  educ_univ               `Not trusting` Trusting `&lt;NA&gt;`\n  &lt;fct&gt;                            &lt;int&gt;    &lt;int&gt;  &lt;int&gt;\n1 No university education          26838    11319    890\n2 University education             10153     9416    434\n3 &lt;NA&gt;                               239      118     31\n\n### Proportions\nakaeda |&gt; \n  group_by(educ_univ, trusting) |&gt; \n  summarise(n=n()) |&gt; \n  mutate(prop=n/sum(n)) |&gt; \n  subset(select=c(\"educ_univ\",\"trusting\",\"prop\")) |&gt; \n  spread(trusting, prop)\n\n`summarise()` has grouped output by 'educ_univ'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 4\n# Groups:   educ_univ [3]\n  educ_univ               `Not trusting` Trusting `&lt;NA&gt;`\n  &lt;fct&gt;                            &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n1 No university education          0.687    0.290 0.0228\n2 University education             0.508    0.471 0.0217\n3 &lt;NA&gt;                             0.616    0.304 0.0799\n\n  # or, for % of education by trust:\n  # spread(educ_univ, prop)\n\n\n## In {datawizard}:\n### Both frequencies and % in a listing format rather than crosstabulated\nakaeda |&gt; \n  data_group(educ_univ) |&gt;\n  data_tabulate(trusting, collapse = TRUE)\n\n# Frequency Table\n\nVariable |                               Group |        Value |     N | Raw % | Valid % | Cumulative %\n---------+-------------------------------------+--------------+-------+-------+---------+-------------\ntrusting | educ_univ (No university education) | Not trusting | 26838 | 68.73 |   70.34 |        70.34\n         |                                     |     Trusting | 11319 | 28.99 |   29.66 |       100.00\n         |                                     |         &lt;NA&gt; |   890 |  2.28 |    &lt;NA&gt; |         &lt;NA&gt;\n---------+-------------------------------------+--------------+-------+-------+---------+-------------\ntrusting |    educ_univ (University education) | Not trusting | 10153 | 50.76 |   51.88 |        51.88\n         |                                     |     Trusting |  9416 | 47.07 |   48.12 |       100.00\n         |                                     |         &lt;NA&gt; |   434 |  2.17 |    &lt;NA&gt; |         &lt;NA&gt;\n---------+-------------------------------------+--------------+-------+-------+---------+-------------\ntrusting |                      educ_univ (NA) | Not trusting |   239 | 61.60 |   66.95 |        66.95\n         |                                     |     Trusting |   118 | 30.41 |   33.05 |       100.00\n         |                                     |         &lt;NA&gt; |    31 |  7.99 |    &lt;NA&gt; |         &lt;NA&gt;\n------------------------------------------------------------------------------------------------------\n\n## In {gtsummary}:\nakaeda |&gt; \n  gtsummary::tbl_cross(educ_univ, trusting,\n                     percent = \"row\",\n                     missing = \"no\")\n\nFALSE observations with missing data have been removed.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npeople can be trusted/can’t be too careful (Q7)\nTotal\n\n\nNot trusting\nTrusting\n\n\n\n\neducational level respondent: recoded (Q81)\n\n\n\n\n\n\n\n\n    No university education\n26,838 (70%)\n11,319 (30%)\n38,157 (100%)\n\n\n    University education\n10,153 (52%)\n9,416 (48%)\n19,569 (100%)\n\n\nTotal\n36,991 (64%)\n20,735 (36%)\n57,726 (100%)\n\n\n\n\n\n\n\n\n\nMultiple regression model without interaction terms\nOur dependent variable (redistribute) can be treated as numeric, so we will fit a linear (ordinary least squares) regression model using the lm() function:\n\nm1 &lt;- lm(redistribute ~ educ_univ + trusting + female + employment + hh_income + married + child + politics, data = akaeda)\n\nLet’s then check the model coefficients (parameters):\n\nmodel_parameters(m1)\n\nParameter                        | Coefficient |       SE |         95% CI | t(40050) |      p\n----------------------------------------------------------------------------------------------\n(Intercept)                      |        4.05 |     0.05 | [ 3.95,  4.15] |    77.35 | &lt; .001\neduc univ [University education] |       -0.50 |     0.03 | [-0.56, -0.44] |   -16.51 | &lt; .001\ntrusting [Trusting]              |        0.30 |     0.03 | [ 0.25,  0.36] |    10.12 | &lt; .001\nfemale [female]                  |        0.14 |     0.03 | [ 0.09,  0.20] |     5.12 | &lt; .001\nemployment [Other]               |    5.89e-03 |     0.05 | [-0.09,  0.10] |     0.12 | 0.901 \nemployment [Retired]             |        0.09 |     0.04 | [ 0.02,  0.16] |     2.62 | 0.009 \nemployment [Self-employed]       |       -0.21 |     0.06 | [-0.33, -0.09] |    -3.54 | &lt; .001\nemployment [Unemployed]          |       -0.20 |     0.06 | [-0.31, -0.09] |    -3.58 | &lt; .001\nhh income                        |        0.03 | 7.73e-03 | [ 0.01,  0.04] |     3.53 | &lt; .001\nmarried [Maried]                 |       -0.16 |     0.03 | [-0.22, -0.09] |    -4.96 | &lt; .001\nchild [Has children]             |       -0.12 |     0.04 | [-0.19, -0.05] |    -3.30 | &lt; .001\npolitics                         |        0.24 | 6.01e-03 | [ 0.22,  0.25] |    39.30 | &lt; .001\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation.\n\n\n\n\nModel with an interaction between education and social trust\nWe can interact predictor variables in regression models using the : and * operators. With :, we include in the regression model only the interaction term, but not the component variables (i.e. their main effects); to include the component variables as well, we need to add them in as usual with the + operator. To note that we should normally want to include both main effects and and the interaction effects in a regression model. With *, we include both the main effects and the interaction effects, so it provides a shortcut to using :, but it is often useful to combine the two in more complex interaction scenarios.\nThe specifications below are equivalent:\n\n# Interaction using \":\"\n# including the constituent terms must be done manually\nm2 &lt;- lm(redistribute ~ educ_univ + trusting + educ_univ:trusting + female + employment + hh_income + married + child + politics, data = akaeda)\n\n# Interaction using \"*\"\n# including the constituent terms is done automatically\nm2 &lt;- lm(redistribute ~                        educ_univ*trusting + female + employment + hh_income + married + child + politics, data = akaeda)\nm2 &lt;- lm(redistribute ~ educ_univ + trusting + educ_univ*trusting + female + employment + hh_income + married + child + politics, data = akaeda)\n\nBut the one below is missing the constituent terms and is very likely not what we want:\n\nm2_wrong &lt;- lm(redistribute ~                  educ_univ:trusting + female + employment + hh_income + married + child + politics, data = akaeda)\n\nOut of precaution, it is advisable to use the * operator and to manually include all the constituent terms as well, as in the third version above.\nLet’s then check the model coefficients (parameters):\n\nmodel_parameters(m2)\n\nParameter                                              | Coefficient |       SE |         95% CI | t(40049) |      p\n--------------------------------------------------------------------------------------------------------------------\n(Intercept)                                            |        4.13 |     0.05 | [ 4.02,  4.23] |    77.15 | &lt; .001\neduc univ [University education]                       |       -0.68 |     0.04 | [-0.76, -0.60] |   -17.06 | &lt; .001\ntrusting [Trusting]                                    |        0.15 |     0.04 | [ 0.07,  0.22] |     3.86 | &lt; .001\nfemale [female]                                        |        0.14 |     0.03 | [ 0.09,  0.20] |     5.00 | &lt; .001\nemployment [Other]                                     |   -1.39e-03 |     0.05 | [-0.09,  0.09] |    -0.03 | 0.976 \nemployment [Retired]                                   |        0.09 |     0.04 | [ 0.02,  0.16] |     2.47 | 0.013 \nemployment [Self-employed]                             |       -0.21 |     0.06 | [-0.33, -0.10] |    -3.59 | &lt; .001\nemployment [Unemployed]                                |       -0.21 |     0.06 | [-0.32, -0.10] |    -3.82 | &lt; .001\nhh income                                              |        0.02 | 7.75e-03 | [ 0.01,  0.04] |     2.94 | 0.003 \nmarried [Maried]                                       |       -0.15 |     0.03 | [-0.22, -0.09] |    -4.90 | &lt; .001\nchild [Has children]                                   |       -0.12 |     0.04 | [-0.20, -0.05] |    -3.48 | &lt; .001\npolitics                                               |        0.24 | 6.01e-03 | [ 0.22,  0.25] |    39.14 | &lt; .001\neduc univ [University education] × trusting [Trusting] |        0.41 |     0.06 | [ 0.29,  0.52] |     6.98 | &lt; .001\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation.\n\n\nWe can compare our results with those reported in Model 3 (Table 2) of Akaeda (2023), keeping in mind that our data are very different. Nonetheless, we find a similar positive effect for the interaction term (0.41), which in our case is stronger.\n\n\nInterpreting interactions\nAs with results from logistic regression models, interpreting interaction results is not straightforward.\nFirst of all, the coefficients associated with the individual variables included in the interaction term can no longer be interpreted in the usual direct way, and we usually no longer interpret the “main effects” of educ_univ and trusting, but only the multiplicative effect of the interaction between them. The interpretation of the numeric results, however, is rather convoluted and prone to lead to misinterpretations. In essence, what we get is the effect of a unit-change in trust among the university-educated compared to the effect of a unit-change in trust among the non-university-educated.\nAs with interpreting logistic regression, it can be much easier and reliable to interpret a plot of the “marginal effects”. As we already know from Lab 4, that can be achieved using the ggpredict() and the plot() functions, and we would add both constitutive terms of the interaction. Depending on which variable we write first we get either the effect of trust by education, or the effect of education by trust:\nEducation by trust:\n\nggpredict(m2, terms = c(\"educ_univ\", \"trusting\")) |&gt; \n  plot()\n\n\n\n\n\n\n\n\nTrust by education:\n\nggpredict(m2, terms = c(\"trusting\", \"educ_univ\")) |&gt; \n  plot()\n\n\n\n\n\n\n\n\nThe latter plot reproduces Figure 1 from Akaeda (2023). To get an even closer reproduction of that Figure, we could add an additional argument to the plotting function, asking for the point-predictions to be connected with lines:\n\nggpredict(m2, terms = c(\"trusting\", \"educ_univ\")) |&gt; \n  plot(connect.lines = TRUE)\n\n\n\n\n\n\n\n\nLooking at whether and how much the confidence intervals of the predicted coefficients overlap with the point-predictions of the coefficients, we can visually asses the interaction effect. We find that positive differences in the level of social trust have a much steeper effect on redistributive attitudes among the highly educated than it does among the lower educated.",
    "crumbs": [
      "Materials",
      "Week 4",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w04.html#example-2.-osterman2021canwetrusteducationfostering-do-educational-reforms-have-different-effects-by-levels-of-parental-education",
    "href": "materials/notes/notes_w04.html#example-2.-osterman2021canwetrusteducationfostering-do-educational-reforms-have-different-effects-by-levels-of-parental-education",
    "title": "Week 4 Worksheet Notes",
    "section": "Example 2. Österman (2021): Do educational reforms have different effects by levels of parental education?",
    "text": "Example 2. Österman (2021): Do educational reforms have different effects by levels of parental education?\nThis research question is at the core of the study conducted by Österman (2021). We have explored this article and used its data to fit simple binary and multiple regression models in Week 2. We can now take that analysis further and replicate some of the models reported in Table 3 of that article:\n\n\n\nOsterman 2021, Table 3\n\n\nAs our main interest is not so much on their substantive findings regarding the complex effects of different types of educational reforms, but rather on seeing interaction effects operating in real-life data, we will focus on Models 1-3 (All reforms). The main difference compared to the previous example is conceptual: the variable “Reform” is meant to distinguish between respondents who were affected by a major reform of the secondary education system in their countries during their schooling years, or not. This allows the researcher to posit a “quasi-experimental” scenario, in which being exposed to a “reform” can be interpreted in a more causal way, as in an experimental setting. The “reform”, thus, can be thought of as a “treatment” in an experiment, so the examining its statistical effect can be taken to have a more reliably causal interpretation that when exploring associations between purely “descriptive” variables. Technically, however, the models we fit are no different to those in the previous example.\n\nData preparation\nAs a first step, let’s import the osterman dataset that underpins the Österman (2021) article (see the Data page on the course website for information about the datasets available in this course). We can download the data to a local folder and load it from there, or we can load it directly from the web (if it works…):\n\n# Import the data\nosterman &lt;- data_read(\"https://cgmoreh.github.io/HSS8005-24/data/osterman.dta\")\n\nIt’s always a good idea to inspect the dataset after importing, to identify any issues. One option is to check a codebook, for example:\n\n# `View` the codebook:\ndata_codebook(osterman) |&gt; View()\n\nRemember that some “tagged” NA values that were imported from the Stata data format need changing (see Week 2 worksheet):\n\nosterman &lt;- sjlabelled::zap_na_tags(osterman)\n\n\n\nModel 1 redux: no covariates\nWe start by fitting a simplified version of Model1 (in Table 3 of Österman (2021)). The reported model contains the variables highlighted in the table (“Reform”, “Female” and “Ethnic minority”) as well as a number of additional covariates for statistical control (fbrneur, mbrneur, fnotbrneur, mnotbrneur, agea, essround, yrbrn, eform_id_num, including “self-interactions” and interactions between some of those control variables: yrbrn*yrbrn, yrbrn*reform_id_num, agea*reform_id_num, agea*agea, agea*agea*reform_id_num). The model is also adjusted for sampling weights (dweight) and the standard errors are clustered in “country-by-birth year cohort” groups (see Österman (2021)[pp. 222] for their reasoning for this modelling choice; we will discuss this aspect of the data in more detail when we consider multilevel models).\nHere we will first fit a much simplified model that only includes the few variables highlighted in the table, without any additional control variables, weighting or clustering.\nModel 1 doesn’t include an interaction, so it is a simple multiple linear regression model:\n\nosterman_m1 &lt;- lm(trustindex3 ~ reform1_7 + female + blgetmg_d, data = osterman)\n\n# Print model parameters, with digits rounded to three decimal points\nmodel_parameters(osterman_m1, digits = 3)\n\nParameter   | Coefficient |    SE |           95% CI | t(68792) |      p\n------------------------------------------------------------------------\n(Intercept) |       5.251 | 0.013 | [ 5.226,  5.276] |  412.067 | &lt; .001\nreform1 7   |      -0.008 | 0.015 | [-0.037,  0.020] |   -0.560 | 0.576 \nfemale      |       0.007 | 0.015 | [-0.021,  0.036] |    0.493 | 0.622 \nblgetmg d   |      -0.478 | 0.060 | [-0.595, -0.361] |   -8.010 | &lt; .001\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation.\n\n\nWe find that without the additional model specifications, our results are quite different from those reported in the article. The “Reform” effect is much weaker and in the opposite direction, losing its statistical significance (p = 0.576). The effect of “Female” is also weaker and statistically not significant. On the other hand, belonging to an “ethnic minority group” has a stronger and clearer effect in this simplified model.\nAs a next step, we aim to expand the model by including all the specified covariates. This, however, will bring up an R coding challenge which can also serve as an introduction to the concept of polynomial terms.\n\nProblem 1: Polynomials\nIn the footnotes to Table 3 and Table A.3 in the Appendix, the author tells us:\n\nAll models include reform FEs [Fixed Effects], a general quadratic birth year trend, and reform-specific trends for birth year (linear) and age (quadratic). Additional controls: foreign-born parents and ESS round dummies.\n\nThe tables in the Appendix (Table A.3) “report all of the coefficients for the control variables, except for the age and birth year controls. Since the latter variables are interacted with all of the reform fixed effects, they are not interpretable as single coefficients”.\nIn the main text, the author further explains some of the reasoning behind their modelling choices:\n\nOne dilemma for the design is that there has been a trend of increasing educational attainment throughout the studied time period, which means that the reform-windows of treated and non-treated cohorts will also pick up the effects of this trend. To counter this, [the list of covariates] includes a general quadratic birth year trend, reform-specific linear controls for birth year and reform-specific quadratic age trends. The quadratic terms are included to allow sufficient flexibility in absorbing possible non-linear trends of increasing education within the reform-window of seven treated and seven untreated birth year cohorts. … The reform-fixed effects are also essential because they imply that only the within-reform-window variation is used to estimate the effects and between-reform differences are factored out, such as pre-reform differences in social trust. (Österman 2021:221–22)\n\nBefore we fit the model, some of the concepts in the quotation need unpacking. A quadratic term is a second-degree polynomial term: put simply, it’s the square of the variable concerned. The quadratic of a variable such as \\(age\\) is therefore \\(age^2\\), or \\(age \\times age\\). In other words, it is like a variable’s “interaction” with itself. Because of this, there are several ways in which the quadratic terms to be included in a model can be specified:\n\nWe could create the quadratic terms as new variables, and include those in the model. Effectively, we would be creating new variables/columns in the dataset and using those in the model. We could do that as shown below:\n\n\n# Create new quadratic variables by multiplication with themselves and add them to the dataset, saving it as a new data object:\n\nosterman &lt;- osterman |&gt; \n  mutate(agea_quad = agea*agea,                                                         # quadratic age variable\n         yrbrn_quad = yrbrn*yrbrn) |&gt;                                                   # quadratic birth-year variable\n  sjlabelled::var_labels(agea_quad = \"Age (quadratic)\",                                 # we can label the variable if we want\n                        yrbrn_quad = \"Birth year (quadratic)\")\n\n# We now have two additional variables in the dataset; we can fit a model using those:\n\nm1_prequad &lt;- lm(trustindex3 ~ reform1_7 + female + blgetmg_d +                         # main covariates reported in Table 3\n                   fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) +     # additional controls for foreign-born parents and ESS Round dummies (we treat `round` as a factor for this)\n                   agea + yrbrn + agea_quad + yrbrn_quad +                              # general quadratic birth year trend and quadratic age\n                   factor(reform_id_num) +                                              # reform fixed effects dummies\n                   yrbrn:factor(reform_id_num) +                                        # reform-specific birth year trend\n                   agea:factor(reform_id_num) +  agea_quad:factor(reform_id_num),       # reform-specific quadratic age trend\n               data = osterman)                                                         # the new expanded dataset\n\n\nWe can get the same results by creating the quadratic terms directly as part of the modelling function. The one thing we should keep in mind is that if we want to include standard mathematical operations within a formula function, we need to isolate or insulate the operation from R’s formula parsing code using the I() function, which returns the contents of I(...) “as.is”. The model formula would then be:\n\n\n# Create quadratic terms internally as part of the modelling function:\n\nm1_funquad &lt;- lm(trustindex3 ~ reform1_7 + female + blgetmg_d +                         # main covariates reported in Table 3\n                 fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) +       # additional controls for foreign-born parents and ESS Round dummies (we treat `round` as a factor for this)\n                 agea + yrbrn + I(agea^2) + I(yrbrn^2) +                                # general quadratic birth year trend and quadratic age\n                 factor(reform_id_num) +                                                # reform fixed effects dummies\n                 yrbrn:factor(reform_id_num) +                                          # reform-specific birth year trend\n                 agea:factor(reform_id_num) +  I(agea^2):factor(reform_id_num),         # reform-specific quadratic age trend\n              data = osterman)                                                          # the original dataset\n\n\nIn the two previous options, the quadratic terms will be correlated with the original variables. To avoid this by relying on so-called orthogonal polynomials we should use the poly() function. We can also fit the same correlated polynomial model as the ones above by adding the raw = TRUE option to the poly() function. In the code below, we will fit the correlated version first, then the orthogonal version (This stackoverflow discussion explains in more detail the difference between the two options):\n\n\nm1_polyraw &lt;- lm(trustindex3 ~ reform1_7 + female + blgetmg_d + \n                 fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) + \n                 poly(agea, 2, raw = TRUE) + poly(yrbrn, 2, raw = TRUE) +\n                 factor(reform_id_num) +           \n                 yrbrn:factor(reform_id_num) + \n                 agea:factor(reform_id_num) + poly(agea, 2, raw = TRUE):factor(reform_id_num),\n               data = osterman)\n\nm1_polyorth &lt;- lm(trustindex3 ~ reform1_7 + female + blgetmg_d + \n                 fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) + \n                 poly(agea, 2) + poly(yrbrn, 2) +\n                 factor(reform_id_num) +           \n                 yrbrn:factor(reform_id_num) + \n                 agea:factor(reform_id_num) + poly(agea, 2):factor(reform_id_num),\n               data = osterman)\n\nFor a side-by-side overview comparison of the models we fitted so far, we can use one of the many model summary tabulation functions that exist in various packages. Some popular options are stargazer::stargazer(), jtools::export_summs(), sjPlot::tab_model(), modelsummary::modelsummary() or parameters::compare_models from the {easystats} ecosystem. Below we will use modelsummary(), which produces publication-ready summary tables in HTML format, but which can easily be exported to other formats, such as Microsoft Word or PDF:\n\n# It's cleaner to first make a list of the models we want to summarise; we can even name them:\nmodels &lt;- list(\n  \"Pre-calculated quadratic\" = m1_prequad,\n  \"Within-function quadratic\" = m1_funquad,\n  \"poly() with raw coding\" = m1_polyraw,\n  \"poly() with default orthogonal coding\" = m1_polyorth\n)\n\n# modelsummary table with stars for p-values added\nmodelsummary::modelsummary(models, stars = TRUE)\n\nThe results from the modelsummary() are not shown here because it’s a long and ugly table, but it’s useful for perusing to compare the results across the different models. We do notice some differences in the affected variables between the orthogonal-coded version and the others. It’s worth noting, however, that the Stata routine used by the author fitted correlated/raw-coded polynomials, so the orthogonal version from the output above is just for a comparison and we will not use it going forward. We generally want our transformed (polynomial) variables to be correlated with the original variables, as they are in fact measuring the same thing.\nFor a cleaner table showing only the results included in Table A.3 in the Appendix to Österman (2021), we can use the coef_map or the coef_omit option in modelsummary() and only include m1_funquad, which will be the polynomial fitting routine that we will use going forward:\n\n# It's cleaner to first make a vector of the coefficients we wish to include; we can name the coefficients as they appear in Table A.3; note that we also leave out the Intercept, as in the published table:\ncoefs &lt;- c(\"reform1_7\" = \"Reform\",\n           \"female\" = \"Female\",\n           \"blgetmg_d\" = \"Ethnic minority\",\n           \"fbrneur\" = \"Foreign-born father, Europe\",\n           \"mbrneur\" = \"Foreign-born mother, Europe\",\n           \"fnotbrneur\" = \"Foreign-born father, outside Europe\",\n           \"mnotbrneur\" = \"Foreign-born mother, outside Europe\",\n           \"factor(essround)2\" = \"ESS Round 2\",\n           \"factor(essround)3\" = \"ESS Round 3\",\n           \"factor(essround)4\" = \"ESS Round 4\",\n           \"factor(essround)5\" = \"ESS Round 5\",\n           \"factor(essround)6\" = \"ESS Round 6\",\n           \"factor(essround)7\" = \"ESS Round 7\",\n           \"factor(essround)8\" = \"ESS Round 8\",\n           \"factor(essround)9\" = \"ESS Round 9\")\n\n# Then we pass the vector to coef_map to select the coefficients to print\nmodelsummary::modelsummary(list(m1_funquad), stars = TRUE, coef_map = coefs)\n\n\n\n\n\n (1)\n\n\n\n\nReform\n0.063*\n\n\n\n(0.027)\n\n\nFemale\n0.058***\n\n\n\n(0.013)\n\n\nEthnic minority\n−0.241***\n\n\n\n(0.054)\n\n\nForeign-born father, Europe\n−0.111**\n\n\n\n(0.042)\n\n\nForeign-born mother, Europe\n−0.108*\n\n\n\n(0.044)\n\n\nForeign-born father, outside Europe\n−0.065\n\n\n\n(0.073)\n\n\nForeign-born mother, outside Europe\n−0.110\n\n\n\n(0.078)\n\n\nESS Round 2\n0.059\n\n\n\n(0.045)\n\n\nESS Round 3\n0.162*\n\n\n\n(0.075)\n\n\nESS Round 4\n0.243*\n\n\n\n(0.108)\n\n\nESS Round 5\n0.360*\n\n\n\n(0.144)\n\n\nESS Round 6\n0.397*\n\n\n\n(0.179)\n\n\nESS Round 7\n0.449*\n\n\n\n(0.212)\n\n\nESS Round 8\n0.655**\n\n\n\n(0.246)\n\n\nESS Round 9\n0.816**\n\n\n\n(0.283)\n\n\nNum.Obs.\n68796\n\n\nR2\n0.200\n\n\nR2 Adj.\n0.198\n\n\nAIC\n268913.8\n\n\nBIC\n270056.1\n\n\nLog.Lik.\n−134331.877\n\n\nRMSE\n1.71\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\nWe can compare our table to the published one; there will, of course, be some differences, as our model specification is still not the same as that of the original paper. One source of the inconsistencies are the use of “survey weights” in the original article, something we will look into in Week 6.\n\n\n\nModel 2\nModel 2 includes two additions: an extra predictor for “High Parental Education”, as well as an interaction effect between “Reform” and “High parental education”. As in the previous example, we can fit the model like so:\n\nosterman_m2 &lt;- lm(trustindex3 ~ reform1_7 + paredu_a_high + reform1_7*paredu_a_high + female + blgetmg_d + # main covariates reported in Table 3\n                 fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) +       # additional controls for foreign-born parents and ESS Round dummies (we treat `round` as a factor for this)\n                 agea + yrbrn + I(agea^2) + I(yrbrn^2) +                                # general quadratic birth year trend and quadratic age\n                 factor(reform_id_num) +                                                # reform fixed effects dummies\n                 yrbrn:factor(reform_id_num) +                                          # reform-specific birth year trend\n                 agea:factor(reform_id_num) +  I(agea^2):factor(reform_id_num),         # reform-specific quadratic age trend\n              data = osterman)                                                          # the original dataset\n\nWe can now select the coefficients we want to display in the table and create a summary table comparing the results from Model 1 and Model 2 side by side:\n\ncoefs_m2 &lt;- c(\"reform1_7\" = \"Reform\",\n              \"paredu_a_high\" = \"High parental edu\",\n              \"reform1_7:paredu_a_high\" = \"Ref x High par edu\",\n           \"femaleFemale\" = \"Female\",\n           \"blgetmg_d\" = \"Ethnic minority\",\n           \"fbrneur\" = \"Foreign-born father, Europe\",\n           \"mbrneur\" = \"Foreign-born mother, Europe\",\n           \"fnotbrneur\" = \"Foreign-born father, outside Europe\",\n           \"mnotbrneur\" = \"Foreign-born mother, outside Europe\")\n\n# Print model parameters, with digits rounded to three decimal points\nmodelsummary::modelsummary(list(m1_funquad, osterman_m2), stars = TRUE, coef_map = coefs_m2)\n\n\n\n\n\n (1)\n  (2)\n\n\n\n\nReform\n0.063*\n0.081**\n\n\n\n(0.027)\n(0.029)\n\n\nHigh parental edu\n\n0.349***\n\n\n\n\n(0.020)\n\n\nRef x High par edu\n\n−0.049+\n\n\n\n\n(0.029)\n\n\nEthnic minority\n−0.241***\n−0.207***\n\n\n\n(0.054)\n(0.056)\n\n\nForeign-born father, Europe\n−0.111**\n−0.106*\n\n\n\n(0.042)\n(0.044)\n\n\nForeign-born mother, Europe\n−0.108*\n−0.115*\n\n\n\n(0.044)\n(0.046)\n\n\nForeign-born father, outside Europe\n−0.065\n−0.047\n\n\n\n(0.073)\n(0.076)\n\n\nForeign-born mother, outside Europe\n−0.110\n−0.135+\n\n\n\n(0.078)\n(0.081)\n\n\nNum.Obs.\n68796\n64960\n\n\nR2\n0.200\n0.209\n\n\nR2 Adj.\n0.198\n0.208\n\n\nAIC\n268913.8\n252985.1\n\n\nBIC\n270056.1\n254138.4\n\n\nLog.Lik.\n−134331.877\n−126365.537\n\n\nRMSE\n1.71\n1.69\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\nWhile the results of our Model 2 still differ from those reported based on a more complex model, we find that our estimates are much closer now, with all the coefficients pointing in the same direction as in the reported model, including the interaction effect of “Reform” by “High parental education”. Because the two variables involved in this interaction are both simple binary, indicator, variables (coded 0 and 1) it is possible to make (some) sense of these results. Compared to the “main” effects shown in the previous model, the coefficient for “Reform” now refers to the effect of the reforms among individuals with poorly educated parents (coded 0) only. The interaction coefficient shows, by contrast, the difference in the effect of “Reform” for those with highly educated parents (coded 1). In this case, the negative coefficient shows that in the case of those with highly educated parents, the effect of educational “reforms” is smaller.\nWe can check more closely the meaning of the interaction effect using a marginal plot:\n\nggpredict(osterman_m2, terms = c(\"reform1_7\", \"paredu_a_high\")) |&gt; \n  plot(connect.lines = TRUE)\n\n\n\n\n\n\n\n\nThis visualization in now easier to interpret than the numerical output. a steeper effect among those whose parents were highly educated compared to those whose parents had lower education, however, we can also see more clearly that the effect of educational reforms within the two groups is actually in the opposite direction: among those with lower parental education, educational reforms are associated with higher levels of trust, while among those with lower parental education, the effect is in the opposite direction.\nModel 3 is different from Model 2 in that it includes interaction terms not only between “Reform” and “High parental education”, but Parental education is also interacted with all the other covariates that we did not include in our models.",
    "crumbs": [
      "Materials",
      "Week 4",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w07.html",
    "href": "materials/notes/notes_w07.html",
    "title": "Week 7 Worksheet Notes",
    "section": "",
    "text": "By the end of the session you will learn how to:\n\nfit random-intercepts and random coefficients models to hierarchical data that contains a temporal dimension\nuse several R packages for modelling time-series data",
    "crumbs": [
      "Materials",
      "Week 7",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w07.html#aims",
    "href": "materials/notes/notes_w07.html#aims",
    "title": "Week 7 Worksheet Notes",
    "section": "",
    "text": "By the end of the session you will learn how to:\n\nfit random-intercepts and random coefficients models to hierarchical data that contains a temporal dimension\nuse several R packages for modelling time-series data",
    "crumbs": [
      "Materials",
      "Week 7",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w07.html#r-packages",
    "href": "materials/notes/notes_w07.html#r-packages",
    "title": "Week 7 Worksheet Notes",
    "section": "R packages",
    "text": "R packages\n\n# Just in case we get errors asking that the package repositories be explicitly set when installing new packages:\n\noptions(repos = list(CRAN = \"http://cran.rstudio.com/\"))\n\n# Install and load required packages\n\n# We can use the {pacman} package to easily install and load several packages:\n# ({pacman} itself may need installing if not yet installed)\n\npacman::p_load(\n  tidyverse, sjlabelled, easystats, \n  ggformula, ggeffects, marginaleffects, \n  modelsummary, gtsummary, sjPlot,\n  survey, sandwich, lmtest, lme4,            # for general hierarchical modelling\n  panelr, plm, pglm)                         # for time-series hierarchical data structures",
    "crumbs": [
      "Materials",
      "Week 7",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w07.html#example-1-basic-tabulations-of-hierarchical-and-time-series-structures",
    "href": "materials/notes/notes_w07.html#example-1-basic-tabulations-of-hierarchical-and-time-series-structures",
    "title": "Week 7 Worksheet Notes",
    "section": "Example 1: basic tabulations of hierarchical and time-series structures",
    "text": "Example 1: basic tabulations of hierarchical and time-series structures\nLet’s import this simulated toy dataset:\n\ntest &lt;- data_read(\"https://cgmoreh.github.io/HSS8005-24/data/test.dta\")\n\nReading data...\n\n\nVariables where all values have associated labels are now converted into\n  factors. If this is not intended, use `convert_factors = FALSE`.\n\n\n1 out of 9 variables were fully labelled and converted into factors.\n\n\nwe can peek at the data to get a feel for the variables:\n\ndatawizard::data_peek(test) |&gt; print_md()\n\n\nData frame with 375 rows and 9 variables\n\n\nVariable\nType\nValues\n\n\n\n\nteacher\nnumeric\n1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\n\nstudent\nnumeric\n1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, …\n\n\nage\nnumeric\n14, 15, 16, 17, 18, 14, 15, 16, 17, 18, 14, …\n\n\ncage\nnumeric\n-2, -1, 0, 1, 2, -2, -1, 0, 1, 2, -2, -1, 0, …\n\n\nsex\nfactor\nMale, Male, Male, Male, Male, Male, …\n\n\nscore\nnumeric\n64, 68, 69, 71, 75, 58, 60, 71, 69, 72, 54, …\n\n\npass\nnumeric\n0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, …\n\n\nexperience\nnumeric\n5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, …\n\n\nzero\nnumeric\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\n\n\n\nWe can also check the first few and last few observations in a dataframe using the head() and tail() functions included in base-R. The {gt} package also has a nice function (gt_preview()) that can do the same more flexibly and output it as a single table:\n\ngt::gt_preview(test, top_n = 3, bottom_n = 3, incl_rownums = TRUE)\n\n\n\n\n\n\n\n\nteacher\nstudent\nage\ncage\nsex\nscore\npass\nexperience\nzero\n\n\n\n\n1\n1\n1\n14\n-2\nMale\n64\n0\n5\n0\n\n\n2\n1\n1\n15\n-1\nMale\n68\n0\n5\n0\n\n\n3\n1\n1\n16\n0\nMale\n69\n0\n5\n0\n\n\n4..372\n\n\n\n\n\n\n\n\n\n\n\n373\n3\n75\n16\n0\nFemale\n81\n1\n8\n0\n\n\n374\n3\n75\n17\n1\nFemale\n85\n1\n8\n0\n\n\n375\n3\n75\n18\n2\nFemale\n86\n1\n8\n0\n\n\n\n\n\n\n\nThis allows us to see more clearly how teachers, students and ages relate to each other and how they are nested.\nTo check more directly the number of students and teachers in the dataset, we could use the n_unique() function from {dplyr} in the {tidyverse}:\n\nn_unique(test$student)\n\n[1] 75\n\nn_unique(test$teacher)\n\n[1] 3\n\n\nWe can also check the distribution of the variables; we can break the sex variable (a categorical variable) into its two constituent categories and treat it as numeric for this purpose:\n\ntest |&gt; datawizard::to_numeric() |&gt; \n  datawizard::describe_distribution()\n\nVariable   |  Mean |    SD | IQR |          Range | Skewness | Kurtosis |   n | n_Missing\n-----------------------------------------------------------------------------------------\nteacher    |  2.00 |  0.82 |   2 |   [1.00, 3.00] |     0.00 |    -1.50 | 375 |         0\nstudent    | 38.00 | 21.68 |  38 |  [1.00, 75.00] |     0.00 |    -1.20 | 375 |         0\nage        | 16.00 |  1.42 |   2 | [14.00, 18.00] |     0.00 |    -1.30 | 375 |         0\ncage       |  0.00 |  1.42 |   2 |  [-2.00, 2.00] |     0.00 |    -1.30 | 375 |         0\nsex.Female |  0.51 |  0.50 |   1 |   [0.00, 1.00] |    -0.03 |    -2.01 | 375 |         0\nsex. Male  |  0.49 |  0.50 |   1 |   [0.00, 1.00] |     0.03 |    -2.01 | 375 |         0\nscore      | 68.71 |  7.20 |  10 | [51.00, 87.00] |     0.14 |    -0.28 | 375 |         0\npass       |  0.39 |  0.49 |   1 |   [0.00, 1.00] |     0.46 |    -1.80 | 375 |         0\nexperience |  6.33 |  1.25 |   3 |   [5.00, 8.00] |     0.38 |    -1.50 | 375 |         0\nzero       |  0.00 |  0.00 |   0 |   [0.00, 0.00] |          |          | 375 |         0\n\n\nFinally, it’s worth looking at the timeline of how test scores change across time (i.e. ages) for\n\nggplot(test, aes(x= age, score)) +\n  theme_bw() +\n  geom_line(aes(group= student), color= \"blue\")",
    "crumbs": [
      "Materials",
      "Week 7",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w07.html#example-2-mitchell2021socialtrustantiimmigrant-longitudinal-multi-level-analysis",
    "href": "materials/notes/notes_w07.html#example-2-mitchell2021socialtrustantiimmigrant-longitudinal-multi-level-analysis",
    "title": "Week 7 Worksheet Notes",
    "section": "Example 2: (Mitchell 2021): longitudinal multi-level analysis",
    "text": "Example 2: (Mitchell 2021): longitudinal multi-level analysis\nThe article by Mitchell (2021) uses the European Social Survey (2002–2016) to test how differences in social trust, both within and between countries influence attitudes about immigrants. The ESS is a cross-national survey with representative samples of 34 countries, all of them are included in this study. Three items were included in each of the eight waves of the ESS to measure attitudes about immigrants:\n\n“Would you say it is generally bad or good for [country]’s economy that people come to live here from other countries?” (0= “Bad for the economy,” 10 = “Good for the economy”).\n“Would you say that [country]’s cultural life is generally undermined or enriched by people coming to live here from other countries?” (0 = “Cultural life undermined,” 10= “Cultural life enriched”).\n“Is [country] made a worse or a better place to live by people coming to live here from other countries?,” (0= “Worse place to live,” 10 = “Better place to live”).\n\nAn index was created by averaging responses to each of the three questions.\nThe main independent variable measures generalized trust. At the individual level, trust is measured through the question, “generally speaking, would you say that most people can be trusted, or that you can’t be too careful in dealing with people?” On a 10 point scale (0= “You cant be too careful,” 10= “most people can be trusted”). To isolate individuals’ trust levels in a way that is relative to the respondents’ country, responses were centered against the average level of generalized trust in that country at that time. This means that, the variable included in the analysis is the level of difference people say that they can trust others, compared to others in their country during the survey wave.\nDue to the structure of the data, a multi-level modeling approach that nests respondents inside of country-years and counties was employed for this study. This allows for both the estimation of the relationship between contextual variables of interest and anti-immigrant attitudes both cross-sectionally and longitudinally. Since the responses to the surveys are in part dependent on the groups that the respondents belong, models that accommodate for this country and country-year grouping are better suited for this analysis than models with no grouping structure.\nThe analysis follows a model building approach where Model 1 is an “empty” model for the dependent variable and its nesting structure in the three level model. Model 2 tests the relationship between the individual level independent variables and the dependent variable measuring respondents’ attitudes about immigrants. Model 3 adds the country level independent variables, including country level social trust. In the first three models random intercepts are used in estimation, and Model 4 adds random slopes to the estimates in the three- level models. These models are presented in Table 1 of the article (see there).\nFirst we load the already prepared dataset:\n\nmitchell &lt;- data_read(\"https://cgmoreh.github.io/HSS8005-24/data/mitchell2021.rds\")\n\nReading data...\n\n\nVariables where all values have associated labels are now converted into\n  factors. If this is not intended, use `convert_factors = FALSE`.\n\n\n18 out of 70 variables were fully labelled and converted into factors.\n\n\nFollowing 1 variables are empty:\n  edulvlb\n  \nUse `remove_empty_columns()` to remove them from the data frame.\n\n\n\nModel 1:\n\n#Null model ------------------------------------------------------------------------------------------------------\nm1  &lt;- lmer(immatt~ 1 + \n            (1|cntry/cntryyr), data=mitchell)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00277535 (tol = 0.002, component 1)\n\nm1.1&lt;- lmer(immatt~ 1 + \n              (1|cntry), data=mitchell)\n\nm1.2&lt;- lmer(immatt~ 1 + \n              (1|cntryyr), data=mitchell)\n\nm1.3&lt;- lmer(immatt~ 1 + \n              (1|cntry) +\n              (1|cntry:cntryyr),\n            data=mitchell)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00277535 (tol = 0.002, component 1)\n\nm1.4&lt;- lmer(immatt~ 1 + \n              (1|cntry) +\n              (1|cntryyr:cntry),\n            data=mitchell)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00277535 (tol = 0.002, component 1)\n\nsummary(m1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: immatt ~ 1 + (1 | cntry/cntryyr)\n   Data: mitchell\n\nREML criterion at convergence: 1334089\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.3198 -0.6271  0.0599  0.6635  3.5527 \n\nRandom effects:\n Groups        Name        Variance Std.Dev.\n cntryyr:cntry (Intercept) 0.07828  0.2798  \n cntry         (Intercept) 0.61843  0.7864  \n Residual                  4.03754  2.0094  \nNumber of obs: 314934, groups:  cntryyr:cntry, 200; cntry, 34\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   4.9262     0.1368   36.02\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00277535 (tol = 0.002, component 1)\n\nparameters::compare_models(m1, m1.1, m1.2, m1.3, effects = \"all\")\n\n# Fixed Effects\n\nParameter   |                m1 |              m1.1 |              m1.2 |              m1.3\n-------------------------------------------------------------------------------------------\n(Intercept) | 4.93 (4.66, 5.19) | 4.92 (4.65, 5.19) | 4.99 (4.88, 5.10) | 4.93 (4.66, 5.19)\n\n# Random Effects\n\nParameter                     |        m1 |      m1.1 |      m1.2 |      m1.3\n-----------------------------------------------------------------------------\nSD (Residual)                 | 2.01 (, ) | 2.03 (, ) | 2.01 (, ) | 2.01 (, )\nSD (Intercept: cntry)         | 0.79 (, ) | 0.80 (, ) |           | 0.79 (, )\nSD (Intercept: cntryyr:cntry) | 0.28 (, ) |           |           |          \nSD (Intercept: cntryyr)       |           |           | 0.76 (, ) |          \nSD (Intercept: cntry:cntryyr) |           |           |           | 0.28 (, )\n\nmodelsummary::modelsummary(list(\"cntry/cntryyr\" = m1, m1.1, m1.2, m1.3, \"cntry+cntryyr:cntry\" = m1.4))\n\n\n\n\n\ncntry/cntryyr\n\n\n\ncntry+cntryyr:cntry\n\n\n\n\n(Intercept)\n4.926\n4.918\n4.990\n4.926\n4.926\n\n\n\n(0.137)\n(0.138)\n(0.054)\n(0.137)\n(0.137)\n\n\nSD (Observations)\n2.009\n2.025\n2.009\n2.009\n2.009\n\n\nSD (Intercept cntry)\n0.786\n0.804\n\n0.786\n0.786\n\n\nSD (Intercept cntryyrcntry)\n0.280\n\n\n\n0.280\n\n\nSD (Intercept cntryyr)\n\n\n0.763\n\n\n\n\nSD (Intercept cntrycntryyr)\n\n\n\n0.280\n\n\n\nNum.Obs.\n314934\n314934\n314934\n314934\n314934\n\n\nR2 Marg.\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nR2 Cond.\n0.147\n0.136\n0.126\n0.147\n0.147\n\n\nAIC\n1334097.2\n1338521.2\n1334365.6\n1334097.2\n1334097.2\n\n\nBIC\n1334139.9\n1338553.2\n1334397.6\n1334139.9\n1334139.9\n\n\nICC\n0.1\n0.1\n0.1\n0.1\n0.1\n\n\nRMSE\n2.01\n2.03\n2.01\n2.01\n2.01\n\n\n\n\n\n\n\n\n\nModel 2:\n\n#Model with individual level variables ----------------------------------------------------------------------------------\nm2&lt;-lmer(immatt~  ppltrustd+ young+ old + university + gndr+ hincfel+ lrscale+(1|cntry)+  (1|cntryyr), data=mitchell)\nsummary(m2)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: immatt ~ ppltrustd + young + old + university + gndr + hincfel +  \n    lrscale + (1 | cntry) + (1 | cntryyr)\n   Data: mitchell\n\nREML criterion at convergence: 1096546\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9489 -0.6138  0.0431  0.6506  4.3466 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n cntryyr  (Intercept) 0.07645  0.2765  \n cntry    (Intercept) 0.46891  0.6848  \n Residual             3.43915  1.8545  \nNumber of obs: 268995, groups:  cntryyr, 198; cntry, 34\n\nFixed effects:\n                                         Estimate Std. Error t value\n(Intercept)                              5.374154   0.121853  44.103\nppltrustd                                0.195515   0.001637 119.448\nyoung                                    0.158414   0.010878  14.563\nold                                     -0.284244   0.009190 -30.931\nuniversity                               0.706875   0.009983  70.805\ngndr                                    -0.023206   0.007199  -3.223\nhincfelCoping on present income         -0.279744   0.009005 -31.064\nhincfelDifficult on present income      -0.535303   0.012056 -44.403\nhincfelVery difficult on present income -0.803543   0.017141 -46.879\nlrscale1                                 0.085591   0.030502   2.806\nlrscale2                                -0.655995   0.027094 -24.212\nlrscale3                                 0.202945   0.025126   8.077\nlrscale4                                 0.167045   0.023010   7.260\nlrscale5                                 0.071751   0.022953   3.126\nlrscale6                                -0.267820   0.020911 -12.808\nlrscale7                                -0.155967   0.023003  -6.780\nlrscale8                                -0.241845   0.022773 -10.620\nlrscale9                                -0.335819   0.023464 -14.312\nlrscaleRight                            -0.488616   0.029146 -16.765\n\n\n\nCorrelation matrix not shown by default, as p = 19 &gt; 12.\nUse print(x, correlation=TRUE)  or\n    vcov(x)        if you need it\n\n\n\n\nModel 3:\n\n#Full model with context level variables ---------------------------------------------------------------------------------\nm3&lt;-lmer(immatt~  ppltrustd+ young +old + university+ gndr+ hincfel+ lrscale+ \n           countrytrustD+ countrytrustM+ nwolD+ nwolM + lGDPD+\n           lGDPM + PctFBD + PctFBM+ essround + \n           (1|cntry) +  \n           (1|cntryyr), \n         data=mitchell)\nsummary(m3)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: immatt ~ ppltrustd + young + old + university + gndr + hincfel +  \n    lrscale + countrytrustD + countrytrustM + nwolD + nwolM +  \n    lGDPD + lGDPM + PctFBD + PctFBM + essround + (1 | cntry) +  \n    (1 | cntryyr)\n   Data: mitchell\n\nREML criterion at convergence: 1036621\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9669 -0.6108  0.0419  0.6506  4.3838 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n cntryyr  (Intercept) 0.06101  0.2470  \n cntry    (Intercept) 0.30562  0.5528  \n Residual             3.40292  1.8447  \nNumber of obs: 254959, groups:  cntryyr, 189; cntry, 32\n\nFixed effects:\n                                         Estimate Std. Error t value\n(Intercept)                             10.244812   4.465218   2.294\nppltrustd                                0.197809   0.001682 117.605\nyoung                                    0.140804   0.011116  12.666\nold                                     -0.280120   0.009353 -29.950\nuniversity                               0.711735   0.010111  70.389\ngndr                                    -0.033242   0.007357  -4.518\nhincfelCoping on present income         -0.280695   0.009103 -30.834\nhincfelDifficult on present income      -0.534626   0.012359 -43.256\nhincfelVery difficult on present income -0.807173   0.017778 -45.403\nlrscale1                                 0.069075   0.031374   2.202\nlrscale2                                -0.733225   0.028132 -26.063\nlrscale3                                 0.184455   0.025777   7.156\nlrscale4                                 0.134272   0.023604   5.689\nlrscale5                                 0.031266   0.023557   1.327\nlrscale6                                -0.320745   0.021487 -14.928\nlrscale7                                -0.209380   0.023602  -8.871\nlrscale8                                -0.302706   0.023374 -12.951\nlrscale9                                -0.399881   0.024124 -16.576\nlrscaleRight                            -0.564745   0.030231 -18.681\ncountrytrustD                            0.731459   0.118322   6.182\ncountrytrustM                            0.375491   0.146294   2.567\nnwolD                                   -0.021017   0.009739  -2.158\nnwolM                                   -0.098709   0.037864  -2.607\nlGDPD                                    0.114872   0.361877   0.317\nlGDPM                                   -0.592714   0.465571  -1.273\nPctFBD                                   0.017653   0.020988   0.841\nPctFBM                                   0.012114   0.021314   0.568\nessround                                -0.025951   0.016855  -1.540\n\n\n\nCorrelation matrix not shown by default, as p = 28 &gt; 12.\nUse print(x, correlation=TRUE)  or\n    vcov(x)        if you need it\n\n\n\n\nModel 4:\n\n#Full model with random slopes for between country trust -----------------------------------------------------------------\n# due to convergence issues the REML=FALSE but the estimates are the same\nm4&lt;-lmer(immatt~  ppltrustd+ young +old + university+ gndr+ hincfel+ lrscale+ \n           countrytrustD+ countrytrustM+ nwolD+ nwolM + lGDPD+\n           lGDPM + PctFBD + PctFBM+ essround + \n           (countrytrustD|cntry) +  \n           (1|cntryyr), \n         data=mitchell)\n\nWarning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\nModel failed to converge with max|grad| = 0.00286425 (tol = 0.002, component 1)\n\nsummary(m4)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: immatt ~ ppltrustd + young + old + university + gndr + hincfel +  \n    lrscale + countrytrustD + countrytrustM + nwolD + nwolM +  \n    lGDPD + lGDPM + PctFBD + PctFBM + essround + (countrytrustD |  \n    cntry) + (1 | cntryyr)\n   Data: mitchell\n\nREML criterion at convergence: 1036619\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9681 -0.6107  0.0419  0.6507  4.3840 \n\nRandom effects:\n Groups   Name          Variance Std.Dev. Corr\n cntryyr  (Intercept)   0.06002  0.2450       \n cntry    (Intercept)   0.30433  0.5517       \n          countrytrustD 0.04453  0.2110   1.00\n Residual               3.40292  1.8447       \nNumber of obs: 254959, groups:  cntryyr, 189; cntry, 32\n\nFixed effects:\n                                         Estimate Std. Error t value\n(Intercept)                             11.494698   4.152133   2.768\nppltrustd                                0.197812   0.001682 117.607\nyoung                                    0.140817   0.011116  12.667\nold                                     -0.280137   0.009353 -29.952\nuniversity                               0.711716   0.010111  70.388\ngndr                                    -0.033238   0.007357  -4.518\nhincfelCoping on present income         -0.280658   0.009103 -30.830\nhincfelDifficult on present income      -0.534571   0.012359 -43.252\nhincfelVery difficult on present income -0.807094   0.017778 -45.399\nlrscale1                                 0.069090   0.031374   2.202\nlrscale2                                -0.733242   0.028132 -26.064\nlrscale3                                 0.184458   0.025777   7.156\nlrscale4                                 0.134287   0.023604   5.689\nlrscale5                                 0.031286   0.023557   1.328\nlrscale6                                -0.320695   0.021487 -14.925\nlrscale7                                -0.209369   0.023602  -8.871\nlrscale8                                -0.302694   0.023374 -12.950\nlrscale9                                -0.399874   0.024124 -16.576\nlrscaleRight                            -0.564760   0.030231 -18.681\ncountrytrustD                            0.728344   0.123881   5.879\ncountrytrustM                            0.408231   0.138753   2.942\nnwolD                                   -0.021657   0.009677  -2.238\nnwolM                                   -0.106870   0.034795  -3.071\nlGDPD                                    0.011592   0.358608   0.032\nlGDPM                                   -0.723821   0.433199  -1.671\nPctFBD                                   0.018206   0.021093   0.863\nPctFBM                                   0.010639   0.020044   0.531\nessround                                -0.022654   0.016835  -1.346\n\n\n\nCorrelation matrix not shown by default, as p = 28 &gt; 12.\nUse print(x, correlation=TRUE)  or\n    vcov(x)        if you need it\n\n\noptimizer (nloptwrap) convergence code: 0 (OK)\nModel failed to converge with max|grad| = 0.00286425 (tol = 0.002, component 1)\n\n\n\n\nTabulating all the models:\nWe can use the same modelsummary() function we have already used before:\n\nmodelsummary::modelsummary(list(m1, m2, m3, m4))\n\n\n\n\n\n (1)\n  (2)\n  (3)\n  (4)\n\n\n\n\n(Intercept)\n4.926\n5.374\n10.245\n11.495\n\n\n\n(0.137)\n(0.122)\n(4.465)\n(4.152)\n\n\nppltrustd\n\n0.196\n0.198\n0.198\n\n\n\n\n(0.002)\n(0.002)\n(0.002)\n\n\nyoung\n\n0.158\n0.141\n0.141\n\n\n\n\n(0.011)\n(0.011)\n(0.011)\n\n\nold\n\n−0.284\n−0.280\n−0.280\n\n\n\n\n(0.009)\n(0.009)\n(0.009)\n\n\nuniversity\n\n0.707\n0.712\n0.712\n\n\n\n\n(0.010)\n(0.010)\n(0.010)\n\n\ngndr\n\n−0.023\n−0.033\n−0.033\n\n\n\n\n(0.007)\n(0.007)\n(0.007)\n\n\nhincfelCoping on present income\n\n−0.280\n−0.281\n−0.281\n\n\n\n\n(0.009)\n(0.009)\n(0.009)\n\n\nhincfelDifficult on present income\n\n−0.535\n−0.535\n−0.535\n\n\n\n\n(0.012)\n(0.012)\n(0.012)\n\n\nhincfelVery difficult on present income\n\n−0.804\n−0.807\n−0.807\n\n\n\n\n(0.017)\n(0.018)\n(0.018)\n\n\nlrscale1\n\n0.086\n0.069\n0.069\n\n\n\n\n(0.031)\n(0.031)\n(0.031)\n\n\nlrscale2\n\n−0.656\n−0.733\n−0.733\n\n\n\n\n(0.027)\n(0.028)\n(0.028)\n\n\nlrscale3\n\n0.203\n0.184\n0.184\n\n\n\n\n(0.025)\n(0.026)\n(0.026)\n\n\nlrscale4\n\n0.167\n0.134\n0.134\n\n\n\n\n(0.023)\n(0.024)\n(0.024)\n\n\nlrscale5\n\n0.072\n0.031\n0.031\n\n\n\n\n(0.023)\n(0.024)\n(0.024)\n\n\nlrscale6\n\n−0.268\n−0.321\n−0.321\n\n\n\n\n(0.021)\n(0.021)\n(0.021)\n\n\nlrscale7\n\n−0.156\n−0.209\n−0.209\n\n\n\n\n(0.023)\n(0.024)\n(0.024)\n\n\nlrscale8\n\n−0.242\n−0.303\n−0.303\n\n\n\n\n(0.023)\n(0.023)\n(0.023)\n\n\nlrscale9\n\n−0.336\n−0.400\n−0.400\n\n\n\n\n(0.023)\n(0.024)\n(0.024)\n\n\nlrscaleRight\n\n−0.489\n−0.565\n−0.565\n\n\n\n\n(0.029)\n(0.030)\n(0.030)\n\n\ncountrytrustD\n\n\n0.731\n0.728\n\n\n\n\n\n(0.118)\n(0.124)\n\n\ncountrytrustM\n\n\n0.375\n0.408\n\n\n\n\n\n(0.146)\n(0.139)\n\n\nnwolD\n\n\n−0.021\n−0.022\n\n\n\n\n\n(0.010)\n(0.010)\n\n\nnwolM\n\n\n−0.099\n−0.107\n\n\n\n\n\n(0.038)\n(0.035)\n\n\nlGDPD\n\n\n0.115\n0.012\n\n\n\n\n\n(0.362)\n(0.359)\n\n\nlGDPM\n\n\n−0.593\n−0.724\n\n\n\n\n\n(0.466)\n(0.433)\n\n\nPctFBD\n\n\n0.018\n0.018\n\n\n\n\n\n(0.021)\n(0.021)\n\n\nPctFBM\n\n\n0.012\n0.011\n\n\n\n\n\n(0.021)\n(0.020)\n\n\nessround\n\n\n−0.026\n−0.023\n\n\n\n\n\n(0.017)\n(0.017)\n\n\nSD (Intercept cntry)\n0.786\n0.685\n0.553\n0.552\n\n\nSD (countrytrustD cntry)\n\n\n\n0.211\n\n\nCor (Intercept~countrytrustD cntry)\n\n\n\n1.000\n\n\nSD (Observations)\n2.009\n1.854\n1.845\n1.845\n\n\nSD (Intercept cntryyr)\n\n0.276\n0.247\n0.245\n\n\nSD (Intercept cntryyrcntry)\n0.280\n\n\n\n\n\nNum.Obs.\n314934\n268995\n254959\n254959\n\n\nR2 Marg.\n0.000\n0.108\n0.163\n0.165\n\n\nR2 Cond.\n0.147\n0.230\n0.244\n0.246\n\n\nAIC\n1334097.2\n1096590.3\n1036683.2\n1036685.1\n\n\nBIC\n1334139.9\n1096821.4\n1037007.1\n1037029.9\n\n\nICC\n0.1\n0.1\n0.1\n0.1\n\n\nRMSE\n2.01\n1.85\n1.84\n1.84\n\n\n\n\n\n\n\nOr the {sjPlot} package would replicate the output presented in the article exactly:\n\nsjPlot::tab_model(m1, m2, m3, m4)\n\n\n\n \nImmigration bad or goodfor country's economy\nImmigration bad or goodfor country's economy\nImmigration bad or goodfor country's economy\nImmigration bad or goodfor country's economy\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n4.93\n4.66 – 5.19\n&lt;0.001\n5.37\n5.14 – 5.61\n&lt;0.001\n10.24\n1.49 – 19.00\n0.022\n11.49\n3.36 – 19.63\n0.006\n\n\nMost people can betrusted or you can't betoo careful\n\n\n\n0.20\n0.19 – 0.20\n&lt;0.001\n0.20\n0.19 – 0.20\n&lt;0.001\n0.20\n0.19 – 0.20\n&lt;0.001\n\n\nyoung\n\n\n\n0.16\n0.14 – 0.18\n&lt;0.001\n0.14\n0.12 – 0.16\n&lt;0.001\n0.14\n0.12 – 0.16\n&lt;0.001\n\n\nold\n\n\n\n-0.28\n-0.30 – -0.27\n&lt;0.001\n-0.28\n-0.30 – -0.26\n&lt;0.001\n-0.28\n-0.30 – -0.26\n&lt;0.001\n\n\nuniversity\n\n\n\n0.71\n0.69 – 0.73\n&lt;0.001\n0.71\n0.69 – 0.73\n&lt;0.001\n0.71\n0.69 – 0.73\n&lt;0.001\n\n\nGender\n\n\n\n-0.02\n-0.04 – -0.01\n0.001\n-0.03\n-0.05 – -0.02\n&lt;0.001\n-0.03\n-0.05 – -0.02\n&lt;0.001\n\n\nFeeling about household'sincome nowadays: Copingon present income\n\n\n\n-0.28\n-0.30 – -0.26\n&lt;0.001\n-0.28\n-0.30 – -0.26\n&lt;0.001\n-0.28\n-0.30 – -0.26\n&lt;0.001\n\n\nFeeling about household'sincome nowadays:Difficult on presentincome\n\n\n\n-0.54\n-0.56 – -0.51\n&lt;0.001\n-0.53\n-0.56 – -0.51\n&lt;0.001\n-0.53\n-0.56 – -0.51\n&lt;0.001\n\n\nFeeling about household'sincome nowadays: Verydifficult on presentincome\n\n\n\n-0.80\n-0.84 – -0.77\n&lt;0.001\n-0.81\n-0.84 – -0.77\n&lt;0.001\n-0.81\n-0.84 – -0.77\n&lt;0.001\n\n\nPlacement on left rightscale: 1\n\n\n\n0.09\n0.03 – 0.15\n0.005\n0.07\n0.01 – 0.13\n0.028\n0.07\n0.01 – 0.13\n0.028\n\n\nPlacement on left rightscale: 2\n\n\n\n-0.66\n-0.71 – -0.60\n&lt;0.001\n-0.73\n-0.79 – -0.68\n&lt;0.001\n-0.73\n-0.79 – -0.68\n&lt;0.001\n\n\nPlacement on left rightscale: 3\n\n\n\n0.20\n0.15 – 0.25\n&lt;0.001\n0.18\n0.13 – 0.23\n&lt;0.001\n0.18\n0.13 – 0.23\n&lt;0.001\n\n\nPlacement on left rightscale: 4\n\n\n\n0.17\n0.12 – 0.21\n&lt;0.001\n0.13\n0.09 – 0.18\n&lt;0.001\n0.13\n0.09 – 0.18\n&lt;0.001\n\n\nPlacement on left rightscale: 5\n\n\n\n0.07\n0.03 – 0.12\n0.002\n0.03\n-0.01 – 0.08\n0.184\n0.03\n-0.01 – 0.08\n0.184\n\n\nPlacement on left rightscale: 6\n\n\n\n-0.27\n-0.31 – -0.23\n&lt;0.001\n-0.32\n-0.36 – -0.28\n&lt;0.001\n-0.32\n-0.36 – -0.28\n&lt;0.001\n\n\nPlacement on left rightscale: 7\n\n\n\n-0.16\n-0.20 – -0.11\n&lt;0.001\n-0.21\n-0.26 – -0.16\n&lt;0.001\n-0.21\n-0.26 – -0.16\n&lt;0.001\n\n\nPlacement on left rightscale: 8\n\n\n\n-0.24\n-0.29 – -0.20\n&lt;0.001\n-0.30\n-0.35 – -0.26\n&lt;0.001\n-0.30\n-0.35 – -0.26\n&lt;0.001\n\n\nPlacement on left rightscale: 9\n\n\n\n-0.34\n-0.38 – -0.29\n&lt;0.001\n-0.40\n-0.45 – -0.35\n&lt;0.001\n-0.40\n-0.45 – -0.35\n&lt;0.001\n\n\nPlacement on left rightscale: Right\n\n\n\n-0.49\n-0.55 – -0.43\n&lt;0.001\n-0.56\n-0.62 – -0.51\n&lt;0.001\n-0.56\n-0.62 – -0.51\n&lt;0.001\n\n\ncountrytrust D\n\n\n\n\n\n\n0.73\n0.50 – 0.96\n&lt;0.001\n0.73\n0.49 – 0.97\n&lt;0.001\n\n\ncountrytrust M\n\n\n\n\n\n\n0.38\n0.09 – 0.66\n0.010\n0.41\n0.14 – 0.68\n0.003\n\n\nnwol D\n\n\n\n\n\n\n-0.02\n-0.04 – -0.00\n0.031\n-0.02\n-0.04 – -0.00\n0.025\n\n\nnwol M\n\n\n\n\n\n\n-0.10\n-0.17 – -0.02\n0.009\n-0.11\n-0.18 – -0.04\n0.002\n\n\nl GDPD\n\n\n\n\n\n\n0.11\n-0.59 – 0.82\n0.751\n0.01\n-0.69 – 0.71\n0.974\n\n\nl GDPM\n\n\n\n\n\n\n-0.59\n-1.51 – 0.32\n0.203\n-0.72\n-1.57 – 0.13\n0.095\n\n\nPct FBD\n\n\n\n\n\n\n0.02\n-0.02 – 0.06\n0.400\n0.02\n-0.02 – 0.06\n0.388\n\n\nPct FBM\n\n\n\n\n\n\n0.01\n-0.03 – 0.05\n0.570\n0.01\n-0.03 – 0.05\n0.596\n\n\nESS round\n\n\n\n\n\n\n-0.03\n-0.06 – 0.01\n0.124\n-0.02\n-0.06 – 0.01\n0.178\n\n\nRandom Effects\n\n\n\nσ2\n4.04\n3.44\n3.40\n3.40\n\n\n\nτ00\n0.08 cntryyr:cntry\n0.08 cntryyr\n0.06 cntryyr\n0.06 cntryyr\n\n\n\n0.62 cntry\n0.47 cntry\n0.31 cntry\n0.30 cntry\n\n\nτ11\n \n \n \n0.04 cntry.countrytrustD\n\n\nρ01\n \n \n \n1.00 cntry\n\n\nICC\n0.15\n0.14\n0.10\n0.10\n\n\nN\n200 cntryyr\n34 cntry\n32 cntry\n32 cntry\n\n\n\n34 cntry\n198 cntryyr\n189 cntryyr\n189 cntryyr\n\nObservations\n314934\n268995\n254959\n254959\n\n\nMarginal R2 / Conditional R2\n0.000 / 0.147\n0.108 / 0.230\n0.163 / 0.244\n0.165 / 0.246\n\n\n\n\n\n\nAnd we can also plot the results from a model of interest:\n\nsjPlot::plot_model( m4)",
    "crumbs": [
      "Materials",
      "Week 7",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w07.html#example-3-longer-panel-data-estimation-with-plm",
    "href": "materials/notes/notes_w07.html#example-3-longer-panel-data-estimation-with-plm",
    "title": "Week 7 Worksheet Notes",
    "section": "Example 3: Longer panel data estimation with {plm}",
    "text": "Example 3: Longer panel data estimation with {plm}\nPanel data gathers information about several individuals (cross-sectional units) over several periods. The panel is balanced if all units are observed in all periods; if some units are missing in some periods, the panel is unbalanced. A wide panel has the cross-sectional dimension (N) much larger than the longitudinal dimension (T); when the opposite is true, we have a long panel. Normally, the same units are observed in all periods; when this is not the case and each period samples mostly other units, the result is not a proper panel data, but pooled cross-sections model.\nIn the previous examples our panels were fairly short. In this exercise, we use longer panel data to also demonstrate some additional functionalities in the {plm} package. The dataset is more typical of econometric data and originates from Hill et al.’s book “Principles of Econometrics”.\nWe can load the dataset from the module website and inspect its contents:\n\nnls &lt;- data_read(\"https://cgmoreh.github.io/HSS8005-24/data/nls_panel.rda\")\n\nReading data...\n\n\nVariables where all values have associated labels are now converted into\n  factors. If this is not intended, use `convert_factors = FALSE`.\n\n\n0 out of 18 variables were fully labelled and converted into factors.\n\n\nwe can peek at the data to get a feel for the variables:\n\ndatawizard::data_peek(nls) |&gt; print_md()\n\n\nData frame with 3580 rows and 18 variables\n\n\nVariable\nType\nValues\n\n\n\n\nid\nnumeric\n1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, …\n\n\nyear\nnumeric\n82, 83, 85, 87, 88, 82, 83, 85, 87, 88, 82, …\n\n\nlwage\nnumeric\n1.808289, 1.863417, 1.789367, 1.84653, …\n\n\nhours\nnumeric\n38, 38, 38, 40, 40, 48, 43, 35, 42, 42, 48, …\n\n\nage\nnumeric\n30, 31, 33, 35, 37, 36, 37, 39, 41, 43, 35, …\n\n\neduc\nnumeric\n12, 12, 12, 12, 12, 17, 17, 17, 17, 17, 12, …\n\n\ncollgrad\nnumeric\n0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, …\n\n\nmsp\nnumeric\n1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n\n\nnev_mar\nnumeric\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\nnot_smsa\nnumeric\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\nc_city\nnumeric\n1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\nsouth\nnumeric\n0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\nblack\nnumeric\n1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n\n\nunion\nnumeric\n1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, …\n\n\nexper\nnumeric\n7.666667, 8.583333, 10.17949, 12.17949, …\n\n\nexper2\nnumeric\n58.77777, 73.67361, 103.622, 148.3399, …\n\n\ntenure\nnumeric\n7.666667, 8.583333, 1.833333, 3.75, 5.25, …\n\n\ntenure2\nnumeric\n58.77777, 73.67361, 3.361111, 14.0625, …\n\n\n\n\n\nWe can also check the first few and last few observations in a dataframe using the head() and tail() functions included in base-R. The {gt} package also has a nice function (gt_preview()) that can do the same more flexibly and output it as a single table:\n\ngt::gt_preview(nls, top_n = 3, bottom_n = 3, incl_rownums = TRUE)\n\n\n\n\n\n\n\n\nid\nyear\nlwage\nhours\nage\neduc\ncollgrad\nmsp\nnev_mar\nnot_smsa\nc_city\nsouth\nblack\nunion\nexper\nexper2\ntenure\ntenure2\n\n\n\n\n1\n1\n82\n1.808289\n38\n30\n12\n0\n1\n0\n0\n1\n0\n1\n1\n7.666667\n58.77777\n7.666667\n58.777770\n\n\n2\n1\n83\n1.863417\n38\n31\n12\n0\n1\n0\n0\n1\n0\n1\n1\n8.583333\n73.67361\n8.583333\n73.673610\n\n\n3\n1\n85\n1.789367\n38\n33\n12\n0\n0\n0\n0\n1\n0\n1\n1\n10.179490\n103.62200\n1.833333\n3.361111\n\n\n4..3577\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3578\n716\n85\n1.427116\n40\n39\n12\n0\n1\n0\n1\n0\n1\n0\n0\n15.435900\n238.26690\n6.083333\n37.006950\n\n\n3579\n716\n87\n1.494368\n30\n41\n12\n0\n1\n0\n1\n0\n1\n0\n0\n17.435900\n304.01050\n8.166667\n66.694450\n\n\n3580\n716\n88\n1.341422\n40\n42\n12\n0\n1\n0\n1\n0\n1\n0\n0\n18.858970\n355.66090\n9.583333\n91.840270\n\n\n\n\n\n\n\nTo check more directly the number of ids and years in the dataset, we could use the n_unique() function from {dplyr} in the {tidyverse}:\n\nn_unique(nls$id)\n\n[1] 716\n\nn_unique(nls$year)\n\n[1] 5\n\n\nWe can also check the distribution of the variables:\n\ndatawizard::describe_distribution(nls)\n\nVariable |   Mean |     SD |    IQR |          Range | Skewness | Kurtosis |    n | n_Missing\n---------------------------------------------------------------------------------------------\nid       | 358.50 | 206.72 | 358.50 | [1.00, 716.00] |     0.00 |    -1.20 | 3580 |         0\nyear     |  85.00 |   2.28 |   4.00 | [82.00, 88.00] |     0.00 |    -1.57 | 3580 |         0\nlwage    |   1.92 |   0.46 |   0.64 |   [0.14, 4.25] |     0.26 |     0.49 | 3580 |         0\nhours    |  38.03 |   7.97 |   2.00 |  [1.00, 80.00] |    -1.20 |     3.85 | 3580 |         0\nage      |  35.88 |   3.89 |   6.00 | [28.00, 46.00] |     0.11 |    -0.62 | 3580 |         0\neduc     |  13.02 |   2.44 |   3.00 |  [4.00, 18.00] |     0.24 |     0.15 | 3580 |         0\ncollgrad |   0.23 |   0.42 |   0.00 |   [0.00, 1.00] |     1.28 |    -0.36 | 3580 |         0\nmsp      |   0.66 |   0.47 |   1.00 |   [0.00, 1.00] |    -0.67 |    -1.55 | 3580 |         0\nnev_mar  |   0.14 |   0.35 |   0.00 |   [0.00, 1.00] |     2.07 |     2.30 | 3580 |         0\nnot_smsa |   0.30 |   0.46 |   1.00 |   [0.00, 1.00] |     0.88 |    -1.23 | 3580 |         0\nc_city   |   0.30 |   0.46 |   1.00 |   [0.00, 1.00] |     0.86 |    -1.25 | 3580 |         0\nsouth    |   0.42 |   0.49 |   1.00 |   [0.00, 1.00] |     0.31 |    -1.91 | 3580 |         0\nblack    |   0.28 |   0.45 |   1.00 |   [0.00, 1.00] |     0.97 |    -1.06 | 3580 |         0\nunion    |   0.26 |   0.44 |   1.00 |   [0.00, 1.00] |     1.07 |    -0.86 | 3580 |         0\nexper    |  12.03 |   3.86 |   5.35 |  [1.06, 27.19] |     0.02 |    -0.13 | 3580 |         0\nexper2   | 159.60 |  95.46 | 128.86 | [1.12, 739.42] |     0.92 |     1.32 | 3580 |         0\ntenure   |   6.95 |   5.17 |   7.83 |  [0.00, 24.75] |     0.64 |    -0.41 | 3580 |         0\ntenure2  |  75.01 |  93.66 | 101.83 | [0.00, 612.56] |     1.74 |     2.91 | 3580 |         0\n\n\nPanel datsets can be organized in mainly two forms: the long form has a column for each variable and a row for each individual-period; the wide form has a column for each variable-period and a row for each individual. Most panel data methods require the long form, but many data sources provide one wide-form table for each variable; assembling the data from different sources into a long form data frame is often not a trivial matter.\nThe next code sequence creates a panel structure for the dataset using the function pdata.frame() of the {plm} package and displays a small part of this datase:\n\nnlspd &lt;- pdata.frame(nls, index=c(\"id\", \"year\"))\n\nThe function pdim() extracts the dimensions of the panel data:\n\npdim(nlspd)\n\nBalanced Panel: n = 716, T = 5, N = 3580\n\n\nIn the following, we will fit a series of models estimating wage as a function of education, experience (and a second-order polynomial for experience) and race (“black” vs. “white”), with the aim of demonstrating functions in the plm() package. We could also fit these models using the hierarchical modelling functions form previous examples and exercises.\n\nPooled model\nA pooled model does not allow for intercept or slope differences among individuals. Such a model can be estimated with plm() using the specification pooling:\n\nwage.pooled &lt;- plm(lwage ~ educ + exper + I(exper^2) + black, \n  model=\"pooling\", \n  data = nlspd)\n\n\nsummary(wage.pooled)\n\nPooling Model\n\nCall:\nplm(formula = lwage ~ educ + exper + I(exper^2) + black, data = nlspd, \n    model = \"pooling\")\n\nBalanced Panel: n = 716, T = 5, N = 3580\n\nResiduals:\n      Min.    1st Qu.     Median    3rd Qu.       Max. \n-1.7043039 -0.2469447 -0.0062387  0.2421563  2.6619636 \n\nCoefficients:\n               Estimate  Std. Error t-value  Pr(&gt;|t|)    \n(Intercept)  0.42706205  0.05691619  7.5033 7.807e-14 ***\neduc         0.07451334  0.00274756 27.1198 &lt; 2.2e-16 ***\nexper        0.06272218  0.00797946  7.8605 5.026e-15 ***\nI(exper^2)  -0.00122307  0.00032263 -3.7910 0.0001525 ***\nblack       -0.13616209  0.01485167 -9.1681 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    772.56\nResidual Sum of Squares: 550.24\nR-Squared:      0.28777\nAdj. R-Squared: 0.28697\nF-statistic: 361.111 on 4 and 3575 DF, p-value: &lt; 2.22e-16\n\nmodel_parameters(wage.pooled)\n\n# Fixed Effects\n\nParameter   | Coefficient |       SE |         95% CI | t(3575) |      p\n------------------------------------------------------------------------\n(Intercept) |        0.43 |     0.06 | [ 0.32,  0.54] |    7.50 | &lt; .001\neduc        |        0.07 | 2.75e-03 | [ 0.07,  0.08] |   27.12 | &lt; .001\nexper       |        0.06 | 7.98e-03 | [ 0.05,  0.08] |    7.86 | &lt; .001\nexper^2     |   -1.22e-03 | 3.23e-04 | [ 0.00,  0.00] |   -3.79 | &lt; .001\nblack       |       -0.14 |     0.01 | [-0.17, -0.11] |   -9.17 | &lt; .001\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation.\n\n\n\n\nFixed effects model\nThe fixed effects model takes into account individual differences, translated into different intercepts of the regression line for different individuals. Variables that change little or not at all over time, such as some individual characteristics should not be included in a fixed effects model because they produce collinearity with the fixed effects.\nTo estimate a fixed effects with {plm}, we can use the option model=“within”, and dummy variables for individuals are created automatically in the background and included in the model:\n\nwage.within &lt;- plm(lwage ~ educ + exper + I(exper^2) + black, \n  model=\"within\", \n  data = nlspd)\n\n\nsummary(wage.within)\n\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = lwage ~ educ + exper + I(exper^2) + black, data = nlspd, \n    model = \"within\")\n\nBalanced Panel: n = 716, T = 5, N = 3580\n\nResiduals:\n      Min.    1st Qu.     Median    3rd Qu.       Max. \n-1.1798141 -0.0693879  0.0052198  0.0789143  1.9969132 \n\nCoefficients:\n              Estimate  Std. Error t-value  Pr(&gt;|t|)    \nexper       0.05521048  0.00580433  9.5120 &lt; 2.2e-16 ***\nI(exper^2) -0.00105655  0.00022838 -4.6263 3.888e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    126.95\nResidual Sum of Squares: 110.37\nR-Squared:      0.13057\nAdj. R-Squared: -0.087246\nF-statistic: 214.901 on 2 and 2862 DF, p-value: &lt; 2.22e-16\n\nmodel_parameters(wage.within)\n\n# Fixed Effects\n\nParameter | Coefficient |       SE |         95% CI | t(2862) |      p\n----------------------------------------------------------------------\nexper     |        0.06 | 5.80e-03 | [ 0.04,  0.07] |    9.51 | &lt; .001\nexper^2   |   -1.06e-03 | 2.28e-04 | [ 0.00,  0.00] |   -4.63 | &lt; .001\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald t-distribution approximation.\n\n\nAs we can see in the results above, the “race” variable was excluded from the model because it does not vary over time (it stays constant “within” an individual). This is one major limitation of so-called fixed effects (“within”) models.\nThe within method is equivalent to including the individual “dummies” in the model.\n\n\nRandom effects\nThe random effects model elaborates on the fixed effects model by recognizing that, since the individuals in the panel are randomly selected, their characteristics, measured by the intercept \\(\\beta_{1i}\\) should also be random. Random effects estimators are reliable under the assumption that individual characteristics (heterogeneity) are exogenous, that is, they are independent with respect to the regressors in the random effects equation. We have already fit random effects models using the {lme4} packages previously.\nIn {plm}, the same function we used for fixed effects can be used for random effects, but setting the argument model= to ‘random’ and selecting the random.method as one out of four possibilities: “swar” (default), “amemiya”, “walhus”, or “nerlove”:\n\nwage.random &lt;- plm(lwage ~ educ + exper + I(exper^2) + black, \n  model = \"random\",\n  random.method = \"swar\",\n  data = nlspd)\n\n\nsummary(wage.random)\n\nOneway (individual) effect Random Effect Model \n   (Swamy-Arora's transformation)\n\nCall:\nplm(formula = lwage ~ educ + exper + I(exper^2) + black, data = nlspd, \n    model = \"random\", random.method = \"swar\")\n\nBalanced Panel: n = 716, T = 5, N = 3580\n\nEffects:\n                  var std.dev share\nidiosyncratic 0.03857 0.19638  0.25\nindividual    0.11592 0.34047  0.75\ntheta: 0.7502\n\nResiduals:\n      Min.    1st Qu.     Median    3rd Qu.       Max. \n-1.2666036 -0.0928955  0.0057325  0.0984554  2.0978278 \n\nCoefficients:\n               Estimate  Std. Error z-value  Pr(&gt;|z|)    \n(Intercept)  0.47585529  0.08084927  5.8857 3.964e-09 ***\neduc         0.07488688  0.00547943 13.6669 &lt; 2.2e-16 ***\nexper        0.05638773  0.00560490 10.0604 &lt; 2.2e-16 ***\nI(exper^2)  -0.00108166  0.00022148 -4.8838 1.041e-06 ***\nblack       -0.13627562  0.02973398 -4.5832 4.580e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    167.23\nResidual Sum of Squares: 137.85\nR-Squared:      0.17566\nAdj. R-Squared: 0.17474\nChisq: 761.809 on 4 DF, p-value: &lt; 2.22e-16\n\nmodel_parameters(wage.random)\n\n# Fixed Effects\n\nParameter   | Coefficient |       SE |         95% CI |     z |   df |      p\n-----------------------------------------------------------------------------\n(Intercept) |        0.48 |     0.08 | [ 0.32,  0.63] |  5.89 | 3575 | &lt; .001\neduc        |        0.07 | 5.48e-03 | [ 0.06,  0.09] | 13.67 | 3575 | &lt; .001\nexper       |        0.06 | 5.60e-03 | [ 0.05,  0.07] | 10.06 | 3575 | &lt; .001\nexper^2     |   -1.08e-03 | 2.21e-04 | [ 0.00,  0.00] | -4.88 | 3575 | &lt; .001\nblack       |       -0.14 |     0.03 | [-0.19, -0.08] | -4.58 | 3575 | &lt; .001\n\n\n\nUncertainty intervals (equal-tailed) and p-values (two-tailed) computed\n  using a Wald z-distribution approximation.\n\n\n\n\nTabulating all the models:\nWe can now collate the models into a summary tabe to compare them more closely:\n\nmodelsummary::modelsummary(list(wage.pooled, wage.within, wage.random))\n\n\n\n\n\n (1)\n  (2)\n  (3)\n\n\n\n\n(Intercept)\n0.427\n\n0.476\n\n\n\n(0.057)\n\n(0.081)\n\n\neduc\n0.075\n\n0.075\n\n\n\n(0.003)\n\n(0.005)\n\n\nexper\n0.063\n0.055\n0.056\n\n\n\n(0.008)\n(0.006)\n(0.006)\n\n\nI(exper^2)\n−0.001\n−0.001\n−0.001\n\n\n\n(0.000)\n(0.000)\n(0.000)\n\n\nblack\n−0.136\n\n−0.136\n\n\n\n(0.015)\n\n(0.030)\n\n\nNum.Obs.\n3580\n3580\n3580\n\n\nR2\n0.288\n0.131\n0.176\n\n\nR2 Adj.\n0.287\n−0.087\n0.175\n\n\nAIC\n3467.1\n−2290.1\n−1488.2\n\n\nBIC\n3504.2\n−2271.6\n−1451.1\n\n\nRMSE\n0.39\n0.18\n0.20\n\n\n\n\n\n\n\nWe can compare these results from those obtaied using other hierarchical modelling functions, such as the lmer() function we used in earlier examples and exercises.",
    "crumbs": [
      "Materials",
      "Week 7",
      "Notes"
    ]
  },
  {
    "objectID": "materials/slides/test.html#not-outline-just-simple-dice",
    "href": "materials/slides/test.html#not-outline-just-simple-dice",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Not outline, just simple dice",
    "text": "Not outline, just simple dice\n\n\none\ntwo\nthree"
  },
  {
    "objectID": "materials/slides/test.html#numbered",
    "href": "materials/slides/test.html#numbered",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Numbered",
    "text": "Numbered\n\n\nGaming chance\nsecond topic\nThird topic\nForth topic"
  },
  {
    "objectID": "materials/slides/test.html#not-numbered",
    "href": "materials/slides/test.html#not-numbered",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Not numbered",
    "text": "Not numbered\n\n\nGaming chance\nsecond topic\nThird topic\nForth topic"
  },
  {
    "objectID": "materials/slides/test.html#numbered-small",
    "href": "materials/slides/test.html#numbered-small",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Numbered small",
    "text": "Numbered small\n\n\nGaming chance\nsecond topic\nThird topic\nForth topic"
  },
  {
    "objectID": "materials/slides/test.html#not-numbered-small",
    "href": "materials/slides/test.html#not-numbered-small",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Not numbered small",
    "text": "Not numbered small\n\n\nGaming chance\nsecond topic\nThird topic\nForth topic"
  },
  {
    "objectID": "materials/slides/test.html#just-text",
    "href": "materials/slides/test.html#just-text",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Just text",
    "text": "Just text\n\nSomething like a text here\n\nThis is my first line and it’s a very long line so that I can check how it looks like when it is printed on the slide and there are other lines below too\nThis is the second line\nAnd a third line here\n\nMore here\n\nFifth line\nSixth line"
  },
  {
    "objectID": "materials/slides/test.html#code",
    "href": "materials/slides/test.html#code",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Code",
    "text": "Code\n\n\na &lt;- rnorm(100, 4, 2)\nsummary(a)\n\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.003077 3.037188 4.125257 4.179099 5.208441 8.424084 \n\n\n\n\n\nhist(a)"
  },
  {
    "objectID": "materials/slides/test.html#testing",
    "href": "materials/slides/test.html#testing",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Testing",
    "text": "Testing\n\n\nTesting\n\n\nhow\n\n\nfragments work in\n\n\nreality"
  },
  {
    "objectID": "materials/slides/test.html#testing-2",
    "href": "materials/slides/test.html#testing-2",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Testing 2",
    "text": "Testing 2\n\nTesting\n. . .\nHow\n. . .\nfragments work\n. . .\nreally"
  },
  {
    "objectID": "materials/slides/test.html#statistics",
    "href": "materials/slides/test.html#statistics",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Statistics",
    "text": "Statistics\n\nand the state\n\n\n\n\nstatshistory\n\n\n\n1660\n\nHermann Conring \n (1606–1681)\n\n1660\n\n'statisticum'; political science lectures on European states, \n quantifying and comparing their finances, population, agriculture, etc.\n\nbotero\n\nGiovanni Botero \n (c. 1544–1617)\n\n'Della ragion di Stato' ~ 'Reason of State'\n\n\n\n\n\n\n1672\n\nHelenus Politanus (pse.)\n\n1672\n\n'Microscopium Statisticum'\n\nghilini\n\nGirolamo Ghilini \n (1589–1668)\n\n'Ristretto della civile, politica, statistica e militare scienza'\n\n\n\n\n1748\n\nGottfried Achenwall \n (1719–1772)\n\n1748\n\n'Vorbereitung zur Staatswissenschaft'; 'Statistik'\n\n\n\n1660-&gt;1672\n\n\n\n\nsittewald\n\nPhilander Von Sittewald \n (1601–1669)\n\n'statista' ~ 'someone versed in the knowledge of the state'\n\n\n1725\n\nMartin Schmeitzel \n (1679–1747)\n\n1725\n\n'collegium statisticum' ~ 'council of state'\n\n\n1660-&gt;1725\n\n\n\n\n\n\n\n\n\n\n1725-&gt;1748\n\n\n\n\n\n\n\npetty\n\nWilliam Petty \n (1623-1687)\n\n1672\n\n'political arithmetic'; 'Essays in Political Arithmetick \n and Political Survey or Anatomy of Ireland'\n\n\n\nsuss\n\nJohann Peter Süssmilch \n (1707-1767)\n\n1761-1762\n\n'The Divine order in the changes in the human sex from birth, \n death and reproduction of the same'\n\n\n\n\n\n\ngraunt\n\nJohn Graunt \n (1620–1674)\n\n1663\n\n'Natural and Political Observations \n Made upon the Bills of Mortality'"
  },
  {
    "objectID": "materials/slides/test.html#statistics-1",
    "href": "materials/slides/test.html#statistics-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Statistics",
    "text": "Statistics\nand probability\n\n\n\nStatistics as the mathematical science of using probability to describe uncertainty"
  },
  {
    "objectID": "materials/slides/test.html#gaming-chance",
    "href": "materials/slides/test.html#gaming-chance",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Gaming chance",
    "text": "Gaming chance\n\n\n\nWe may never know when humans started playing games of chance, but archaeological findings suggest it was a rather long time ago\nDuring the the First Dynasty in Egypt (c. 3500 B.C.) variants of a game involving astragali (small bones in the ankle of an animal) were already documented\nOne of the chief games may have been the simple one of throwing four astragali together and noting which sides fell uppermost"
  },
  {
    "objectID": "materials/slides/test.html#ālea-iacta-est",
    "href": "materials/slides/test.html#ālea-iacta-est",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Ālea iacta est",
    "text": "Ālea iacta est\n\n\n\nThe six-sided die we know today may have been obtained from the astragalus by grinding it down until it formed a rough cube\nDice became common in the Ptolemaic dynasty (300 to 30 B.C.)\nThere is evidence that dice were used for divination rites in this period - one carried the sacred symbols of Osiris, Horus, Isis, Nebhat, Hathor and Horhudet engraved on its six sides\nIn Roman times, rule by divination attained great proportions; Emperors Septimius Severus (Emperor A.D. 193-211) and Diocletian (Emperor AD. 284-305) were notorious for their reliance on the whims of the gods"
  },
  {
    "objectID": "materials/slides/test.html#fat-chance",
    "href": "materials/slides/test.html#fat-chance",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Fat chance",
    "text": "Fat chance\n\n\n\nHe threw four knucklebones on to the table and committed his hopes to the throw. If he threw well, particularly if he obtained the image of the goddess herself, no two showing the same number, he adored the goddess, and was in high hopes of gratifying his passion; if he threw badly, as usually happens, and got an unlucky combination, he called down imprecations on all Cnidos, and was as much overcome by grief as if he had suffered some personal loss.\n— Lucian of Samosata (c. 125 – 180), writing in his trademark satirical style about a young man who fell in love with Praxiteles’s Aphrodite of Knidos; cited in F. N. David (1955:8)"
  },
  {
    "objectID": "materials/slides/test.html#chance-with-limitations",
    "href": "materials/slides/test.html#chance-with-limitations",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Chance with limitations",
    "text": "Chance with limitations\n\n\n\nDice were sometimes faked. Sometimes numbers were left off or duplicated; hollow dice have been found dating from Roman time\nDice were also imperfect; a fair die was the exception rather than the rule\nExperiment by F. N. David using three dice from the British Museum:"
  },
  {
    "objectID": "materials/slides/test.html#exercise",
    "href": "materials/slides/test.html#exercise",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Exercise",
    "text": "Exercise\n\n\nWhich of the three dice (if any) would you call fair?\nWhat distribution of outcomes would you expect 204 fair dice rolls to produce prior to seeing any results?\nHow would you expect that distribution to change as the number of rolls progresses towards \\(\\infty\\)?\nWhat name would you give to that distribution?\nverv\nrever"
  },
  {
    "objectID": "materials/slides/test.html#from-chance-to-probability",
    "href": "materials/slides/test.html#from-chance-to-probability",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "From chance to probability\n",
    "text": "From chance to probability\n\n\n\n\nUntil 18th century people had mostly used probability to solve problems about dice throwing and other games of chance\nJacob (Jacques/James) Bernoulli (1654/1655-1705), a Swiss mathematician trained as a theologian and ordained as a minister of the Reformed church in Basel, began asking questions about probabilistic inference instead\nHis work focused on the mathematics of uncertainty - what he came to call stochastics (from the Greek word \\(στόχος\\) [stókhos] meaning to aim or “guess’)\n\nArs Conjectandi (The Art of Conjecturing) - published posthumously in 1713"
  },
  {
    "objectID": "materials/slides/test.html#inferential-questions",
    "href": "materials/slides/test.html#inferential-questions",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Inferential questions",
    "text": "Inferential questions\n\n\n\nSuppose you are presented with a large urn full of tiny white and black pebbles, in a ratio that’s unknown to you. You begin selecting pebbles from the urn and recording their colors, black or white. How do you use these results to make a guess about the ratio of pebble colors in the urn as a whole?\n\n\nBernoulli’s solution: if you take a large enough sample, you can be very sure, to within a small margin of absolute certainty, that the proportion of white pebbles you observe in the sample is close to the proportion of white pebbles in the urn.\nA first version of the Law of Large Numbers"
  },
  {
    "objectID": "materials/slides/test.html#large-numbers",
    "href": "materials/slides/test.html#large-numbers",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Large numbers",
    "text": "Large numbers\n\n\nBernoulli’s solution, more technically:  For any given \\(\\epsilon\\) &gt; 0 and any \\(s\\) &gt; 0, there is a sample size \\(n\\) such that, with \\(w\\) being the number of white pebbles counted in the sample and \\(f\\) being the true fraction of white pebbles in the urn, the probability of \\(w/n\\) falling between \\(f − \\epsilon\\) and \\(f + \\epsilon\\) is greater than \\(1 − s\\).\nthe fraction \\(w/n\\) is the ratio of white to total pebbles we observe in our sample\n\\(\\epsilon\\) (epsilon) captures the fact that we may not see the true urn ratio exactly thanks to random variation in the sample; larger samples help assure that we get closer to the true value, but uncertainty alwa ys remains\n\\(s\\) reflects just how sure we want to be; for example, set \\(s\\) = 0.01 and be 99% percent sure.\nmoral certainty as distinct from absolute certainty of the kind logical deduction provides"
  },
  {
    "objectID": "materials/slides/test.html#final-slides",
    "href": "materials/slides/test.html#final-slides",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Final slides",
    "text": "Final slides"
  },
  {
    "objectID": "materials/slides/test.html#references",
    "href": "materials/slides/test.html#references",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "materials/worksheets/worksheets_w02.html",
    "href": "materials/worksheets/worksheets_w02.html",
    "title": "Week 2 Worksheet Exercises",
    "section": "",
    "text": "This session introduces simple and multiple linear regression models. You will be working with data from Österman (2021) to replicate parts their analysis. We will be covering only basic regression methods in this session, so the article will serve mainly as a broad background to the data here. We will be returning to this article in future weeks too, expanding our modelling strategy as we discover new methods. We will also practice some data management tasks and the basics of data visualisation using principles from ‘the grammar of graphics’ as implemented in the {ggplot2} package (see Kieran Healy’s Data Visualization: A practical introduction for an introduction with many practical examples).\nBy the end of the session, you will:\n\nlearn how to import data from foreign formats (e.g. SPSS, Stata, CSV)\nknow how to perform basic descriptive statistics on a dataset\nunderstand the basics of data visualisation\nknow how to fit linear regression models in R using different functions\nlearn a few options for presenting findings from regression models",
    "crumbs": [
      "Materials",
      "Week 2",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w02.html#aims",
    "href": "materials/worksheets/worksheets_w02.html#aims",
    "title": "Week 2 Worksheet Exercises",
    "section": "",
    "text": "This session introduces simple and multiple linear regression models. You will be working with data from Österman (2021) to replicate parts their analysis. We will be covering only basic regression methods in this session, so the article will serve mainly as a broad background to the data here. We will be returning to this article in future weeks too, expanding our modelling strategy as we discover new methods. We will also practice some data management tasks and the basics of data visualisation using principles from ‘the grammar of graphics’ as implemented in the {ggplot2} package (see Kieran Healy’s Data Visualization: A practical introduction for an introduction with many practical examples).\nBy the end of the session, you will:\n\nlearn how to import data from foreign formats (e.g. SPSS, Stata, CSV)\nknow how to perform basic descriptive statistics on a dataset\nunderstand the basics of data visualisation\nknow how to fit linear regression models in R using different functions\nlearn a few options for presenting findings from regression models",
    "crumbs": [
      "Materials",
      "Week 2",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w02.html#setup",
    "href": "materials/worksheets/worksheets_w02.html#setup",
    "title": "Week 2 Worksheet Exercises",
    "section": "Setup",
    "text": "Setup\nIn Week 1 you set up R and RStudio, and an RProject folder (we called it “HSS8005_labs”) with an .R script and a .qmd or .Rmd document in it (we called these “Lab_1”). Ideally, you saved this on a cloud drive so you can access it from any computer (e.g. OneDrive). You will be working in this folder. If it’s missing, complete Exercise 3 from the Week 1 Worksheet.\nYou can create a new .R script and .qmd/.Rmd for this week’s work (e.g. “Lab_2”). Start working in the .R script initially, then switch to .qmd/.Rmd later in the session to report on your final analysis.",
    "crumbs": [
      "Materials",
      "Week 2",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w02.html#exercise-1-load-and-install-r-packages-needed-for-this-lab",
    "href": "materials/worksheets/worksheets_w02.html#exercise-1-load-and-install-r-packages-needed-for-this-lab",
    "title": "Week 2 Worksheet Exercises",
    "section": "Exercise 1: Load (and install) R packages needed for this lab",
    "text": "Exercise 1: Load (and install) R packages needed for this lab\nUsing function we have learnt in Week 1, load (and install, if needed) the following R packages:\n\ntidyverse\neasystats\ngtsummary\nggformula\nsjlabelled",
    "crumbs": [
      "Materials",
      "Week 2",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w02.html#exercise-2-import-external-data",
    "href": "materials/worksheets/worksheets_w02.html#exercise-2-import-external-data",
    "title": "Week 2 Worksheet Exercises",
    "section": "Exercise 2: Import external data",
    "text": "Exercise 2: Import external data\nAs we have seen in Week 1, small datasets that are included in R packages (including base R) for demonstration purposes can be used by simply invoking the name of the dataset. For example, the command head(mtcars) would print out the first six rows (cases) in the “mtcars” dataset included in base R (more specifically, in its “datasets” package). To access a dataset from a non-base-R package, the process is similar, however, we need to ensure that the package is installed on our system and that we specify the name of the package; for example, to access the starwars dataset (which contains all sorts of information about the characters of Star Wars films), we need to make sure that dplyr - or the whole tidyverse - is installed:\n\nhead(starwars) # gives an Error\n\nhead(dplyr::starwars) # works, as long as {dplyr} or the whole {tidyverse} are installed\n\nReal-life datasets, however, need to be imported into R. Datasets come in various formats. R’s native data format has the extension .rds and can be imported with the readRDS() function. The counterpart function saveRDS() exports a dataset to the .rds format. The core-tidyverse {readr} package has similar functions (read_rds() / write_rds()).\nThe .rds format is useful because it can be compressed to various sizes to take up less space, but can only be directly opened in R. It is much more common to encounter data saved in a “delimited” text format, which can be easily opened in a spreadsheet viewer/editor such as Excel. This makes it very interchangeable and therefore very common. The most common is probably the “comma separated values” (.csv) format, which can be imported with the base-R function read.csv() or the tidyverse readr::read_csv() equivalent. Read Chapter 11 in R4DS for more on these functions.\nVery often, you will need to import data saved in the format of another proprietary statistical analysis package such as SPSS or Stata. Large survey projects usually make data available in these formats. The great advantage of these formats is that they can incorporate additional information about variables and the levels of categorical variables (e.g. value labels, specific values for different types of missing values). These additional information can be extremely valuable, but they are not handled straight-forwardly in text-based format, spreadsheets and R’s native data format. To make them operational in R, we need a few specially designed functions.\nThe {haven} package — part of the extended {tidyverse}, meaning that it is installed on your system as part of {tidyverse}, but the library(\"tidyverse\") command does not load it by default; it needs to be loaded explicitly — is one of the most commonly used for this purpose. Functions such as read_sas(), read_sav() and read_dta() import datasets specific to the SAS, SPSS and Stata programs, respectively.\nIt is highly recommended to read the documentation available for the {haven} package to understand how it operates. Fundamentally, it is designed to import data to a intermediary format which stores the additional labelling information in a special format that allows users to access them, but not making them easy to use directly. A suite of packages developed by Daniel Lüdecke from the University of Hamburg offer some additional functionality to work with labels directly when summarising and plotting data. These packages integrate well with the {tidyverse} and are actively maintained, and we will use them in this course to make our lives a bit easier.\nIn a previous step, we have installed and loaded the {sjlabelled} package and the easystats suite of packages, which includes the datawizard package that contains a number of functions that make data(frame) manipulations easier.\nThe functions sjlabelled::read_sas(), sjlabelled::read_spss() and sjlabelled::read_stata() are the sjlabelled equivalents of the haven functions mentioned above. This vignette article included with the package explains the main differences between the two.\nThe more generic function data_read() from easystats’s datawizard package loads data from various formats based on the source files extension, including files from internet sources or compressed files. It relies on the rio package, which provides similar functionality.\n\n\n\n\n\n\nTip\n\n\n\nIt’s important to note that by default the data_read() function assumes that numeric variables where all values have a value label are categorical and will convert them into factors. That means that all the numeric “values” will be replaced by the “value labels” (e.g. 1=“Yes”/ 2=“No” will become simply “Yes”/“No”).\nThis is usually a reasonable default behaviour, because the majority of functions in R do not handle “value labels” and working with textual (character string) values can be more explicit.\nHowever, this may be less appropriate when the dataset contains many long ordered variables (such as 0-10 scale items), as we will most likely want to treat such variables as numeric in statistical models. To cancel this default behaviour, we can add the additional argument convert_factors = FALSE. This is also the format that gets imported when using readRDS().\nHowever, most of the common tabulation and graphing functions will not show the category “labels” in the output either, and for that purpose having variables “converted to factors” (with the original “Values” overwritten by the “Value labels”) may be a better option.\n\n\nAs a first step, let’s import the osterman dataset that underpins the Österman (2021) article (see the Data page on the course website for information about the datasets available in this course):\n\nosterman &lt;- datawizard::data_read(\"https://cgmoreh.github.io/HSS8005-data/osterman.dta\")",
    "crumbs": [
      "Materials",
      "Week 2",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w02.html#exercise-3-summarise-dataset-and-create-a-codebook",
    "href": "materials/worksheets/worksheets_w02.html#exercise-3-summarise-dataset-and-create-a-codebook",
    "title": "Week 2 Worksheet Exercises",
    "section": "Exercise 3: Summarise dataset and create a codebook",
    "text": "Exercise 3: Summarise dataset and create a codebook\n\nUsing functions learnt in Week 1, do the following:\n\ncheck the dimensions of the dataset; what does it tell you?\nprint a summary of the entire dataset; what have you learnt about the data?\n\n\nThere are various other options available for describing variables in different packages. For example, the describe_distribution() function from the datawizard package which is part of the easystats ecosystem that we already installed and loaded is useful for summarising numeric variables, while the data_tabulate() is useful for creating frequency tables of categorical variables.\nRun the commands below and inspect the outputs:\n\ndescribe_distribution(osterman)\n\nA very convenient way to create a codebook for a dataset – especially if it has value-labelled categorical variables – is offered by datawizard::data_codebook() function. The generated codebook describes the variables in the dataset and provides brief summary statistics. We can view this codebook in the RStudio Viewer, or we can save it as an html file. Codebooks are very useful for gaining an overview understanding of a large dataset.\nIn the command below we create an object storing the codebook; once it’s created, open the codebook in the Viewer and inspect it:\n\nosterman_codebook &lt;- data_codebook(osterman)\n\nWe can also generate and view the codebook interactively, without first saving it to an object:\n\ndata_codebook(osterman) |&gt; View()\n\n# or\n\nosterman |&gt; data_codebook() |&gt; View()\n\n# or\n\nView(data_codebook(osterman))\n\nThe result should be the following:\nProblem 1: Some issues when importing data from other software formats\nWe do notice a few strange values for some variables. For example, let’s inspect the ppltrst and dscrgrp variables in a little more detail:\n\nosterman |&gt; data_tabulate(c(ppltrst, dscrgrp))\n\nThe results in the frequency tables look good. So it’s probably something awkward about the labelling. We can check the codebook again; to allow for all levels of the ppltrst variable to be tabulated, we can change the number of maximum values shown from the default 10 to something larger:\n\nosterman |&gt; data_codebook(c(ppltrst, dscrgrp), max_values = 20)\n\nAs we see, the so-called “tagged” NA/missing values are causing the ordering of the values to be unexpected: because of letters appearing as part of a numeric value scale, the scale is automatically ordered following “alphabetic sorting” rather than “natural sorting”. R is not designed to handle “tagged” NA/missing values, but these are commonly used in other statistical software, and the original dataset was imported from a Stata/.dta format. In most cases this will not pose an issue, but it’s safer to convert all “tagged” missing values to standard NAs. We can easily do that with the zap_na_tags() function from the sjlabelled package:\n\nosterman &lt;- sjlabelled::zap_na_tags(osterman)\n\nWe can test the result to see if it is what we would expect:\n\n## testing the results:\n\nosterman |&gt; data_codebook(c(ppltrst, dscrgrp), max_values = 20)",
    "crumbs": [
      "Materials",
      "Week 2",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w02.html#exercise-4-descriptive-visualisation",
    "href": "materials/worksheets/worksheets_w02.html#exercise-4-descriptive-visualisation",
    "title": "Week 2 Worksheet Exercises",
    "section": "Exercise 4: Descriptive visualisation",
    "text": "Exercise 4: Descriptive visualisation\nCreate some basic descriptive graphs using the ggplot() command from the {ggplot2} tidyverse package for the association between the following variables:\n\n‘trustindex3’ and ‘eduyrs25’\n‘trustindex3’ and ‘agea’\n‘trustindex3’ and ‘female’\n\n1. ‘trustindex3’ and ‘eduyrs25’\nThe best way to approach this problem is by working through the first examples in Kieran Healy’s Data Visualization: A practical introduction, starting at Chapter 3, and applying them to your data. Outside class, you can develop these basic graphs into better looking ones by adding various extra layers. The ggplot() function is part of the ggplot2 package, which is included in the core tidyverse, so we don’t need to load it separately if we have already loaded the tidyverse.\nThe ggplot approach to graphs is to build them up step-by-step using various layers. The basic template code for a ggplot() graph is the following:\nggplot(data = &lt;DATA&gt;, mapping = aes(&lt;MAPPINGS&gt;)) +  &lt;GEOM_FUNCTION&gt;()\nFor example, the code below sets up a totally blank canvas:\n\nggplot()\n\nThe result is the same if we specify a data-frame object only. The commands below are equivalent\n\nggplot(data = osterman)\nggplot(osterman)\n\nTo start populating the canvas we need to add a first layer containing the variables we want to ‘map’ using the aes() argument (for “aesthetic mapping”). This adds coordinates to the canvas based on the values of the variable we are mapping. For example, in the code below we ‘map’ the trustindex3 variable on the y (vertical) axis:\n\n# either:\nggplot(data = osterman, aes(y = trustindex3))\n\n# or:\nggplot(osterman, aes(y = trustindex3))\n\n# or:\nggplot(aes(y = trustindex3), data = osterman)\n\n# but this is not sufficient, as the data is expected to be the first object by default:\nggplot(aes(y = trustindex3), osterman)\n\n\nggplot(osterman, aes(y = trustindex3))\n\nWe now see the canvas partitioned by horizontal grid lines, equally paced within the minimum value of 0 and maximum of 10, which are the limits of the trustindex3 variable. We could also ‘map’ the trustindex3 variable on the x (horizontal) axis:\n\nggplot(osterman, aes(x = trustindex3))\n\nWe have the same canvas as before, but transposed.\nIf we are interested in plotting the relationship between two variables (in our case, trustindex3 and eduyrs25), we can ‘map’ one on the y axis and the other on the x axis. The choice of which variable should go where is our decision, but because in our analysis we are treating trustindex3 as the outcome (dependent) variable, the convention is to position it on the y axis.1\n\nggplot(osterman, aes(y = trustindex3, x = eduyrs25))\n\nWe now have a basic layer, but no actual data. The next crucial move is to add another layer with the type of graph we wish to produce (called a “geom” in ggplot, short for “geometric object”, such as a bar, a line, a boxplot, histogram, etc.) using the + operator. For example, we could produce a histogram of the trustindex3 variable by adding + geom_histogram() to the earlier mapping code:\n\n# mapped to `x`\nggplot(osterman, aes(x = trustindex3)) + geom_histogram()\n\n# mapped to `y`\nggplot(osterman, aes(y = trustindex3)) + geom_histogram()\n\nWe could also structure the command differently, by mapping the aesthetics within the geom function:\n\nggplot(osterman) + geom_histogram(aes(x = trustindex3))\n\n# or simply:\n\nggplot(osterman) + geom_histogram(aes(trustindex3))\n\nOr even separating the aesthetics specification out completely:\n\nggplot(osterman)  + aes(trustindex3) + geom_histogram()\n\nWhichever style we choose, we should aim for consistency in our code. Each may have advantages and disadvantages when expanding the function with various other more complex specifications for customising the graphs further, but we will not cover visualisation in that much detail in this course. Kieran Healy’s book on data visualisation is a good resource for ideas that you can test out.\nTo visualise the relationship between trustindex3 and eduyrs25, given that both variables are measured on a numeric scale (or at least on an ordinal scale with seven or more categories), the best option is a scatterplot. In ggplot(), a scatterplot “geom” is called with geom_point():\n\nggplot(osterman, aes(y = trustindex3, x = eduyrs25)) + geom_point()\n\nWe now have a scatterplot of the relationship between ‘trustindex3’ and ‘eduyrs25’. However, our data presents some challenges: our measurement scales are relatively short (length(unique(na.omit(osterman$trustindex3))) = 40 and length(unique(na.omit(osterman$eduyrs25))) = 26) and the data are spread out across all categories. As such, the points that we see on the plot actually represent a great number of overlapping data points. But does each represent the same number of overlapping points, or is there variation? There are a few tricks that we can employ to improve this visualisation. The function geom_jitter() (a shortcut to the specification geom_point(position = \"jitter\")) is helpful in such cases because it adds a small amount of random variation to the location of each point, making areas of overlapping points more visible. The commands below do the same thing:\n\nggplot(osterman, aes(y = trustindex3, x = eduyrs25)) +\n  geom_point(position = \"jitter\")\n\n\nggplot(osterman, aes(y = trustindex3, x = eduyrs25)) +\n  geom_point() + \n  geom_jitter()\n\n\nggplot(osterman, aes(y = trustindex3, x = eduyrs25)) +\n  geom_jitter()\n\nAnother useful specification in this case would be to add some level of transparency to the points. That would allow us to distinguish more clearly between the areas with more or fewer overlapping data points, giving a better indication of where the data is clustered and whether there is any noticeable ttrend in that distribution. We can add transparency to a colour with the alpha option. An alpha = 1 means no transparency (the default), while an alpha level closer to 0 represents higher levels of transparency. Given the large number of data-points in our case, a rather high transparency level of 0.1 is probably a good option:\n\nggplot(osterman, aes(y = trustindex3, x = eduyrs25)) +\n  geom_point(position = \"jitter\", alpha = 0.1)\n\nThere seems to be some positive trend in the way the data is distributed, but to get a better sense we can add another geom, geom_smooth(), which provides a set of options. This geom plots “smooth lines” representing various types of regression fit lines. The function fits a regression in the background and graphs the results. The default setting is to fit a generalized additive model that captures non-linearities in the data with a smoothing spline (the Wikipedia article on GAMs gives a maths-heavy outline of these models, but they are beyond our interests here). The produced output is probably more informative about the general idea:\n\nggplot(osterman, aes(y = trustindex3, x = eduyrs25)) +\n  geom_jitter(alpha = 0.1) +\n  geom_smooth()\n\nBut we can also specify other regression methods, and because we are here aiming to model the relationship between trust and education as a linear model, we can specify the method as “lm”:\n\nggplot(osterman, aes(y = trustindex3, x = eduyrs25)) +\n  geom_jitter(alpha = 0.1) +\n  geom_smooth(method = \"lm\")\n\nNow we get a straight regression line, which is basically the visual representation of the bivariate linear regression model that we will fit in Exercise 5 below.\nThere are numerous further specifications that can be added to improve the graph. We won’t go into much more detail about these additional options here, but as a taster, let’s say that we want to make the regression line more pronounced by changing its colour to red:\n\nggplot(osterman, aes(y = trustindex3, x = eduyrs25)) +\n  geom_jitter(alpha = 0.1) +\n  geom_smooth(method = \"lm\", colour = \"red\")\n\n2. ‘trustindex3’ and ‘agea’\nWe can now do something similar for the relationship between trust and age (the ‘trustindex3’ and ‘agea’ variables in the dataset). Again, both variables are measured on a numeric scale, so a scatterplot should work best. Because we don’t know what to expect and therefore what additional settings would improve each individual graph, we start from the most basic informative layer and build up from there. To practice some alternative approaches to working with plots, here we will first save the basic plot as a ggplot object, to which we can later add further layers and specifications:\n\nage_plot &lt;- ggplot(osterman, aes(y = trustindex3, x = agea)) +\n  geom_point()\n\nIf no output was generated from the command above, that’s as expected. The graph was produced, but we didn’t ask for it to be printed, we only asked for it to be saved as an object called “age_plot”. To see it, we can simply call “age_plot”. We can then make various additions to this plot.\n\nage_plot\n\nThis looks very similar to the previous graph, so we could add the same additional specifications as in the previous exercise, this time to the plot object that we saved:\n\nage_plot +\n  geom_jitter(alpha = 0.1) +\n  geom_smooth(method = \"lm\", colour = \"red\")\n\nThe association between age and trust appears very weak, something that we will explore further in Exercise 5.\n3. ‘trustindex3’ and ‘female’\nWe can try a similar scatterplot here too, but there may be better options:\n\nggplot(osterman, aes(y = trustindex3, x = female)) +\n  geom_point(alpha = 0.1)\n\nA scatterplot expects two continuous variables, but the female variable only has two levels (categories) numerically coded as {0, 1}. Because of this, the geom_point() plot type effectively treats it as a continuous measure with all values in-between 0 and 1 missing. We can see in the plot the variation across trust within each sex category, but it’s hard to get a sense of any differences between the sexes. We could - as we did before - apply jitter and transparency to the plotted values and add in a linear regression fit line:\n\nggplot(osterman, aes(y = trustindex3, x = female)) +\n  geom_point() +\n  geom_jitter(alpha = 0.1) +\n  geom_smooth(method = \"lm\", colour = \"red\")\n\nPerhaps this highlights a bit better how the geom_jitter() function actually works; it pulls overlapping data points apart, so that the areas with fewer overlapping data points (i.e. where the distribution is thinner) are more clearly distinguishable from the areas with more overlapping data points (i.e. where the distribution is thicker). Here it is much more obvious than in the previous example that the plot with the jitter is just a visual artefact: we, of course, have not created any new “sexes” with values of 0.4 or 0.6 in-between 0 and 1, even though visually that’s what we see.\nThere are various further options that we could add, for example we could change the width and height of the jitter, the alpha level, and even the number of break points on the x scale (to make the plot even more confusing):\n\na &lt;- ggplot(osterman, aes(y = trustindex3, x = female)) +\n  geom_jitter(width = NULL, \n              height = NULL,\n              alpha = 1) +\n  geom_smooth(method = \"lm\", colour = \"red\", linewidth = 0.1) +\n  scale_x_continuous(breaks = c(0, 0.4, 0.6, 1)) +\n  ggtitle(\"geom_jitter() defaults\")\n\nb &lt;- ggplot(osterman, aes(y = trustindex3, x = female)) +\n  geom_jitter(width = 0.45, \n              height = 0.5,\n              alpha = 0.1) +\n  geom_smooth(method = \"lm\", colour = \"red\", linewidth = 0.3) +\n  scale_x_continuous(breaks = c(0, 0.4, 0.6, 1)) +\n  ggtitle(\"w=0.45; h=0.5; \\u03b1=0.1\")\n\nc &lt;- ggplot(osterman, aes(y = trustindex3, x = female)) +\n  geom_jitter(width = 0.5, \n              height = 3,\n              alpha = 0.01) +\n  geom_smooth(method = \"lm\", colour = \"red\", linewidth = 0.3) +\n  scale_x_continuous(breaks = c(0, 0.4, 0.6, 1)) +\n  ggtitle(\"w=0.5; h=3.5; \\u03b1=0.01\")\n\nBecause female is a dichotomous/binary factor (categorical) variable, we would be better off using another “geom”. A good visualisation tool in the this case is a boxplot, which can be called with the geom_boxplot() function:\n\nggplot(osterman, aes(y = trustindex3, x = female)) +\n  geom_boxplot()\n\nThe issue with this graph is that the female variable, while a dichotomous/binary categorical variable, is not labelled; instead, the value 1 is taken to represent the “true” value for the name of the variable (i.e. 1 means that one is female, as the variable name states, and the value 0 means that they are not female, but male).\nWe could use the set_labels() function from the sjlabelled package to add labels to this variable:\n\nosterman &lt;- osterman |&gt; \n  sjlabelled::set_labels(female, labels = c(\"Male\", \"Female\"))\n\nThe sjlabelled package also has a special variable type - as_label() - which is useful for forcing R to use the labels of factor variables in outputs. In the command below, we first change the variable type with as_label(), then we run the same ggplot(_) function as before:\n\n# We are overwriting the original dataset here, so we better not make a mistake:\nosterman &lt;- osterman |&gt; mutate(female = sjlabelled::as_label(female))\n\n# And from now on the 'female' variable will be treated as a labelled factor:\nggplot(osterman, aes(y = trustindex3, x = female)) +\n  geom_boxplot()\n\nBox-plots contain a lot of useful summary information about variables, and the interpretation of the shapes is the following:\n\n\nbox-plot\n\nIn the case above, where we compare the average (median) level of trust across males and females in the data, we find that the two sexes do not differ much at all. We can also check a more precise numeric comparison; using the dplyr package, we could do:\n\nosterman |&gt; \n  group_by(female) |&gt; \n  summarise(Mean=mean(trustindex3), Median=median(trustindex3), SD=sd(trustindex3))",
    "crumbs": [
      "Materials",
      "Week 2",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w02.html#exercise-5-fit-simple-bivariate-regression-models-using-ols",
    "href": "materials/worksheets/worksheets_w02.html#exercise-5-fit-simple-bivariate-regression-models-using-ols",
    "title": "Week 2 Worksheet Exercises",
    "section": "Exercise 5: Fit simple bivariate regression models using OLS",
    "text": "Exercise 5: Fit simple bivariate regression models using OLS\nFit three simple bivariate OLS regressions using the lm() function:\n\nRegress ‘trustindex3’ on ‘eduyrs25’ and interpret the results\nRegress ‘trustindex3’ on ‘agea’ and interpret the results\nRegress ‘trustindex3’ on ‘female’ and interpret the results\nRegress ‘trustindex3’ on all three predictors listed above and interpret the results\n\n1. Regress ‘trustindex3’ on ‘eduyrs25’ and interpret the results\nWe will do just that, saving the regression as an object called “m1” (for model 1):\n\nm1 &lt;- lm(trustindex3 ~ eduyrs25, data = osterman)\n\nThe model object has now been saved in the Environment, and we can inspect it manually if we want by opening it in the Source window. The object is a large list, with various components that we can call and print separately. The most basic information that we can obtain from the model is the coefficients:\n\ncoefficients(m1)\n\nThis basic information is enough to solve the linear equation underpinning the model:\n\\[ y_i=b_0+b_1x_i \\] The coefficients correspond to the \\(b\\)’s in this simple model, and we can plug the values in to obtain\n\\[ trust_i=3.91 + 0.11 \\times education_i \\]\nWe find, thus, that the number of years spent in education has a positive outcome on social trust, with each additional year of education associated with a 0.11-points higher score on the trust index, above the baseline of 3.91 points in the case when education is equal to 0. With this formula we can calculate predictions of the trust score for any individual \\(i\\) from their years of education.\nWe can also get more information about the model with the summary() function. When applied to a linear model object, it provides the following output:\n\nsummary(m1)\n\nThis output tells us a lot more about the fitted model, for example a summary table of the residuals and an analysis of variance (ANOVA) summary of the residuals, as well as estimates of variation for our coefficients (the standard errors and the p-values associated with t-tests - displayed as Pr(&gt;|t|)).\nWhile these are informative, the format is not ideal for further manipulation and presentation. Several user-written functions exist to improve on this output. For example, the {broom} package - part of the {tidymodels} suite of packages - has functions to extract model information into “tidy” tibbles (data sets), which can then be further manipulated and plotted. This is especially useful when working with results from many models that would benefit from comparing in a standardised format.\nThe summary() function prints out a lot of information, but it’s not the best format if we wish to reuse the various statistical components for further analysis, and the presentation of the output could also be improved. The model_parameters() and the model_performance() functions from the parameters package part of easystats is a better option:\n\nmodel_parameters(m1) \n\nmodel_performance(m1)\n\nThe output table shows both 95% confidence intervals (CI) and the standard errors (SE), which can be easier to interpret (CI are calculated as Estimate +/- (1.96 x Std. Error); you can try it out in the Console, replacing in the numeric values).\nThe best approach is to graph the model results and present them in a figure, but that’s not very informative in the case of a simple model with only one predictor, so we can leave it for later.\n2. Regress ‘trustindex3’ on ‘agea’ and interpret the results\nWe can do as above:\n\n# Write your own code; name the mode \"m2\"\n\n3. Regress ‘trustindex3’ on ‘female’ and interpret the results\n\n# Write your own code; name the model \"m3\"\n\n4. Regress ‘trustindex3’ on all three predictors listed above and interpret the results\nFinally we can fit a multiple linear model with several predictors:\n\n# Write your own code; name the model \"m4\"\n\nOne interesting finding from Model 4 is to notice how radically the statistical significance of the female variable changes compared to Model 3. The impact of gender is still very weak in real terms: compared to men of similar age and education level, women score 0.04 points higher on the trust scale; but this is still a stronger effect than in the simple bivariate model (where \\(b_1\\) was 0.008), and our confidence intervals are much narrower.\nIt’s worth noticing that the number of observations used in the two models is not the same, due to missing values in some variables. We could make the samples comparable by selecting out the sample of 68,211 included in Model 4, then refitting Model 3 on that sample only:\n\nsample &lt;- m4$model\n\nm3_new &lt;- lm(trustindex3 ~ female, data = sample)\n\nmodel_parameters(m3) \n\nWe see that this does not affect the overall picture.",
    "crumbs": [
      "Materials",
      "Week 2",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w02.html#exercise-6-advanced-apply-the-model-to-a-new-dataset",
    "href": "materials/worksheets/worksheets_w02.html#exercise-6-advanced-apply-the-model-to-a-new-dataset",
    "title": "Week 2 Worksheet Exercises",
    "section": "Exercise 6 (Advanced): Apply the model to a new dataset",
    "text": "Exercise 6 (Advanced): Apply the model to a new dataset\nThe ostermann data originates from Waves 1-9 of the European Social Survey. The ESS data are accessible freely upon registration. As part of this exercise, access data from Wave 10 of the survey (from this site: https://www.europeansocialsurvey.org/data/) and perform the following tasks:\n\ndownload the dataset to the Rproject folder\nselect the variables required to recreate the data to fit the multiple regression model from the previous exercise\ncreate your version of the ‘trustindex3’ variable\nfit the models from Exercise 2 and compare the results.\n\nYou should already be familiar with the functions needed to complete each of these steps, but it may require some self-study. The most important missing information required to complete this exercise is to be found in the description on how the trustindex3 scale was computed:\n\nTo study generalized social trust, I am following the established approach of using a validated three-item scale (Reeskens and Hooghe 2008; Zmerli and Newton 2008). This scale consists of the classic trust question, an item on whether people try to be fair, and an item on whether people are helpful:  - ‘Generally speaking, would you say that most people can be trusted, or that you can’t be too careful in dealing with people?’  - ‘Do you think that most people would try to take advantage of you if they got the chance, or would they try to be fair?’  - ‘Would you say that most of the time people try to be helpful or that they are mostly looking out for themselves?’  All of the items may be answered on a scale from 0 to 10 (where 10 represents the highest level of trust) and the scale is calculated as the mean of the three items. The three-item scale clearly improves measurement reliability and cross-country validity compared to using a single item, such as the classic trust question. … See the Supplementary material for additional information on the construction of the social trust scale (Section A.1), as well as for models using the classic single-item measure of trust (Section A.9).",
    "crumbs": [
      "Materials",
      "Week 2",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w02.html#footnotes",
    "href": "materials/worksheets/worksheets_w02.html#footnotes",
    "title": "Week 2 Worksheet Exercises",
    "section": "Footnotes",
    "text": "Footnotes\n\nThis “convention” makes sense conceptually, if we think about plotting in the same way as we think about modelling - i.e. that we are describing the y variable as a function of the x variable. As we will see later, the ggformula package expands {ggplot} precisely alongside this logic, by simplifying the ggplot() syntax so that it resembles the syntax of the linear model-fitting function lm(). For our example, ggplot2::ggplot(osterman, aes(y = trustindex3, x = eduyrs25)) + geom_point() is equivalent to ggformula::gf_point(osterman, trustindex3 ~ eduyrs25).↩︎",
    "crumbs": [
      "Materials",
      "Week 2",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w04.html",
    "href": "materials/worksheets/worksheets_w04.html",
    "title": "Week 4 Worksheet Exercises",
    "section": "",
    "text": "By the end of the session you will learn how to:\n\nfit, visualise and interpret results from regression models that include interaction terms",
    "crumbs": [
      "Materials",
      "Week 4",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w04.html#aims",
    "href": "materials/worksheets/worksheets_w04.html#aims",
    "title": "Week 4 Worksheet Exercises",
    "section": "",
    "text": "By the end of the session you will learn how to:\n\nfit, visualise and interpret results from regression models that include interaction terms",
    "crumbs": [
      "Materials",
      "Week 4",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w04.html#setup",
    "href": "materials/worksheets/worksheets_w04.html#setup",
    "title": "Week 4 Worksheet Exercises",
    "section": "Setup",
    "text": "Setup\nCreate a worksheet document\nIn Week 1 you set up R and RStudio, and an RProject folder (we called it “HSS8005_labs”) with an .R script and a .qmd or .Rmd document in it (we called these “Lab_1”). Ideally, you saved this on a cloud drive so you can access it from any computer (e.g. OneDrive). You will be working in this folder. If it’s missing, complete Exercise 3 from the Week 1 Worksheet.\nCreate a new Quarto markdown file (.qmd) for this session (e.g. “Lab_4.qmd”) and work in it to complete the exercises and report on your final analysis.\nLoad R packages\nUsing functions learnt in Week 1, load (and install, if needed) the following R packages:\n\ntidyverse\neasystats\ngtsummary\nggformula\nsjlabelled\nggeffects\nmarginaleffects",
    "crumbs": [
      "Materials",
      "Week 4",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w04.html#introduction",
    "href": "materials/worksheets/worksheets_w04.html#introduction",
    "title": "Week 4 Worksheet Exercises",
    "section": "Introduction",
    "text": "Introduction\nThis session explores examples of interactions in regression models. We will look more closely at some of the multiple regression models we have fit in previous labs and ask whether the effects of core explanatory variables could be said to depend on (or are conditioned on) the values of other explanatory variables included in the model. In practice, this will involve including the product of two explanatory variables in the model. Thus, taking a regression model of the generic form \\(y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\epsilon\\), we ask whether there is an interaction between variables \\(X_1\\) and \\(X_2\\) (i.e. whether the effect of one depends on the values of the other) by fitting a model of the form \\(y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\color{green}{\\beta_3(X_1 \\times X_2)} + \\epsilon\\), where we are interested in the “interaction effect” represented by \\(\\beta_3\\).\nWhile fitting such interaction models is simple in practice, understanding when they are needed, interpreting, and communicating their results can be challenging, and a growing literature in the social sciences has explored best practices in relation to such models (Berry, Golder, and Milton 2012; Brambor, Clark, and Golder 2006; Clark and Golder 2023; Hainmueller, Mummolo, and Xu 2019). Advancements in software have also made it easier to interpret and present results from interaction models, with some notable R packages entering this space over the past few years; we have already encountered the marginaleffects and ggeffects packages when visualising results from logistic regression models, and examining results from interaction models presents very similar challenges. In this week’s lab we will use some of these tools to undertake comprehensive analyses of interaction effects.\nWe have already encountered interactions in all of the application readings we have engaged with so far. However, they mostly involved more complex cases of interactions, whose understanding will first require a more basic knowledge of how interaction effects work and how they can be implemented in practice. Wu (2021) and Dingemans and Van Ingen (2015) make use of “cross-level” interactions, which we will revisit when learning about multilevel models (Week 6). Mitchell (2021) uses higher-level interactions on data aggregated at country level as an additional analysis to their main models, while Österman (2021) operates with a quasi-experimental design in which the interaction effect is taken to divulge a more directly causal effect the data. This latter example is “more complex” only at a conceptual and study design level, and we will replicate it in the lab exercises. However, we begin by looking at a conceptually less involved example where interaction effects are at the core of the analysis, also from the field of social trust research.",
    "crumbs": [
      "Materials",
      "Week 4",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w04.html#exercise-1.-akaeda2023trusteducationalgap",
    "href": "materials/worksheets/worksheets_w04.html#exercise-1.-akaeda2023trusteducationalgap",
    "title": "Week 4 Worksheet Exercises",
    "section": "Exercise 1. Akaeda (2023)\n",
    "text": "Exercise 1. Akaeda (2023)\n\nFollowing a review of the literature on the relationship between attitudes towards redistribution, education, and social- and institutional trust, Akaeda (2023) derives a hypothesis they want to investigate: “trust decreases the gap in preferences for redistribution due to education” (p. 296). They break down the hypothesis into two parts, one relating to social trust and the other to institutional trust. In this exercise, follow the description and steps in the Notes page to answer a similar question to this by using only data on European countries from the European Values Study.\n\n\n\n\n\n\nNote\n\n\n\nQuestions\n\nHow would you interpret the effect of education and of social trust on redistributive attitudes based on Model 1?\n\nHow would you interpret the interaction effect of education by social trust on redistributive attitudes based on Model 2?\n\nHow does Akaeda (2023) discuss their findings in respect to social trust? Read the relevant sections in the journal article and attempt to write down our own findings along those lines.\nFit another model with an interaction between female and social trust and attempt an interpretation of the results.",
    "crumbs": [
      "Materials",
      "Week 4",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w04.html#exercise-2.-osterman2021canwetrusteducationfostering-model-1-and-model-2-main-variables",
    "href": "materials/worksheets/worksheets_w04.html#exercise-2.-osterman2021canwetrusteducationfostering-model-1-and-model-2-main-variables",
    "title": "Week 4 Worksheet Exercises",
    "section": "Exercise 2. Österman (2021): Model 1 and Model 2, main variables",
    "text": "Exercise 2. Österman (2021): Model 1 and Model 2, main variables\nFollowing the second example in the Notes, fit models osterman_m1 and osterman_m2.\n\n\n\n\n\n\nNote\n\n\n\nQuestions\n\nRead through the Osterman article and check your understanding of how the author interprets these results. Particularly, how does the interaction model help us elucidate causal factors in this regression model?\nFit another model similar to osterman_m2, but with an interaction between female and reform1_7. How doe you interpret the results from this interaction? Is there a difference in how educational reforms affect social trust among men and women?",
    "crumbs": [
      "Materials",
      "Week 4",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w04.html#exercise-3.-osterman2021canwetrusteducationfostering-model-1-and-model-2-full-covariate-models",
    "href": "materials/worksheets/worksheets_w04.html#exercise-3.-osterman2021canwetrusteducationfostering-model-1-and-model-2-full-covariate-models",
    "title": "Week 4 Worksheet Exercises",
    "section": "Exercise 3. Österman (2021): Model 1 and Model 2, full covariate models",
    "text": "Exercise 3. Österman (2021): Model 1 and Model 2, full covariate models\nAs described in the Notes, the models reported in Table 3 of Österman (2021) also included a number of additional covariates for statistical control (fbrneur, mbrneur, fnotbrneur, mnotbrneur, agea, essround, yrbrn, eform_id_num, including interactions between some of those control variables: yrbrn*yrbrn, yrbrn*reform_id_num, agea*reform_id_num, agea*agea, agea*agea*reform_id_num).\nFit a more detailed version of model osterman_m2 from Exercise 2 that also includes these covariates, and compare your results to the simpler models fit in Exercise 2 and those reported by Österman (2021). Keep in mind that the results will still diverge from those reported in the original study because you are still not using sample weights or clustering.",
    "crumbs": [
      "Materials",
      "Week 4",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w04.html#exercise-4.-osterman2021canwetrusteducationfostering-model-3-flexible-interaction-model",
    "href": "materials/worksheets/worksheets_w04.html#exercise-4.-osterman2021canwetrusteducationfostering-model-3-flexible-interaction-model",
    "title": "Week 4 Worksheet Exercises",
    "section": "Exercise 4. Österman (2021): Model 3, “flexible interaction” model",
    "text": "Exercise 4. Österman (2021): Model 3, “flexible interaction” model\nÖsterman (2021:223) writes:\n\n“In the third main model I allow the effect of parental education to vary with all other independent variables, including the reform-fixed effects. This flexible model explores whether there exists any other conditional relationship between parental education and the covariates that could potentially bias the interaction estimate between parental education and reform exposure”\n\nHe calls this a “flexible interaction” model - also referred to as a “fully dummy-interactive” model given the binary nature of the interaction variable.\nAttempt to fit a model that replicates the “flexible interaction” specification of Model 3 in Table 3 of Österman (2021). This model would include interaction terms not only between “Reform” and “High parental education”, but parental education is also interacted with all the other covariates.",
    "crumbs": [
      "Materials",
      "Week 4",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w06.html",
    "href": "materials/worksheets/worksheets_w06.html",
    "title": "Week 6 Worksheet Exercises",
    "section": "",
    "text": "By the end of the session you will learn how to:\n\nuse survey weights in single-level linear regression models\nestimate variance in hierarchical/clustered data using robust standard errors in a single-level modelling framework\nfit random intercept models to hierarchical/clustered data",
    "crumbs": [
      "Materials",
      "Week 6",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w06.html#aims",
    "href": "materials/worksheets/worksheets_w06.html#aims",
    "title": "Week 6 Worksheet Exercises",
    "section": "",
    "text": "By the end of the session you will learn how to:\n\nuse survey weights in single-level linear regression models\nestimate variance in hierarchical/clustered data using robust standard errors in a single-level modelling framework\nfit random intercept models to hierarchical/clustered data",
    "crumbs": [
      "Materials",
      "Week 6",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w06.html#setup",
    "href": "materials/worksheets/worksheets_w06.html#setup",
    "title": "Week 6 Worksheet Exercises",
    "section": "Setup",
    "text": "Setup\nCreate a worksheet document\nIn Week 1 you set up R and RStudio, and an RProject folder (we called it “HSS8005_labs”) with an .R script and a .qmd or .Rmd document in it (we called these “Lab_1”). Ideally, you saved this on a cloud drive so you can access it from any computer (e.g. OneDrive). You will be working in this folder. If it’s missing, complete Exercise 3 from the Week 1 Worksheet.\nCreate a new Quarto markdown file (.qmd) for this session (e.g. “Lab_6.qmd”) and work in it to complete the exercises and report on your final analysis.",
    "crumbs": [
      "Materials",
      "Week 6",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w06.html#r-packages",
    "href": "materials/worksheets/worksheets_w06.html#r-packages",
    "title": "Week 6 Worksheet Exercises",
    "section": "R packages",
    "text": "R packages\n\n# Just in case we get errors asking that the package repositories be explicitly set when installing new packages:\n\noptions(repos = list(CRAN = \"http://cran.rstudio.com/\"))\n\n# Install and load required packages\n\n# We can use the {pacman} package to easily install and load several packages:\n# ({pacman} itself may need installing if not yet installed)\n\npacman::p_load(\n  tidyverse, easystats, sjlabelled,\n  ggformula, ggeffects, marginaleffects, \n  modelsummary, gtsummary,\n  survey, sandwich, lmtest, lme4)            # new modelling packages",
    "crumbs": [
      "Materials",
      "Week 6",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w06.html#example-1.-osterman2021canwetrusteducationfostering-polynomials-weights-and-clustered-errors",
    "href": "materials/worksheets/worksheets_w06.html#example-1.-osterman2021canwetrusteducationfostering-polynomials-weights-and-clustered-errors",
    "title": "Week 6 Worksheet Exercises",
    "section": "Example 1. Österman (2021): polynomials, weights and clustered errors",
    "text": "Example 1. Österman (2021): polynomials, weights and clustered errors\nIn Worksheet 4 we fitted versions of Models 1-3 reported in Table 3 of Österman (2021) (see also Table A.3. in their Appendix for a more complete reporting on the models).\nComparing the model we fitted to the one reported by the author, our results were very close, but not totally equivalent on several coefficients and standard errors. The main reasons for the divergence had to do with two aspects of the published model that we had disregarded: (1) we did not include survey weights to correct for sampling errors, and (2) we did not allow for intra-group correlation in the standard errors among respondents from the same country (and the same age cohort). We will first implement these two additional steps and compare our final results again to those reported in Österman (2021). Then, we will refit the model in a multilevel/hierarchical framework.\nData management\nAs a first step, let’s import the osterman dataset that underpins the Österman (2021) article (see the Data page on the course website for information about the datasets available in this course). We can download the data to a local folder and load it from there, or we can load it directly from the web (if it works…):\n\n# Import the data\nosterman &lt;- data_read(\"https://cgmoreh.github.io/HSS8005-24/data/osterman.dta\")\n\nIt’s always a good idea to inspect the dataset after importing, to identify any issues. One option is to check a codebook, for example:\n\n# `View` the codebook:\ndata_codebook(osterman) |&gt; View()\n\nWe do notice a few strange values for some variables. For example, let’s inspect the ppltrst and dscrgrp variables in a little more detail:\n\nosterman |&gt; data_tabulate(c(ppltrst, dscrgrp))\n\nMost people can be trusted or you can't be too careful (ppltrst) &lt;numeric&gt;\n# total N=68796 valid N=68733\n\nValue |     N | Raw % | Valid % | Cumulative %\n------+-------+-------+---------+-------------\n0     |  3634 |  5.28 |    5.29 |         5.29\n1     |  2374 |  3.45 |    3.45 |         8.74\n2     |  4621 |  6.72 |    6.72 |        15.46\n3     |  7170 | 10.42 |   10.43 |        25.90\n4     |  6522 |  9.48 |    9.49 |        35.38\n5     | 13962 | 20.29 |   20.31 |        55.70\n6     |  7793 | 11.33 |   11.34 |        67.04\n7     | 11067 | 16.09 |   16.10 |        83.14\n8     |  8374 | 12.17 |   12.18 |        95.32\n9     |  2049 |  2.98 |    2.98 |        98.30\n10    |  1167 |  1.70 |    1.70 |       100.00\n&lt;NA&gt;  |    63 |  0.09 |    &lt;NA&gt; |         &lt;NA&gt;\n\nMember of a group discriminated against in this country (dscrgrp) &lt;numeric&gt;\n# total N=68796 valid N=68565\n\nValue |     N | Raw % | Valid % | Cumulative %\n------+-------+-------+---------+-------------\n1     |  3950 |  5.74 |    5.76 |         5.76\n2     | 64615 | 93.92 |   94.24 |       100.00\n&lt;NA&gt;  |   231 |  0.34 |    &lt;NA&gt; |         &lt;NA&gt;\n\n\nThe results in the frequency tables look good. So it’s probably something awkward about the labelling. We can check the codebook again; to allow for all levels of the ppltrst variable to be tabulated, we can change the number of maximum values shown from the default 10 to something larger:\n\nosterman |&gt; data_codebook(c(ppltrst, dscrgrp), max_values = 20)\n\nosterman (68796 rows and 30 variables, 2 shown)\n\nID | Name    | Label                                                   | Type    |   Missings | Values | Value Labels               |             N\n---+---------+---------------------------------------------------------+---------+------------+--------+----------------------------+--------------\n4  | ppltrst | Most people can be trusted or you can't be too careful  | numeric |  63 (0.1%) |      0 | You can't be too careful   |  3634 ( 5.3%)\n   |         |                                                         |         |            |      1 | 1                          |  2374 ( 3.5%)\n   |         |                                                         |         |            |     10 | Most people can be trusted |  1167 ( 1.7%)\n   |         |                                                         |         |            |      2 | 2                          |  4621 ( 6.7%)\n   |         |                                                         |         |            |      3 | 3                          |  7170 (10.4%)\n   |         |                                                         |         |            |      4 | 4                          |  6522 ( 9.5%)\n   |         |                                                         |         |            |      5 | 5                          | 13962 (20.3%)\n   |         |                                                         |         |            |      6 | 6                          |  7793 (11.3%)\n   |         |                                                         |         |            |      7 | 7                          | 11067 (16.1%)\n   |         |                                                         |         |            |      8 | 8                          |  8374 (12.2%)\n   |         |                                                         |         |            |      9 | 9                          |  2049 ( 3.0%)\n   |         |                                                         |         |            |  NA(a) | Refusal                    |     9 ( 0.0%)\n   |         |                                                         |         |            |  NA(b) | Don't know                 |    41 ( 0.1%)\n   |         |                                                         |         |            |  NA(c) | No answer                  |    13 ( 0.0%)\n---+---------+---------------------------------------------------------+---------+------------+--------+----------------------------+--------------\n7  | dscrgrp | Member of a group discriminated against in this country | numeric | 231 (0.3%) |      1 | Yes                        |  3950 ( 5.7%)\n   |         |                                                         |         |            |      2 | No                         | 64615 (93.9%)\n   |         |                                                         |         |            |  NA(a) | Refusal                    |    29 ( 0.0%)\n   |         |                                                         |         |            |  NA(b) | Don't know                 |   179 ( 0.3%)\n   |         |                                                         |         |            |  NA(c) | No answer                  |    23 ( 0.0%)\n---------------------------------------------------------------------------------------------------------------------------------------------------\n\n\nAs we see, the so-called “tagged” NA/missing values are causing the ordering of the values to be unexpected: because of letters appearing as part of a numeric value scale, the scale is automatically following “alphabetic sorting” rather than “natural sorting”. R is not designed to handle “tagged” NA/missing values, but these are commonly used in other statistical software, and the original dataset was imported from a Stata/.dta format. In most cases this will not pose an issue, but it’s safer to convert all “lagged” missing values to standard NAs. We can easily do that with the zap_na_tags() function from the sjlabelled package:\n\nosterman &lt;- sjlabelled::zap_na_tags(osterman)\n\n## testing the results:\n\nosterman |&gt; data_codebook(c(ppltrst, dscrgrp), max_values = 20)\n\nosterman (68796 rows and 30 variables, 2 shown)\n\nID | Name    | Label                                                   | Type    |   Missings | Values | Value Labels               |             N\n---+---------+---------------------------------------------------------+---------+------------+--------+----------------------------+--------------\n4  | ppltrst | Most people can be trusted or you can't be too careful  | numeric |  63 (0.1%) |      0 | You can't be too careful   |  3634 ( 5.3%)\n   |         |                                                         |         |            |      1 | 1                          |  2374 ( 3.5%)\n   |         |                                                         |         |            |      2 | 2                          |  4621 ( 6.7%)\n   |         |                                                         |         |            |      3 | 3                          |  7170 (10.4%)\n   |         |                                                         |         |            |      4 | 4                          |  6522 ( 9.5%)\n   |         |                                                         |         |            |      5 | 5                          | 13962 (20.3%)\n   |         |                                                         |         |            |      6 | 6                          |  7793 (11.3%)\n   |         |                                                         |         |            |      7 | 7                          | 11067 (16.1%)\n   |         |                                                         |         |            |      8 | 8                          |  8374 (12.2%)\n   |         |                                                         |         |            |      9 | 9                          |  2049 ( 3.0%)\n   |         |                                                         |         |            |     10 | Most people can be trusted |  1167 ( 1.7%)\n---+---------+---------------------------------------------------------+---------+------------+--------+----------------------------+--------------\n7  | dscrgrp | Member of a group discriminated against in this country | numeric | 231 (0.3%) |      1 | Yes                        |  3950 ( 5.8%)\n   |         |                                                         |         |            |      2 | No                         | 64615 (94.2%)\n---------------------------------------------------------------------------------------------------------------------------------------------------\n\n\nPolynomials\nIn the footnotes to Table 3 and Table A.3 in the Appendix, the author tells us:\n\nAll models include reform FEs [Fixed Effects], a general quadratic birth year trend, and reform-specific trends for birth year (linear) and age (quadratic). Additional controls: foreign-born parents and ESS round dummies.\n\nThe tables in the Appendix (Table A.3) “report all of the coefficients for the control variables, except for the age and birth year controls. Since the latter variables are interacted with all of the reform fixed effects, they are not interpretable as single coefficients”.\nIn the main text, the author further explains some of the reasoning behind their modelling choices:\n\nOne dilemma for the design is that there has been a trend of increasing educational attainment throughout the studied time period, which means that the reform-windows of treated and non-treated cohorts will also pick up the effects of this trend. To counter this, [the list of covariates] includes a general quadratic birth year trend, reform-specific linear controls for birth year and reform-specific quadratic age trends. The quadratic terms are included to allow sufficient flexibility in absorbing possible non-linear trends of increasing education within the reform-window of seven treated and seven untreated birth year cohorts. … The reform-fixed effects are also essential because they imply that only the within-reform-window variation is used to estimate the effects and between-reform differences are factored out, such as pre-reform differences in social trust. (Österman 2021:221–22)\n\nBefore we fit the model, some of the concepts in the quotation need unpacking. A quadratic term is a second-degree polynomial term: put simply, it’s the square of the variable concerned. The quadratic of a variable such as \\(age\\) is therefore \\(age^2\\), or \\(age \\times age\\). In other words, it is like a variable’s “interaction” with itself. Because of this, there are several ways in which the quadratic terms to be included in a model can be specified:\n\nWe could create the quadratic terms as new variables, and include those in the model. Effectively, we would be creating new variables/columns in the dataset and using those in the model. We could do that as shown below:\n\n\n# Create new quadratic variables by multiplication with themselves and add them to the dataset, saving it as a new data object:\n\nosterman &lt;- osterman |&gt; \n  mutate(agea_quad = agea*agea,                                                         # quadratic age variable\n         yrbrn_quad = yrbrn*yrbrn) |&gt;                                                   # quadratic birth-year variable\n  sjlabelled::var_labels(agea_quad = \"Age (quadratic)\",                                 # we can label the variable if we want\n                        yrbrn_quad = \"Birth year (quadratic)\")\n\n# We now have two additional variables in the dataset; we can fit a model using those:\n\nm1_prequad &lt;- lm(trustindex3 ~ reform1_7 + female + blgetmg_d +                         # main covariates reported in Table 3\n                   fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) +     # additional controls for foreign-born parents and ESS Round dummies (we treat `round` as a factor for this)\n                   agea + yrbrn + agea_quad + yrbrn_quad +                              # general quadratic birth year trend and quadratic age\n                   factor(reform_id_num) +                                              # reform fixed effects dummies\n                   yrbrn:factor(reform_id_num) +                                        # reform-specific birth year trend\n                   agea:factor(reform_id_num) +  agea_quad:factor(reform_id_num),       # reform-specific quadratic age trend\n               data = osterman)                                                         # the new expanded dataset\n\n\nWe can get the same results by creating the quadratic terms directly as part of the modelling function. The one thing we should keep in mind is that if we want to include standard mathematical operations within a formula function, we need to isolate or insulate the operation from R’s formula parsing code using the I() function, which returns the contents of I(...) “as.is”. The model formula would then be:\n\n\n# Create quadratic terms internally as part of the modelling function:\n\nm1_funquad &lt;- lm(trustindex3 ~ reform1_7 + female + blgetmg_d +                         # main covariates reported in Table 3\n                 fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) +       # additional controls for foreign-born parents and ESS Round dummies (we treat `round` as a factor for this)\n                 agea + yrbrn + I(agea^2) + I(yrbrn^2) +                                # general quadratic birth year trend and quadratic age\n                 factor(reform_id_num) +                                                # reform fixed effects dummies\n                 yrbrn:factor(reform_id_num) +                                          # reform-specific birth year trend\n                 agea:factor(reform_id_num) +  I(agea^2):factor(reform_id_num),         # reform-specific quadratic age trend\n              data = osterman)                                                          # the original dataset\n\n\nIn the two previous options, the quadratic terms will be correlated with the original variables. To avoid this by relying on so-called orthogonal polynomials we should use the poly() function. We can also fit the same correlated polynomial model as the ones above by adding the raw = TRUE option to the poly() function. In the code below, we will fit the correlated version first, then the orthogonal version (This stackoverflow discussion explains in more detail the difference between the two options):\n\n\nm1_polyraw &lt;- lm(trustindex3 ~ reform1_7 + female + blgetmg_d + \n                 fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) + \n                 poly(agea, 2, raw = TRUE) + poly(yrbrn, 2, raw = TRUE) +\n                 factor(reform_id_num) +           \n                 yrbrn:factor(reform_id_num) + \n                 agea:factor(reform_id_num) + poly(agea, 2, raw = TRUE):factor(reform_id_num),\n               data = osterman)\n\nm1_polyorth &lt;- lm(trustindex3 ~ reform1_7 + female + blgetmg_d + \n                 fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) + \n                 poly(agea, 2) + poly(yrbrn, 2) +\n                 factor(reform_id_num) +           \n                 yrbrn:factor(reform_id_num) + \n                 agea:factor(reform_id_num) + poly(agea, 2):factor(reform_id_num),\n               data = osterman)\n\nFor a side-by-side overview comparison of the models we fitted so far, we can use one of the many model summary tabulation functions that exist in various packages. Some popular options are stargazer::stargazer(), jtools::export_summs(), sjPlot::tab_model(), modelsummary::modelsummary() or parameters::compare_models from the easystats ecosystem. Below we will use modelsummary(), which produces publication-ready summary tables in HTML format, but which can easily be exported to other formats, such as Microsoft Word or PDF:\n\n# It's cleaner to first make a list of the models we want to summarise; we can even name them:\nmodels &lt;- list(\n  \"Pre-calculated quadratic\" = m1_prequad,\n  \"Within-function quadratic\" = m1_funquad,\n  \"poly() with raw coding\" = m1_polyraw,\n  \"poly() with default orthogonal coding\" = m1_polyorth\n)\n\n# modelsummary table with stars for p-values added\nmodelsummary::modelsummary(models, stars = TRUE)\n\nThe results from the modelsummary() are not shown here because it’s a long and ugly table, but it’s useful for perusing to compare the results across the different models. We do notice some differences in the affected variables between the orthogonal-codes version and the other versions. It’s worth noting, however, that the Stata routine used by the author fitted correlated/raw coded polynomials, so the orthogonal version from the output above is just for a comparison and we will not use it going forward. We generally want our transformed (polynomial) variables to be correlated with the original variables, as they are in fact measuring the same thing.\nFor a cleaner table showing only the results included in Table A.3 in the Appendix to Österman (2021), we can use the coef_map or the coef_omit option in modelsummary() and only include m1_funquad, which will be the polynomial fitting routine that we will use going forward:\n\n# It's cleaner to first make a vector of the coefficients we wish to include; we can name the coefficients as they appear in Table A.3; note that we also leave out the Intercept, as in the published table:\ncoefs &lt;- c(\"reform1_7\" = \"Reform\",\n           \"female\" = \"Female\",\n           \"blgetmg_d\" = \"Ethnic minority\",\n           \"fbrneur\" = \"Foreign-born father, Europe\",\n           \"mbrneur\" = \"Foreign-born mother, Europe\",\n           \"fnotbrneur\" = \"Foreign-born father, outside Europe\",\n           \"mnotbrneur\" = \"Foreign-born mother, outside Europe\",\n           \"factor(essround)2\" = \"ESS Round 2\",\n           \"factor(essround)3\" = \"ESS Round 3\",\n           \"factor(essround)4\" = \"ESS Round 4\",\n           \"factor(essround)5\" = \"ESS Round 5\",\n           \"factor(essround)6\" = \"ESS Round 6\",\n           \"factor(essround)7\" = \"ESS Round 7\",\n           \"factor(essround)8\" = \"ESS Round 8\",\n           \"factor(essround)9\" = \"ESS Round 9\")\n\n# Then we pass the vector to coef_map to select the coefficients to print\nmodelsummary::modelsummary(list(m1_funquad), stars = TRUE, coef_map = coefs)\n\n\n\n\n (1)\n\n\n\nReform\n0.063*\n\n\n\n(0.027)\n\n\nFemale\n0.058***\n\n\n\n(0.013)\n\n\nEthnic minority\n−0.241***\n\n\n\n(0.054)\n\n\nForeign-born father, Europe\n−0.111**\n\n\n\n(0.042)\n\n\nForeign-born mother, Europe\n−0.108*\n\n\n\n(0.044)\n\n\nForeign-born father, outside Europe\n−0.065\n\n\n\n(0.073)\n\n\nForeign-born mother, outside Europe\n−0.110\n\n\n\n(0.078)\n\n\nESS Round 2\n0.059\n\n\n\n(0.045)\n\n\nESS Round 3\n0.162*\n\n\n\n(0.075)\n\n\nESS Round 4\n0.243*\n\n\n\n(0.108)\n\n\nESS Round 5\n0.360*\n\n\n\n(0.144)\n\n\nESS Round 6\n0.397*\n\n\n\n(0.179)\n\n\nESS Round 7\n0.449*\n\n\n\n(0.212)\n\n\nESS Round 8\n0.655**\n\n\n\n(0.246)\n\n\nESS Round 9\n0.816**\n\n\n\n(0.283)\n\n\nNum.Obs.\n68796\n\n\nR2\n0.200\n\n\nR2 Adj.\n0.198\n\n\nAIC\n268913.8\n\n\nBIC\n270056.1\n\n\nLog.Lik.\n−134331.877\n\n\nRMSE\n1.71\n\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\nWe can compare our table to the published one; there will, of course, be some differences, as our model specification is still not the same as that of the original paper. One source of the inconsistencies are the use of “survey weights” in the original article.\nSurvey weights\nOne of the differences between our coefficients and the ones in the published table is due to the fact that we did not account for survey weights, while in Österman (2021), p. 220:\n\nThe data are weighted using ESS design weights\n\nTo understand in more detail what this means, we need some understanding of how weights are constructed in the European Social Survey (ESS). In a nutshell, ESS data are distributed containing 3 types of weights:\n\ndweight: These are the so-called design weights. Quoting the ESS website: “the main purpose of the design weights is to correct for the fact that in some countries respondents have different probabilities to be part of the sample due to the sampling design used.” These weights have been built to correct for the coverage error, that is, the error created by the different chances that individuals from the target population are covered in the sample frame.\npspwght: These are the post-stratification weights. According the the ESS website, these “are a more sophisticated weighting strategy that uses auxiliary information to reduce the sampling error and potential non-response bias.” These weights have been computed after the data has been collected, to correct from differences between population frequencies observed in the sample and the “true” population frequencies (i.e. those provided by the Labour Force Survey funded by the EU and available on Eurostat). Unlike the design weights, which are based on the probability of inclusion of different groups of individuals in the sample frames, these have been calculated starting from variables that are there in the data, and are really an “adjustment” of the design weight made to reach observed frequencies that match those of the target population.\npweight: These are the population size weights. These weights have the purpose to match the numbers of observations collected in each country to the country populations. They are to be used only when we calculate statistics on multiple countries (for instance, unemployment in Scandinavia). Their value is the same for all observations within the same country.\n\nThere is a lot to be said about survey weights and options for dealing with them, which we will not cover in more detail in this course. But as part of this exercise we will get to know some functions that can help with including survey weights and can be extended to include more complex design weights as well. Specifically, we will look at the survey package\nWe start by creating a weighted data object using the svydesign() function from survey, which includes the dweight as used in the original article:\n\n## Create weighted data\nosterman_w &lt;- svydesign(id = ~1,                 # specifying cluster IDs is needed; ~0 or ~1 means no clusters\n                        weights = ~dweight,      # we apply the design weights\n                        data = osterman)\n\nWe then fit the model using the svyglm() function from the survey package and save the model object; note that we specify a design = option with the weighted data object we created earlier:\n\nm1_w &lt;- svyglm(trustindex3 ~ reform1_7 + female + blgetmg_d + \n           fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) + \n           agea + yrbrn + I(agea^2) + I(yrbrn^2) +\n           factor(reform_id_num) +           \n           yrbrn:factor(reform_id_num) + agea:factor(reform_id_num) +  \n           I(agea^2):factor(reform_id_num),\n       design = osterman_w, data = osterman) \n\nTo compare the results from the weighted model to the one we produced earlier, we can check them in a modelsummary() table; we can reuse the list of coefficients to display that we created earlier:\n\n# List and name the models\nmodels &lt;- list(\n  \"Unweighted model\" = m1_funquad,\n  \"Weighted model\" = m1_w)\n\n# Tabulate the models\nmodelsummary::modelsummary(models, stars = TRUE, coef_map = coefs)\n\n\n\n\nUnweighted model\nWeighted model\n\n\n\nReform\n0.063*\n0.063*\n\n\n\n(0.027)\n(0.029)\n\n\nFemale\n0.058***\n0.061***\n\n\n\n(0.013)\n(0.014)\n\n\nEthnic minority\n−0.241***\n−0.261***\n\n\n\n(0.054)\n(0.066)\n\n\nForeign-born father, Europe\n−0.111**\n−0.090*\n\n\n\n(0.042)\n(0.046)\n\n\nForeign-born mother, Europe\n−0.108*\n−0.092*\n\n\n\n(0.044)\n(0.046)\n\n\nForeign-born father, outside Europe\n−0.065\n−0.053\n\n\n\n(0.073)\n(0.079)\n\n\nForeign-born mother, outside Europe\n−0.110\n−0.087\n\n\n\n(0.078)\n(0.082)\n\n\nESS Round 2\n0.059\n0.052\n\n\n\n(0.045)\n(0.047)\n\n\nESS Round 3\n0.162*\n0.148+\n\n\n\n(0.075)\n(0.080)\n\n\nESS Round 4\n0.243*\n0.253*\n\n\n\n(0.108)\n(0.114)\n\n\nESS Round 5\n0.360*\n0.364*\n\n\n\n(0.144)\n(0.153)\n\n\nESS Round 6\n0.397*\n0.403*\n\n\n\n(0.179)\n(0.190)\n\n\nESS Round 7\n0.449*\n0.458*\n\n\n\n(0.212)\n(0.224)\n\n\nESS Round 8\n0.655**\n0.671*\n\n\n\n(0.246)\n(0.261)\n\n\nESS Round 9\n0.816**\n0.835**\n\n\n\n(0.283)\n(0.299)\n\n\nNum.Obs.\n68796\n68796\n\n\nR2\n0.200\n0.206\n\n\nR2 Adj.\n0.198\n0.204\n\n\nAIC\n268913.8\n\n\n\nBIC\n270056.1\n305027.4\n\n\nLog.Lik.\n−134331.877\n−151817.519\n\n\nRMSE\n1.71\n1.71\n\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\nWe can check our results again to those published in Table A.3 in the Appendix to Österman (2021), and we will see that all the coefficients are almost the same now.\nThe remaining differences are in the standard error estimates, and those are due to the fact that we did not use robust standard errors to account for intra-group correlation.\nVariance estimation using robust clustered errors\nÖsterman (2021:222) write that:\n\nAll models are estimated with OLS, … and apply country-by-birth year clustered robust standard errors. [Footnote: An alternative would be to cluster the standard errors on the country level but such an approach would risk to lead to biased standard errors because of too few clusters]\n\nApplying clustered robust standard errors is a more elementary and less flexible way to account for breaches of the iid assumptions of OLS (that our variables are “independent and identically distributed”) than fitting a mixed-effects (multilevel, hierarchical) model. There is a vast literature assessing whether one approach is better suited than the other in different contexts. To get a feel for the issues in question and for a deeper understanding of how these methods are useful, compare the analysis of Cheah (2009), whose results “suggest that modeling the clustering of the data using a multilevel methods is a better approach than fixing the standard errors of the OLS estimate”, to that of McNeish, Stapleton, and Silverman (2017), who discuss a number of cases (focusing on psychology literature) where cluster-robust standard error may be more advantageous than multilevel/hierarchical modelling.\nWe will first fit our model using clustered robust standard errors, as done by Österman (2021), then we will check the results against those we would obtain from a multilevel model design to see how the risk related to the low number of country clusters affects the results.\nThe standard was of applying error corrections is by using the sandwich and {lmtest} packages, but they do not handle well the summary objects produced by the survey package for weighted estimates. Using the unweighed model we fitted earlier, we could do the following:\n\n# extract variance-covariance matrix with clustered correction\nvc_cl &lt;- vcovCL(m1_funquad, type='HC1', cluster=~cntry_cohort)\n\n# get coefficients\nm1_funquad_cl &lt;- coeftest(m1_funquad, vc_cl)\n\n## Or, the two steps above can be combined into one call:\n\nm1_funquad_cl2 &lt;- coeftest(m1_funquad, \n                          vcovCL, type='HC1', cluster = ~cntry_cohort)\n\n# And we can check that the two have the same result:\nall.equal(m1_funquad_cl, m1_funquad_cl2)\n\n[1] TRUE\n\n\nLet’s tabulate the results for comparison:\n\n# List and name the models\nmodels &lt;- list(\n  \"Unweighted model\" = m1_funquad,\n  \"Weighted model\" = m1_w,\n  \"Unweighted model with cluster-robust errors\" = m1_funquad_cl)\n\n# Tabulate the models\nmodelsummary::modelsummary(models, stars = TRUE, coef_map = coefs)\n\n\n\n\nUnweighted model\nWeighted model\nUnweighted model with cluster-robust errors\n\n\n\nReform\n0.063*\n0.063*\n0.063*\n\n\n\n(0.027)\n(0.029)\n(0.029)\n\n\nFemale\n0.058***\n0.061***\n0.058***\n\n\n\n(0.013)\n(0.014)\n(0.015)\n\n\nEthnic minority\n−0.241***\n−0.261***\n−0.241***\n\n\n\n(0.054)\n(0.066)\n(0.060)\n\n\nForeign-born father, Europe\n−0.111**\n−0.090*\n−0.111*\n\n\n\n(0.042)\n(0.046)\n(0.046)\n\n\nForeign-born mother, Europe\n−0.108*\n−0.092*\n−0.108*\n\n\n\n(0.044)\n(0.046)\n(0.047)\n\n\nForeign-born father, outside Europe\n−0.065\n−0.053\n−0.065\n\n\n\n(0.073)\n(0.079)\n(0.077)\n\n\nForeign-born mother, outside Europe\n−0.110\n−0.087\n−0.110\n\n\n\n(0.078)\n(0.082)\n(0.086)\n\n\nESS Round 2\n0.059\n0.052\n0.059\n\n\n\n(0.045)\n(0.047)\n(0.044)\n\n\nESS Round 3\n0.162*\n0.148+\n0.162*\n\n\n\n(0.075)\n(0.080)\n(0.079)\n\n\nESS Round 4\n0.243*\n0.253*\n0.243*\n\n\n\n(0.108)\n(0.114)\n(0.115)\n\n\nESS Round 5\n0.360*\n0.364*\n0.360*\n\n\n\n(0.144)\n(0.153)\n(0.154)\n\n\nESS Round 6\n0.397*\n0.403*\n0.397*\n\n\n\n(0.179)\n(0.190)\n(0.190)\n\n\nESS Round 7\n0.449*\n0.458*\n0.449*\n\n\n\n(0.212)\n(0.224)\n(0.224)\n\n\nESS Round 8\n0.655**\n0.671*\n0.655*\n\n\n\n(0.246)\n(0.261)\n(0.262)\n\n\nESS Round 9\n0.816**\n0.835**\n0.816**\n\n\n\n(0.283)\n(0.299)\n(0.298)\n\n\nNum.Obs.\n68796\n68796\n68796\n\n\nR2\n0.200\n0.206\n\n\n\nR2 Adj.\n0.198\n0.204\n\n\n\nAIC\n268913.8\n\n406007.8\n\n\nBIC\n270056.1\n305027.4\n1033594.4\n\n\nLog.Lik.\n−134331.877\n−151817.519\n\n\n\nRMSE\n1.71\n1.71\n\n\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\nThe error-correction does not have an impact on the coefficients, but it did affect the standard errors. Notice that the standard errors came closer to those in the weighted model without any error correction, showing that the weighting procedure already applies an error correction, albeit not specifically on the cluster variable cntry_cohort.\nAn easy way to include information on the clustering directly in the svydesign() function is to add cluster IDs:\n\n# Re-specify the survey design\nosterman_w_cl &lt;- svydesign(id = ~cntry_cohort,        # This time we add cntry_cohort as id\n                         weights = ~dweight, \n                         data = osterman)\n\n# Re-fit the model with the new survey design\nm1_w_cl &lt;- svyglm(trustindex3 ~ reform1_7 + female + blgetmg_d + \n               fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) + \n               agea + yrbrn + I(agea^2) + I(yrbrn^2) +\n               factor(reform_id_num) +           \n               yrbrn:factor(reform_id_num) + agea:factor(reform_id_num) +  \n               I(agea^2):factor(reform_id_num),\n           design = osterman_w_cl, data = osterman) \n\n# Tabulate the models\n\n# Add the latest model to the existing list using the append() function to save typing\nmodels &lt;- append(models, \n                 list(\"Weighted with cluster IDs\" = m1_w_cl)\n                 )\n\n# Tabulate the models\nmodelsummary::modelsummary(models, stars = TRUE, coef_map = coefs)\n\n\n\n\nUnweighted model\nWeighted model\nUnweighted model with cluster-robust errors\n Weighted with cluster IDs\n\n\n\nReform\n0.063*\n0.063*\n0.063*\n0.063*\n\n\n\n(0.027)\n(0.029)\n(0.029)\n(0.030)\n\n\nFemale\n0.058***\n0.061***\n0.058***\n0.061***\n\n\n\n(0.013)\n(0.014)\n(0.015)\n(0.015)\n\n\nEthnic minority\n−0.241***\n−0.261***\n−0.241***\n−0.261***\n\n\n\n(0.054)\n(0.066)\n(0.060)\n(0.067)\n\n\nForeign-born father, Europe\n−0.111**\n−0.090*\n−0.111*\n−0.090+\n\n\n\n(0.042)\n(0.046)\n(0.046)\n(0.047)\n\n\nForeign-born mother, Europe\n−0.108*\n−0.092*\n−0.108*\n−0.092+\n\n\n\n(0.044)\n(0.046)\n(0.047)\n(0.047)\n\n\nForeign-born father, outside Europe\n−0.065\n−0.053\n−0.065\n−0.053\n\n\n\n(0.073)\n(0.079)\n(0.077)\n(0.078)\n\n\nForeign-born mother, outside Europe\n−0.110\n−0.087\n−0.110\n−0.087\n\n\n\n(0.078)\n(0.082)\n(0.086)\n(0.081)\n\n\nESS Round 2\n0.059\n0.052\n0.059\n0.052\n\n\n\n(0.045)\n(0.047)\n(0.044)\n(0.045)\n\n\nESS Round 3\n0.162*\n0.148+\n0.162*\n0.148+\n\n\n\n(0.075)\n(0.080)\n(0.079)\n(0.088)\n\n\nESS Round 4\n0.243*\n0.253*\n0.243*\n0.253*\n\n\n\n(0.108)\n(0.114)\n(0.115)\n(0.125)\n\n\nESS Round 5\n0.360*\n0.364*\n0.360*\n0.364*\n\n\n\n(0.144)\n(0.153)\n(0.154)\n(0.169)\n\n\nESS Round 6\n0.397*\n0.403*\n0.397*\n0.403+\n\n\n\n(0.179)\n(0.190)\n(0.190)\n(0.209)\n\n\nESS Round 7\n0.449*\n0.458*\n0.449*\n0.458+\n\n\n\n(0.212)\n(0.224)\n(0.224)\n(0.246)\n\n\nESS Round 8\n0.655**\n0.671*\n0.655*\n0.671*\n\n\n\n(0.246)\n(0.261)\n(0.262)\n(0.288)\n\n\nESS Round 9\n0.816**\n0.835**\n0.816**\n0.835*\n\n\n\n(0.283)\n(0.299)\n(0.298)\n(0.326)\n\n\nNum.Obs.\n68796\n68796\n68796\n68796\n\n\nR2\n0.200\n0.206\n\n0.206\n\n\nR2 Adj.\n0.198\n0.204\n\n−209.204\n\n\nAIC\n268913.8\n\n406007.8\n\n\n\nBIC\n270056.1\n305027.4\n1033594.4\n7093411.5\n\n\nLog.Lik.\n−134331.877\n−151817.519\n\n−3546009.588\n\n\nRMSE\n1.71\n1.71\n\n1.71\n\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\nThis final model takes us close to the model reported in Österman (2021).",
    "crumbs": [
      "Materials",
      "Week 6",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w06.html#example-2.-osterman2021canwetrusteducationfostering-random-intercept-model",
    "href": "materials/worksheets/worksheets_w06.html#example-2.-osterman2021canwetrusteducationfostering-random-intercept-model",
    "title": "Week 6 Worksheet Exercises",
    "section": "Example 2. Österman (2021): Random intercept model",
    "text": "Example 2. Österman (2021): Random intercept model\nÖsterman (2021:222) write that “An alternative [to the model above] would be to cluster the standard errors on the country level but such an approach would risk to lead to biased standard errors because of too few clusters”. The number of clusters is an important consideration when choosing to go for a multilevel model. For our aims, we will disregard this warning and go ahead and fit a multilevel model on the osterman data regardless, and we can think about what the differences in the results mean.\nWe can fit the model in a multilevel framework using the lme4 package and the lmer() function.\nBelow we begin by looking at the distribution of the cntry variable that codes the countries where respondents are from. Since the European Social Survey is a cross-national survey, it employs a random sampling approach within each participant country and the resulting cross-national dataset is therefore clustered at the country level.\n\ndata_tabulate(osterman, cntry)\n\nCountry (cntry) &lt;character&gt;\n# total N=68796 valid N=68796\n\nValue |    N | Raw % | Valid % | Cumulative %\n------+------+-------+---------+-------------\nAT    | 2387 |  3.47 |    3.47 |         3.47\nBE    | 5220 |  7.59 |    7.59 |        11.06\nDE    | 3035 |  4.41 |    4.41 |        15.47\nDK    | 3979 |  5.78 |    5.78 |        21.25\nES    | 6062 |  8.81 |    8.81 |        30.06\nFI    | 2505 |  3.64 |    3.64 |        33.71\nFR    | 6942 | 10.09 |   10.09 |        43.80\nGB    | 5494 |  7.99 |    7.99 |        51.78\nGR    | 2065 |  3.00 |    3.00 |        54.78\nHU    | 3101 |  4.51 |    4.51 |        59.29\nIE    | 6086 |  8.85 |    8.85 |        68.14\nIT    | 1502 |  2.18 |    2.18 |        70.32\nNL    | 6063 |  8.81 |    8.81 |        79.13\nPL    | 5372 |  7.81 |    7.81 |        86.94\nPT    | 5987 |  8.70 |    8.70 |        95.65\nSE    | 2996 |  4.35 |    4.35 |       100.00\n&lt;NA&gt;  |    0 |  0.00 |    &lt;NA&gt; |         &lt;NA&gt;\n\n\nThere are 16 countries in the data.\nInitially, it is advisable to first fit some simple, preliminary models, in part to establish a baseline for evaluating larger models. Since in the multilevel framework we are interested in understanding the effect that the clusters have in the data, the simplest model we can fit is a so-called random intercepts model or null model, which models the outcome without any predictors. In the single-level framework, this is equivalent to estimating the overall mean of the outcome variable; in the hierarchical framework, we are modelling the mean of the outcome within each category/cluster of the grouping variable. With lmer() this means a simple addition of a specification of the form (1 | cluster) to the model code we are already familiar with, where cluster is the name of the clustering variable, in our case cntry:\n\nmod_null &lt;- lmer(trustindex3 ~ 1 + (1 | cntry), data = osterman)\n\nThe result is the following:\n\nmodel_parameters(mod_null)\n\n# Fixed Effects\n\nParameter   | Coefficient |   SE |       95% CI | t(68793) |      p\n-------------------------------------------------------------------\n(Intercept) |        5.23 | 0.23 | [4.78, 5.69] |    22.47 | &lt; .001\n\n# Random Effects\n\nParameter             | Coefficient\n-----------------------------------\nSD (Intercept: cntry) |        0.93\nSD (Residual)         |        1.71\n\nrandom_parameters(mod_null)\n\n# Random Effects\n\nWithin-Group Variance        2.94 (1.71)\nBetween-Group Variance\n  Random Intercept (cntry)   0.87 (0.93)\nN (groups per factor)\n  cntry                        16\nObservations                68796\n\n\nBelow we fit a random intercept model with cntry_cohort as the single grouping variable and disregarding survey weights:\n\n# Fit a random intercept model with `cntry_cohort` as the grouping variable\nm2 &lt;- lmer(trustindex3 ~ reform1_7 + female + blgetmg_d + \n               fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) + \n               agea + yrbrn + I(agea^2) + I(yrbrn^2) +\n               factor(reform_id_num) +           \n               yrbrn:factor(reform_id_num) + agea:factor(reform_id_num) +  \n               I(agea^2):factor(reform_id_num) +\n               (1|cntry_cohort),\n           data = osterman)\n\n\n# Fit a random intercept model with only `cntry` as the grouping variable\nm2_cntry &lt;- lmer(trustindex3 ~ reform1_7 + female + blgetmg_d + \n               fbrneur + mbrneur + fnotbrneur + mnotbrneur + factor(essround) + \n               agea + yrbrn + I(agea^2) + I(yrbrn^2) +\n               factor(reform_id_num) +           \n               yrbrn:factor(reform_id_num) + agea:factor(reform_id_num) +  \n               I(agea^2):factor(reform_id_num) +\n               (1|cntry),\n           data = osterman)\n\n\n# Add the latest models to the existing list using the append() function\nmodels &lt;- append(models, \n                 list(\"Random intercepts (cntry_cohort)\" = m2,\n                      \"Random intercepts (cntry)\" = m2_cntry)\n                 )\n\n# Tabulate and compare the models\nmodelsummary::modelsummary(models, stars = TRUE, coef_map = coefs)\n\n\n\n\nUnweighted model\nWeighted model\nUnweighted model with cluster-robust errors\n Weighted with cluster IDs\nRandom intercepts (cntry_cohort)\nRandom intercepts (cntry)\n\n\n\nReform\n0.063*\n0.063*\n0.063*\n0.063*\n0.064*\n0.063*\n\n\n\n(0.027)\n(0.029)\n(0.029)\n(0.030)\n(0.028)\n(0.027)\n\n\nFemale\n0.058***\n0.061***\n0.058***\n0.061***\n0.058***\n0.058***\n\n\n\n(0.013)\n(0.014)\n(0.015)\n(0.015)\n(0.013)\n(0.013)\n\n\nEthnic minority\n−0.241***\n−0.261***\n−0.241***\n−0.261***\n−0.241***\n−0.241***\n\n\n\n(0.054)\n(0.066)\n(0.060)\n(0.067)\n(0.054)\n(0.054)\n\n\nForeign-born father, Europe\n−0.111**\n−0.090*\n−0.111*\n−0.090+\n−0.111**\n−0.111**\n\n\n\n(0.042)\n(0.046)\n(0.046)\n(0.047)\n(0.042)\n(0.042)\n\n\nForeign-born mother, Europe\n−0.108*\n−0.092*\n−0.108*\n−0.092+\n−0.108*\n−0.108*\n\n\n\n(0.044)\n(0.046)\n(0.047)\n(0.047)\n(0.044)\n(0.044)\n\n\nForeign-born father, outside Europe\n−0.065\n−0.053\n−0.065\n−0.053\n−0.064\n−0.065\n\n\n\n(0.073)\n(0.079)\n(0.077)\n(0.078)\n(0.073)\n(0.073)\n\n\nForeign-born mother, outside Europe\n−0.110\n−0.087\n−0.110\n−0.087\n−0.110\n−0.110\n\n\n\n(0.078)\n(0.082)\n(0.086)\n(0.081)\n(0.078)\n(0.078)\n\n\nESS Round 2\n0.059\n0.052\n0.059\n0.052\n0.059\n0.059\n\n\n\n(0.045)\n(0.047)\n(0.044)\n(0.045)\n(0.045)\n(0.045)\n\n\nESS Round 3\n0.162*\n0.148+\n0.162*\n0.148+\n0.162*\n0.162*\n\n\n\n(0.075)\n(0.080)\n(0.079)\n(0.088)\n(0.075)\n(0.075)\n\n\nESS Round 4\n0.243*\n0.253*\n0.243*\n0.253*\n0.243*\n0.243*\n\n\n\n(0.108)\n(0.114)\n(0.115)\n(0.125)\n(0.108)\n(0.108)\n\n\nESS Round 5\n0.360*\n0.364*\n0.360*\n0.364*\n0.360*\n0.360*\n\n\n\n(0.144)\n(0.153)\n(0.154)\n(0.169)\n(0.144)\n(0.144)\n\n\nESS Round 6\n0.397*\n0.403*\n0.397*\n0.403+\n0.396*\n0.397*\n\n\n\n(0.179)\n(0.190)\n(0.190)\n(0.209)\n(0.179)\n(0.179)\n\n\nESS Round 7\n0.449*\n0.458*\n0.449*\n0.458+\n0.448*\n0.449*\n\n\n\n(0.212)\n(0.224)\n(0.224)\n(0.246)\n(0.212)\n(0.212)\n\n\nESS Round 8\n0.655**\n0.671*\n0.655*\n0.671*\n0.654**\n0.655**\n\n\n\n(0.246)\n(0.261)\n(0.262)\n(0.288)\n(0.246)\n(0.246)\n\n\nESS Round 9\n0.816**\n0.835**\n0.816**\n0.835*\n0.815**\n0.816**\n\n\n\n(0.283)\n(0.299)\n(0.298)\n(0.326)\n(0.283)\n(0.283)\n\n\nNum.Obs.\n68796\n68796\n68796\n68796\n68796\n68796\n\n\nR2\n0.200\n0.206\n\n0.206\n\n\n\n\nR2 Adj.\n0.198\n0.204\n\n−209.204\n\n\n\n\nR2 Marg.\n\n\n\n\n0.199\n0.126\n\n\nR2 Cond.\n\n\n\n\n0.200\n0.494\n\n\nAIC\n268913.8\n\n406007.8\n\n269877.8\n269878.2\n\n\nBIC\n270056.1\n305027.4\n1033594.4\n7093411.5\n271029.3\n271029.7\n\n\nICC\n\n\n\n\n0.0\n0.4\n\n\nLog.Lik.\n−134331.877\n−151817.519\n\n−3546009.588\n\n\n\n\nRMSE\n1.71\n1.71\n\n1.71\n1.70\n1.71\n\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001",
    "crumbs": [
      "Materials",
      "Week 6",
      "Exercises"
    ]
  },
  {
    "objectID": "misc/dice-calculations.html",
    "href": "misc/dice-calculations.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "The number of possible outcomes when throwing three six-sided dice, without considering the order of the numbers, is nCr(6+3-1, 3), where nCr represents the number of combinations.\nIn this case, nCr(6+3-1, 3) = nCr(8, 3) = 56. So there are 56 possible outcomes.\nThe formula nCr(n, r) represents the number of combinations of r elements from a set of n elements.\nIn the formula nCr(6+3-1, 3), n is 6+3-1 = 8, which represents the total number of elements in the set when considering all the possible outcomes from rolling three six-sided dice. The -1 in the formula accounts for the fact that we’re considering repeating dice rolls.\nr is 3, which represents the number of elements we want to choose (in this case, the number of dice rolls we want to consider in a combination).\nSo, nCr(6+3-1, 3) gives us the number of possible combinations of 3 dice rolls from a set of 8 possible outcomes (the 6 possible outcomes from each dice roll plus 2 duplicates). This is also known as the number of ways to choose 3 dice rolls out of 8 possible outcomes.\nThe result nCr(8, 3) = 56 means there are 56 possible combinations of 3 dice rolls from 8 possible outcomes.\n\n\nThe n in nCr(n, r) represents the total number of elements in the set from which we want to choose r elements.\nIn the case of three six-sided dice, each dice has 6 possible outcomes. If we roll three dice, the total number of possible outcomes is 6 * 6 * 6 = 216. However, because we don’t care about the order in which the dice land, we need to remove the duplicate combinations that would result from simply rearranging the order of the same three outcomes.\nTo account for duplicates, we consider the problem as choosing r elements from a set of n elements, where n is the total number of unique combinations that can be made from rolling three dice.\nTo calculate n, we can use the formula n = n + r - 1, where n is the total number of outcomes from rolling the dice (in this case, 6), and r is the number of dice we’re rolling (in this case, 3).\nSo in this case, n = 6 + 3 - 1 = 8. This means that we have 8 unique combinations of dice rolls, and we can choose 3 dice rolls from this set to form a combination. And the number of combinations of 3 dice rolls from this set of 8 unique combinations is nCr(8, 3) = 56.\n\n\n\nThe formula n = n + r - 1 is used to find the number of unique combinations of r elements from a set of n elements, when the elements can be repeated.\nThe reasoning behind this formula is as follows:\nImagine you have n distinct elements, and you want to form combinations of r elements. In this case, the number of unique combinations is simply nCr(n, r).\nHowever, when elements can be repeated, the number of unique combinations is not simply nCr(n, r), because the same combination of elements can be formed by rearranging the same r elements in different orders. To account for this, we need to consider the problem as choosing r elements from a set of n + r - 1 elements, where n + r - 1 is the total number of unique combinations that can be made from the n elements.\nThe -1 in the formula accounts for the fact that we’re considering repeating elements, so we need to remove one duplicate combination that would result from simply rearranging the same r elements.\nSo in the case of three six-sided dice, each dice has 6 possible outcomes, giving us n = 6 unique elements. If we roll three dice, we have r = 3 elements. And to find the number of unique combinations of r elements from a set of n elements, where elements can be repeated, we use the formula n = n + r - 1, giving us n = 6 + 3 - 1 = 8.\nThis means that there are 8 unique combinations of dice rolls that can be formed from rolling three six-sided dice, and we can choose 3 dice rolls from this set to form a combination. The number of combinations of 3 dice rolls from this set of 8 unique combinations is nCr(8, 3) = 56.\n\n\n\n\n# Define the number of unique elements and the number of elements to choose\nn &lt;- 6\nr &lt;- 3\n\n# Calculate the number of unique combinations using the formula n = n + r - 1\nm &lt;- n + r - 1\n\n# Calculate the number of combinations using the combination formula nCr(m, r)\ncombinations &lt;- choose(m, r)\ncombinations\n\n[1] 56\n\n\nThis code returns the value 56, which is the number of unique combinations of r elements from a set of m elements, where m = n + r - 1 and n is the number of unique elements and r is the number of elements to choose. This is the same result as we found earlier using nCr(8, 3).\n\n\n\n\n# Define the number of unique elements and the number of elements to choose\nn &lt;- 6\nr &lt;- 3\n\n# Calculate the number of unique combinations using the formula n = n + r - 1\nm &lt;- n + r - 1\n\n# Generate all possible combinations of length r from 1 to m\nall_combinations &lt;- combn(1:m, r)\n\n# Convert the combinations to a matrix for easier manipulation\ncombination_matrix &lt;- as.matrix(all_combinations)\n\n# Find the unique rows in the combination matrix\nunique_combinations &lt;- unique(combination_matrix)\n\n# Count the number of unique combinations\nnum_unique_combinations &lt;- nrow(unique_combinations)\nnum_unique_combinations\n\n[1] 3\n\n\n\n\n\n\n# Define the number of unique elements and the number of elements to choose\nn &lt;- 6\nr &lt;- 3\n\n# Generate all possible combinations of length r from 1 to n\nall_combinations &lt;- combn(1:n, r)\n\n# Convert the combinations to a matrix for easier manipulation\ncombination_matrix &lt;- as.matrix(all_combinations)\n\n# Find the unique rows in the combination matrix\nunique_combinations &lt;- unique(combination_matrix)\n\n# Count the number of unique combinations\nnum_unique_combinations &lt;- nrow(unique_combinations)\nnum_unique_combinations\n\n[1] 3"
  },
  {
    "objectID": "misc/dice-calculations.html#the-number-of-possible-outcomes-from-throwing-three-dice-without-counting-the-order",
    "href": "misc/dice-calculations.html#the-number-of-possible-outcomes-from-throwing-three-dice-without-counting-the-order",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "The number of possible outcomes when throwing three six-sided dice, without considering the order of the numbers, is nCr(6+3-1, 3), where nCr represents the number of combinations.\nIn this case, nCr(6+3-1, 3) = nCr(8, 3) = 56. So there are 56 possible outcomes.\nThe formula nCr(n, r) represents the number of combinations of r elements from a set of n elements.\nIn the formula nCr(6+3-1, 3), n is 6+3-1 = 8, which represents the total number of elements in the set when considering all the possible outcomes from rolling three six-sided dice. The -1 in the formula accounts for the fact that we’re considering repeating dice rolls.\nr is 3, which represents the number of elements we want to choose (in this case, the number of dice rolls we want to consider in a combination).\nSo, nCr(6+3-1, 3) gives us the number of possible combinations of 3 dice rolls from a set of 8 possible outcomes (the 6 possible outcomes from each dice roll plus 2 duplicates). This is also known as the number of ways to choose 3 dice rolls out of 8 possible outcomes.\nThe result nCr(8, 3) = 56 means there are 56 possible combinations of 3 dice rolls from 8 possible outcomes.\n\n\nThe n in nCr(n, r) represents the total number of elements in the set from which we want to choose r elements.\nIn the case of three six-sided dice, each dice has 6 possible outcomes. If we roll three dice, the total number of possible outcomes is 6 * 6 * 6 = 216. However, because we don’t care about the order in which the dice land, we need to remove the duplicate combinations that would result from simply rearranging the order of the same three outcomes.\nTo account for duplicates, we consider the problem as choosing r elements from a set of n elements, where n is the total number of unique combinations that can be made from rolling three dice.\nTo calculate n, we can use the formula n = n + r - 1, where n is the total number of outcomes from rolling the dice (in this case, 6), and r is the number of dice we’re rolling (in this case, 3).\nSo in this case, n = 6 + 3 - 1 = 8. This means that we have 8 unique combinations of dice rolls, and we can choose 3 dice rolls from this set to form a combination. And the number of combinations of 3 dice rolls from this set of 8 unique combinations is nCr(8, 3) = 56.\n\n\n\nThe formula n = n + r - 1 is used to find the number of unique combinations of r elements from a set of n elements, when the elements can be repeated.\nThe reasoning behind this formula is as follows:\nImagine you have n distinct elements, and you want to form combinations of r elements. In this case, the number of unique combinations is simply nCr(n, r).\nHowever, when elements can be repeated, the number of unique combinations is not simply nCr(n, r), because the same combination of elements can be formed by rearranging the same r elements in different orders. To account for this, we need to consider the problem as choosing r elements from a set of n + r - 1 elements, where n + r - 1 is the total number of unique combinations that can be made from the n elements.\nThe -1 in the formula accounts for the fact that we’re considering repeating elements, so we need to remove one duplicate combination that would result from simply rearranging the same r elements.\nSo in the case of three six-sided dice, each dice has 6 possible outcomes, giving us n = 6 unique elements. If we roll three dice, we have r = 3 elements. And to find the number of unique combinations of r elements from a set of n elements, where elements can be repeated, we use the formula n = n + r - 1, giving us n = 6 + 3 - 1 = 8.\nThis means that there are 8 unique combinations of dice rolls that can be formed from rolling three six-sided dice, and we can choose 3 dice rolls from this set to form a combination. The number of combinations of 3 dice rolls from this set of 8 unique combinations is nCr(8, 3) = 56.\n\n\n\n\n# Define the number of unique elements and the number of elements to choose\nn &lt;- 6\nr &lt;- 3\n\n# Calculate the number of unique combinations using the formula n = n + r - 1\nm &lt;- n + r - 1\n\n# Calculate the number of combinations using the combination formula nCr(m, r)\ncombinations &lt;- choose(m, r)\ncombinations\n\n[1] 56\n\n\nThis code returns the value 56, which is the number of unique combinations of r elements from a set of m elements, where m = n + r - 1 and n is the number of unique elements and r is the number of elements to choose. This is the same result as we found earlier using nCr(8, 3).\n\n\n\n\n# Define the number of unique elements and the number of elements to choose\nn &lt;- 6\nr &lt;- 3\n\n# Calculate the number of unique combinations using the formula n = n + r - 1\nm &lt;- n + r - 1\n\n# Generate all possible combinations of length r from 1 to m\nall_combinations &lt;- combn(1:m, r)\n\n# Convert the combinations to a matrix for easier manipulation\ncombination_matrix &lt;- as.matrix(all_combinations)\n\n# Find the unique rows in the combination matrix\nunique_combinations &lt;- unique(combination_matrix)\n\n# Count the number of unique combinations\nnum_unique_combinations &lt;- nrow(unique_combinations)\nnum_unique_combinations\n\n[1] 3\n\n\n\n\n\n\n# Define the number of unique elements and the number of elements to choose\nn &lt;- 6\nr &lt;- 3\n\n# Generate all possible combinations of length r from 1 to n\nall_combinations &lt;- combn(1:n, r)\n\n# Convert the combinations to a matrix for easier manipulation\ncombination_matrix &lt;- as.matrix(all_combinations)\n\n# Find the unique rows in the combination matrix\nunique_combinations &lt;- unique(combination_matrix)\n\n# Count the number of unique combinations\nnum_unique_combinations &lt;- nrow(unique_combinations)\nnum_unique_combinations\n\n[1] 3"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "References"
  },
  {
    "objectID": "materials/notes/notes_w08.html",
    "href": "materials/notes/notes_w08.html",
    "title": "Week 8 Worksheet Notes",
    "section": "",
    "text": "By the end of the session you will learn how to perform:\n\nSimulation of random variables\nPower analysis via simulation",
    "crumbs": [
      "Materials",
      "Week 8",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w08.html#aims",
    "href": "materials/notes/notes_w08.html#aims",
    "title": "Week 8 Worksheet Notes",
    "section": "",
    "text": "By the end of the session you will learn how to perform:\n\nSimulation of random variables\nPower analysis via simulation",
    "crumbs": [
      "Materials",
      "Week 8",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w08.html#r-packages",
    "href": "materials/notes/notes_w08.html#r-packages",
    "title": "Week 8 Worksheet Notes",
    "section": "R packages",
    "text": "R packages\n\n# Just in case we get errors asking that the package repositories be explicitly set when installing new packages:\n\noptions(repos = list(CRAN = \"http://cran.rstudio.com/\"))\n\n# Install and load required packages\n\n# We can use the {pacman} package to easily install and load several packages:\n# ({pacman} itself may need installing if not yet installed)\n\npacman::p_load(\n  tidyverse, sjlabelled, easystats,\n  ggformula, ggeffects, marginaleffects, \n  modelsummary, gtsummary,\n  modelr,                        # for some further model dataframe/tibble management functions\n  MASS                           # for the function `mvrnorm` to generate variables with pre-specified covariance structure\n  )",
    "crumbs": [
      "Materials",
      "Week 8",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w08.html#the-uses-of-simulation-methods",
    "href": "materials/notes/notes_w08.html#the-uses-of-simulation-methods",
    "title": "Week 8 Worksheet Notes",
    "section": "The uses of simulation methods",
    "text": "The uses of simulation methods\nSimulating data uses generating random data sets with known properties using code (or some other method). This can be useful in various contexts.\n\nTo better understand our models. Probability models mimic variation in the world, and the tools of simulation can help us better understand this variation. Patterns of randomness are contrary to normal human thinking and simulation helps in training our intuitions about averages and variation\nTo run statistical analyses (e.g., simulating a null distribution against which to compare a sample)\nTo approximate the sampling distribution of data and propagate this to the sampling distribution of statistical estimates and procedures",
    "crumbs": [
      "Materials",
      "Week 8",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w08.html#distribution-functions",
    "href": "materials/notes/notes_w08.html#distribution-functions",
    "title": "Week 8 Worksheet Notes",
    "section": "Distribution functions",
    "text": "Distribution functions\nBase R functions:\n\nrnorm(): sampling from a normal distribution\nrunif(): sampling from a uniform distribution\nrbinom(): sampling from a binomial distribution\nrpois(): sampling from a Poisson distribution\n\n(Other distributions are also available)\n\nsample(): sampling elements from an R object with or without replacement\nreplicate(): often plays a role in conjunction with sampling functions; it is used to evaluate an expression N number of times repeatedly\n\nNot base-R packages:\n\nMASS::mvtnorm(): multivariate normal; sampling multiple variables with a known correlation structure (i.e., we can tell R how variables should be correlated with one another) and normally distributed errors\n\n\nSampling from a uniform distribution\nThe runif function returns some number (n) of random numbers from a uniform distribution with a range from \\(a\\) (min) to \\(b\\) (max) such that \\(X\\sim\\mathcal U(a,b)\\) (verbally, \\(X\\) is sampled from a uniform distribution with the parameters \\(a\\) and \\(b\\)), where \\(-\\infty &lt; a &lt; b &lt; \\infty\\) (verbally, \\(a\\) is greater than negative infinity but less than \\(b\\), and \\(b\\) is finite). The default is to draw from a standard uniform distribution (i.e., \\(a = 0\\) and \\(b = 1\\)):\n\n# Sample a vector of ten numbers and store the results in the object `rand_unifs`\n# Note that the numbers will be different each time we re-run the `runif` function above.\n# If we want to recreate the same sample, we should set a `seed` number first\n\nrand_unifs &lt;- runif(n = 10000, min = 0, max = 1);\n\nThe first 40 numbers from the sample are:\n\n\n [1] 0.37502992 0.68982595 0.98590044 0.71059641 0.06132830 0.17670731\n [7] 0.79833820 0.34533205 0.85024223 0.63665065 0.63472925 0.81505794\n[13] 0.88980845 0.09416752 0.55637083 0.99175606 0.21588906 0.71801451\n[19] 0.41727368 0.63044807 0.55003150 0.44468624 0.77229814 0.84770886\n[25] 0.23830448 0.89719279 0.91995817 0.97298726 0.16592863 0.50980450\n[31] 0.60880849 0.17703089 0.30092050 0.65307591 0.96833831 0.47484581\n[37] 0.06716160 0.23575399 0.96125830 0.54294399 0.14238520 0.69111469\n[43] 0.51297232 0.06054244 0.58162491 0.23383184 0.70888075 0.10920273\n[49] 0.47519353 0.83015849\n\n\nTo visualise the entire sample, we can plot it on a histogram:\n\n\n\n\n\n\n\n\n\n\n\nSampling from a normal distribution\nThe rnorm function returns some number (n) of randomly generated values given a set mean (\\(\\mu\\); mean) and standard deviation (\\(\\sigma\\); sd), such that \\(X\\sim\\mathcal N(\\mu,\\sigma^2)\\). The default is to draw from a standard normal (a.k.a., “Gaussian”) distribution (i.e., \\(\\mu = 0\\) and \\(\\sigma = 1\\)):\n\nrand_norms_10000 &lt;- rnorm(n = 10000, mean = 0, sd = 1)\n\nprint(rand_norms_10000[1:20])\n\n [1]  0.04627100  1.03334482 -1.84240888  1.62460072  1.60980100  1.65705963\n [7]  2.15433314  0.09817849 -0.41576874 -2.78007368  0.31180445 -0.40322909\n[13]  1.58767242  0.52701584 -0.28336089 -1.14416504  0.15796135  0.13720856\n[19]  0.22746198 -0.88482968\n\n\n\n\n\n\n\n\n\n\n\n\nHistograms allow us to check how samples from the same distribution might vary.\n\n\n\nSampling from a Poisson distribution\nA Poisson process describes events happening with some given probability over an area of time or space such that \\(X\\sim Poisson(\\lambda)\\), where the rate parameter \\(\\lambda\\) is both the mean and variance of the Poisson distribution (note that by definition, \\(\\lambda &gt; 0\\), and although \\(\\lambda\\) can be any positive real number, data are always integers, as with count data).\nSampling from a Poisson distribution can be done in R with rpois, which takes only two arguments specifying the number of values to be returned (n) and the rate parameter (lambda). There are no default values for rpois.\n\nrand_poissons &lt;- rpois(n = 10, lambda = 1.5)\n\nprint(rand_poissons)\n\n [1] 0 7 1 3 1 2 1 0 3 4\n\n\nA histogram of a large number of values to see the distribution when \\(\\lambda = 4.5\\):\n\nrand_poissons_10000 &lt;- rpois(n = 10000, lambda = 4.5)\n\n\n\n\n\n\n\n\n\n\n\n\nSampling from a binomial distribution\n\nA binomial distribution describes the number of ‘successes’ for some number of independent trials (\\(\\Pr(success) = p\\)).\nThe rbinom function returns the number of successes after size trials, in which the probability of success in each trial is prob.\nSampling from a binomial distribution in R with rbinom is a bit more complex than using runif, rnorm, or rpois.\nLike those previous functions, the rbinom function returns some number (n) of random numbers, but the arguments and output can be slightly confusing at first.\nFor example, suppose we want to simulate the flipping of a fair coin 1000 times, and we want to know how many times that coin comes up heads (‘success’). We can do this with the following code:\n\n\ncoin_flips &lt;- rbinom(n = 1, size = 1000, prob = 0.5)\n\ncoin_flips\n\n[1] 515\n\n\n\nThe above result shows that the coin came up heads 515 times. But note the (required) argument n. This allows us to set the number of sequences to run.\nIf we instead set n = 2, then this could simulate the flipping of a fair coin 1000 times once to see how many times heads comes up, then repeating the whole process a second time to see how many times heads comes up again (or, if it is more intuitive, the flipping of two separate fair coins 1000 times at the same time).\n\n\ncoin_flips_2 &lt;- rbinom(n = 2, size = 1000, prob = 0.5)\n\ncoin_flips_2\n\n[1] 483 504\n\n\n\nA coin was flipped 1000 times and returned 483 heads, and then another fair coin was flipped 1000 times and returned 504 heads.\nAs with the rnorm and runif functions, we can check to see what the distribution of the binomial function looks like if we repeat this process.\nSuppose that we want to see the distribution of the number of times heads comes up after 1000 flips. We can simulate the process of flipping 1000 times in a row with 10000 different coins:\n\n\ncoin_flips_10000 &lt;- rbinom(n = 10000, size = 1000, prob = 0.5)",
    "crumbs": [
      "Materials",
      "Week 8",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w08.html#random-sampling-using-sample",
    "href": "materials/notes/notes_w08.html#random-sampling-using-sample",
    "title": "Week 8 Worksheet Notes",
    "section": "Random sampling using sample",
    "text": "Random sampling using sample\n\nSometimes it is useful to sample a set of values from a vector or list. The R function sample is very flexible for sampling a subset of numbers or elements from some structure (x) in R according to some set probabilities (prob).\nElements can be sampled from x some number of times (size) with or without replacement (replace), though an error will be returned if the size of the sample is larger than x but replace = FALSE (default).\nSuppose we want to ask R to pick a random number from one to ten with equal probability:\n\n\nrand_number_1 &lt;- sample(x = 1:10, size = 1)\n\nprint(rand_number_1)\n\n[1] 5\n\n\n\nWe can increase the size of the sample to 10:\n\n\nrand_number_10 &lt;- sample(x = 1:10, size = 10)\nprint(rand_number_10)\n\n [1]  8  6  9  7  2  5  1  3  4 10\n\n\n\nNote that all numbers from 1 to 10 have been sampled, but in a random order. This is because the default is to sample without replacement, meaning that once a number has been sampled for the first element in rand_number_10, it is no longer available to be sampled again.\nWe can change this and allow for sampling with replacement:\n\n\nrand_number_10_r &lt;- sample(x = 1:10, size = 10, replace = TRUE)\n\nprint(rand_number_10_r)\n\n [1]  4  9  3  8  5  3 10  2  5  9\n\n\n\nNote that the numbers {3, 5, 9} are now repeated in the set of randomly sampled values above.\nSo far, because we have not specified a probability vector prob, the function assumes that every element in 1:10 is sampled with equal probability\nHere’s an example in which the numbers 1-5 are sampled with a probability of 0.05, while the numbers 6-10 are sampled with a probability of 0.15, thereby biasing sampling toward larger numbers; we always need to ensure that these probabilities need to sum to 1.\n\n\nprob_vec      &lt;- c( rep(x = 0.05, times = 5), rep(x = 0.15, times = 5))\n\nrand_num_bias &lt;- sample(x = 1:10, size = 10, replace = TRUE, prob = prob_vec)\n\nprint(rand_num_bias)\n\n [1]  6 10  9  8  8  9  7  6  6  9",
    "crumbs": [
      "Materials",
      "Week 8",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w08.html#sampling-random-characters-from-a-list",
    "href": "materials/notes/notes_w08.html#sampling-random-characters-from-a-list",
    "title": "Week 8 Worksheet Notes",
    "section": "Sampling random characters from a list",
    "text": "Sampling random characters from a list\n\nWe can also sample characters from a list of elements; it is no different than sampling numbers\nFor example, if we want to create a simulated data set that includes three different species of some plant or animal, we could create a vector of species identities from which to sample:\n\n\nspecies &lt;- c(\"species_A\", \"species_B\", \"species_C\");\n\n\nWe can then sample from these three possible categories. For example:\n\n\nsp_sample &lt;- sample(x = species, size = 24, replace = TRUE, \n                    prob = c(0.5, 0.25, 0.25))\n\n\nWhat did the code above do?\n\n\n\n [1] \"species_B\" \"species_C\" \"species_C\" \"species_B\" \"species_B\" \"species_C\"\n [7] \"species_B\" \"species_C\" \"species_C\" \"species_C\" \"species_C\" \"species_A\"\n[13] \"species_A\" \"species_B\" \"species_A\" \"species_C\" \"species_C\" \"species_C\"\n[19] \"species_B\" \"species_A\" \"species_A\" \"species_B\" \"species_C\" \"species_A\"",
    "crumbs": [
      "Materials",
      "Week 8",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w08.html#simulating-data-with-known-correlations",
    "href": "materials/notes/notes_w08.html#simulating-data-with-known-correlations",
    "title": "Week 8 Worksheet Notes",
    "section": "Simulating data with known correlations",
    "text": "Simulating data with known correlations\n\nWe can generate variables \\(X_{1}\\) and \\(X_{2}\\) that have known correlations \\(\\rho\\) with with one another.\nFor example: two standard normal random variables with a sample size of 10000, and with correlation between them of 0.3:\n\n\nN   &lt;- 10000\nrho &lt;- 0.3\nx1  &lt;- rnorm(n = N, mean = 0, sd = 1)\nx2  &lt;- (rho * x1) + sqrt(1 - rho*rho) * rnorm(n = N, mean = 0, sd = 1)\n\n\nThese variables are generated by first simulating the sample \\(x_{1}\\) (x1 above) from a standard normal distribution. Then, \\(x_{2}\\) (x2 above) is calculated as\n\n\\(x_{2} = \\rho x_{1} + \\sqrt{1 - \\rho^{2}}x_{rand}\\),\nwhere \\(x_{rand}\\) is a sample from a normal distribution with the same variance as \\(x_{1}\\).\n\nWe can generate variables \\(X_{1}\\) and \\(X_{2}\\) that have known correlations \\(\\rho\\) with with one another.\nFor example: two standard normal random variables with a sample size of 10000, and with correlation between them of 0.3:\n\n\nN   &lt;- 10000\nrho &lt;- 0.3\nx1  &lt;- rnorm(n = N, mean = 0, sd = 1)\nx2  &lt;- (rho * x1) + sqrt(1 - rho*rho) * rnorm(n = N, mean = 0, sd = 1)\n\n\nDoes the correlation equal rho (with some sampling error)?\n\n\ncor(x1, x2)\n\n[1] 0.2968118\n\n\n\nThere is a more efficient way to generate any number of variables with different variances and correlations to one another.\nWe need to use the MASS library, which can be installed and loaded as below:\nIn the MASS library, the function mvrnorm can be used to generate any number of variables for a pre-specified covariance structure.",
    "crumbs": [
      "Materials",
      "Week 8",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w08.html#statistical-power",
    "href": "materials/notes/notes_w08.html#statistical-power",
    "title": "Week 8 Worksheet Notes",
    "section": "Statistical power",
    "text": "Statistical power\n\nStatistical power is defined as the probability, before a study is performed, that a particular comparison will achieve “statistical significance” at some predetermined level (typically a p-value below 0.05), given some assumed true effect size\nIf a certain effect of interest exists (e.g. a difference between two groups) power is the chance that we actually find the effect in a given study\nA power analysis is performed by first hypothesizing an effect size, then making some assumptions about the variation in the data and the sample size of the study to be conducted, and finally using probability calculations to determine the chance of the p-value being below the threshold\nThe conventional view is that you should avoid low-power studies because they are unlikely to succeed\nThere are several problems with this view, but it’s often required by research funding bodies",
    "crumbs": [
      "Materials",
      "Week 8",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w08.html#example-1-simulating-a-simple-randomized-experiment",
    "href": "materials/notes/notes_w08.html#example-1-simulating-a-simple-randomized-experiment",
    "title": "Week 8 Worksheet Notes",
    "section": "Example 1: Simulating a simple randomized experiment",
    "text": "Example 1: Simulating a simple randomized experiment\nThis example comes from Gelman, Hill, and Vehtari (2020)[Ch. 16]. They demonstrate data simulation for power analysis with an artificial example of a randomized experiment on 100 students designed to test an intervention for improving final exam scores.\n\nData\n\nset.seed(862)\n\nsim_1 &lt;- function(n = 100) {\n  y_if_control &lt;- rnorm(n, mean = 60, sd = 20)\n  y_if_treated &lt;- y_if_control + 5\n  tibble(\n    z = rep(0:1, n / 2) |&gt; sample(),\n    y = if_else(z == 1, y_if_treated, y_if_control)\n  )\n}\n\ndata_1a1 &lt;- sim_1()\n\nHaving simulated the data, we can now compare treated to control outcomes and compute the standard error for the difference.\n\ndata_1a1 |&gt; \n  summarize(\n    diff = mean(y[z == 1]) - mean(y[z == 0]),\n    diff_se = \n      sqrt(sd(y[z == 0])^2 / sum(z == 0) + sd(y[z == 1])^2 / sum(z == 1))\n  )\n\n# A tibble: 1 × 2\n   diff diff_se\n  &lt;dbl&gt;   &lt;dbl&gt;\n1  4.66    3.80\n\n\nEquivalently, we can run the regression:\n\nset.seed(619)\n\nfit_1a1 &lt;- lm(y ~ z, data = data_1a1, refresh = 0)\n\nWarning: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :\n extra argument 'refresh' will be disregarded\n\nfit_1a1\n\n\nCall:\nlm(formula = y ~ z, data = data_1a1, refresh = 0)\n\nCoefficients:\n(Intercept)            z  \n     59.008        4.656  \n\n\nTo give a sense of why it would be a mistake to focus on the point estimate, we repeat the above steps for a new batch of 100 students simulated from the model. Here is the result:\n\nset.seed(827)\n\ndata_1a2 &lt;- sim_1()\n\n\nset.seed(619)\n\nfit_1a2 &lt;- lm(y ~ z, data = data_1a2, refresh = 0)\n\nWarning: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :\n extra argument 'refresh' will be disregarded\n\nfit_1a2\n\n\nCall:\nlm(formula = y ~ z, data = data_1a2, refresh = 0)\n\nCoefficients:\n(Intercept)            z  \n      56.19        12.19  \n\n\nA naive read of this table would be that the design with 100 students is just fine, as the estimate is well over two standard errors away from zero. But that conclusion would be a mistake, as the coefficient estimate here is too noisy to be useful.\n\n\nIncluding a pre-treatment predictor\nAdd a pre-test variable simulated independently of the potential outcomes for the final test score.\n\nset.seed(134)\n\ndata_1b &lt;- \n  data_1a1 |&gt; \n  mutate(x = rnorm(n(), mean = 50, sd = 20))\n\nWe can then adjust for pre-test in our regression:\n\nset.seed(619)\n\nfit_1b &lt;- lm(y ~ z + x, data = data_1b, refresh = 0)\n\nWarning: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :\n extra argument 'refresh' will be disregarded\n\nfit_1b\n\n\nCall:\nlm(formula = y ~ z + x, data = data_1b, refresh = 0)\n\nCoefficients:\n(Intercept)            z            x  \n   62.18784      4.44862     -0.06444  \n\n\nBecause the pre-test variable was simulated independently of the potential outcomes for the final test score, the standard error for the coefficient of z wasn’t reduced.\nTo perform a realistic simulation, we will now simulate both test scores in a correlated way.\n\nset.seed(822)\n\nn &lt;- 100\n\ntrue_ability &lt;- rnorm(n, mean = 50, sd = 16)\ny_if_control &lt;- true_ability + rnorm(n, mean = 0, sd = 12) + 10\ny_if_treated &lt;- y_if_control + 5\n\ndata_2 &lt;- \n  tibble(\n    x = true_ability + rnorm(n, mean = 0, sd = 12),\n    z = rep(0:1, n / 2) |&gt; sample(),\n    y = if_else(z == 1, y_if_treated, y_if_control)\n  ) \n\nThe simple comparison is equivalent to a regression on the treatment indicator:\n\nset.seed(619)\n\nfit_2a &lt;- lm(y ~ z, data = data_2, refresh = 0)\n\nWarning: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :\n extra argument 'refresh' will be disregarded\n\nfit_2a\n\n\nCall:\nlm(formula = y ~ z, data = data_2, refresh = 0)\n\nCoefficients:\n(Intercept)            z  \n     59.671        6.363  \n\n\nAnd the estimate adjusting for pre-test:\n\nset.seed(619)\n\nfit_2b &lt;- lm(y ~ z + x, data = data_2, refresh = 0)\n\nWarning: In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :\n extra argument 'refresh' will be disregarded\n\nfit_2b\n\n\nCall:\nlm(formula = y ~ z + x, data = data_2, refresh = 0)\n\nCoefficients:\n(Intercept)            z            x  \n     20.673        7.357        0.795  \n\n\nIn this case, with a strong dependence between pre-test and post-test, this adjustment has reduced the residual standard deviation by about a quarter.",
    "crumbs": [
      "Materials",
      "Week 8",
      "Notes"
    ]
  },
  {
    "objectID": "materials/notes/notes_w08.html#example-2-simulating-a-regression-design",
    "href": "materials/notes/notes_w08.html#example-2-simulating-a-regression-design",
    "title": "Week 8 Worksheet Notes",
    "section": "Example 2: simulating a regression design",
    "text": "Example 2: simulating a regression design\n\nWe can use simulation to test rather complex study designs\nImagine you are interested in students attitude towards smoking and how it depends on the medium of the message and the focus of the message\nWe want to know whether people’s attitude is different after seeing a visual anti-smoking message (these pictures on the package) vs. a text-message (the text belonging to that picture)\nWe are interested in whether the attitude that people report is different after seeing a message that regards the consequences on other people (e.g. smoking can harm your loved ones) as compared to yourself (smoking can cause cancer)\n\n\nStudy design\nDV: attitude towards smoking (0-100) IV1: medium (text vs. visual) IV2: focus (internal vs. external)\nThis is, there are 4 groups:\n\ngroup_TI will receive text-messages that are internal\ngroup_TE will receive text-messages that are external\ngroup_VI will receive visual messages that are internal\ngroup_VE will receive visual messages that are external\nassume that we expect that people’s attitude will be more negative after seeing a visual rather than text message if the focus is internal (i.e. the message is about yourself) because it might be difficult to imagine that oneself would get cancer after reading a text but seeing a picture might cause fear regardless\nfor the external focus on the other hand, we expect a more negative attitude after reading a text as compared to seeing a picture, as it might have more impact on attitude to imagine a loved one get hurt than seeing a stranger in a picture suffering from the consequences of second-hand smoking\nwe expect that the internal focus messages will be related to lower attitudes compared to the external focus messages on average but we expect no main-effect of picture vs. text-messages\nvisualize some rough means that show the desired behavior that we described in words earlier and see where we are going\nwe could make the overall mean of the internal focus groups (group_TI and group_VI) 20 and the mean of the external groups (group_TE and group_VE) 50 (this would already reflect the main-effect but also a belief that the smoking-attitudes are on average quite negative as we assume both means to be on the low end of the scale)\nassume that the mean of group_TI is 30 while the mean of group_VI is 10 and we could assume that the mean of group_TE is 40 and the mean of group_VE is 60\n\n\nfocus &lt;- rep(c(\"internal\", \"external\"), each = 2)\nmedia &lt;- rep(c(\"text\", \"visual\"), times = 2)\nmean_TI &lt;- 50\nmean_VI &lt;- 20\nmean_TE &lt;- 30\nmean_VE &lt;- 60\n\npd &lt;- data.frame(score = c(mean_TI, mean_VI, mean_TE, mean_VE), focus = focus, media = media)\n\ninteraction.plot(pd$focus, pd$media, pd$score, ylim = c(0,100))\n\n\n\n\n\n\n\n\n\nfocus &lt;- rep(c(\"internal\", \"external\"), each = 2)\nmedia &lt;- rep(c(\"text\", \"visual\"), times = 2)\nmean_TI &lt;- 43\nmean_VI &lt;- 40\nmean_TE &lt;- 45\nmean_VE &lt;- 47\n\npd &lt;- data.frame(score = c(mean_TI, mean_VI, mean_TE, mean_VE), focus = focus, media = media)\n\ninteraction.plot(pd$focus, pd$media, pd$score, ylim = c(0,100))\n\n\n\n\n\n\n\n\n\nin the new example there is a difference between the two media groups on average but it is only .50 points, so arguably it is small enough to represent the assumption of “no” effect, as in real-life “no” effect in terms of a difference being actually 0 is rather rare\ncome up with some reasonable standard-deviation; if we start at 50 and we want most people to be &lt; 80, we can set the 2-SD bound at 80 to get a standard-deviation of 15 (80-50)/2.\nlet’s assume that each of our groups has a standard-deviation of 15 points.\n\ngroup_TI = normal(n, 43, 15)\ngroup_VI = normal(n, 40, 15)\ngroup_TE = normal(n, 45, 15)\ngroup_VE = normal(n, 47, 15)\n\nn &lt;- 1e5\ngroup_TI &lt;-  rnorm(n, 43, 15)\ngroup_VI &lt;-  rnorm(n, 40, 15)\ngroup_TE &lt;-  rnorm(n, 45, 15)\ngroup_VE &lt;-  rnorm(n, 47, 15)\n\nparticipant &lt;- c(1:(n*4))\nfocus &lt;- rep(c(\"internal\", \"external\"), each = n*2)\nmedia &lt;- rep(c(\"text\", \"visual\"), each = n, times = 2)\n\ndata &lt;- data.frame(participant = participant, focus = focus, media = media, score = c(group_TI, group_VI, group_TE, group_VE))\n\nsummary(data)\n\n  participant       focus              media               score       \n Min.   :1e+00   Length:400000      Length:400000      Min.   :-36.36  \n 1st Qu.:1e+05   Class :character   Class :character   1st Qu.: 33.51  \n Median :2e+05   Mode  :character   Mode  :character   Median : 43.77  \n Mean   :2e+05                                         Mean   : 43.77  \n 3rd Qu.:3e+05                                         3rd Qu.: 54.01  \n Max.   :4e+05                                         Max.   :113.93  \n\n\n\n\nPower-analysis\n\nSome additional assumptions: suppose we have enough funding for a sizeable data collection and the aim is to ensure that we do not draw unwarranted conclusions from the research\nWe should then set the alpha-level at a more conservative value (\\(\\alpha = .001\\)); with this, we expect to draw non-realistic conclusions in the interaction effect in only about 1 in every 1,000 experiments\nWe also want to be sure that we do detect an existing effect and keep our power high at 95%; with this, we expect that if there is an interaction effect, we would detect it in 19 out of 20 cases (only miss it in 1 out of 20, or 5%)\nRunning the power-simulation can be very memory-demanding and the code can run a very long time to complete; it’s advised to start from various “low-resolution” sample-sizes (e.g. n = 10, n = 100, n = 200, etc.) to get a rough idea of where we can expect our loop to end. Then, the search can be made more specific in order to identify a more precise sample size.\n\n\nset.seed(1)\nn_sims &lt;- 1000 # we want 1000 simulations\np_vals &lt;- c()\npower_at_n &lt;- c(0) # this vector will contain the power for each sample-size (it needs the initial 0 for the while-loop to work)\nn &lt;- 100 # sample-size and start at 100 as we can be pretty sure this will not suffice for such a small effect\nn_increase &lt;- 100 # by which stepsize should n be increased\ni &lt;- 2\n\npower_crit &lt;- .95\nalpha &lt;- .001\n\nwhile(power_at_n[i-1] &lt; power_crit){\n  for(sim in 1:n_sims){\n    group_TI &lt;-  rnorm(n, 43, 15)\n    group_VI &lt;-  rnorm(n, 40, 15)\n    group_TE &lt;-  rnorm(n, 45, 15)\n    group_VE &lt;-  rnorm(n, 47, 15)\n    \n    participant &lt;- c(1:(n*4))\n    focus &lt;- rep(c(\"internal\", \"external\"), each = n*2)\n    media &lt;- rep(c(\"text\", \"visual\"), each = n, times = 2)\n    \n    data &lt;- data.frame(participant = participant, focus = focus, media = media, score = c(group_TI, group_VI, group_TE, group_VE))\n    data$media_sum_num &lt;- ifelse(data$media == \"text\", 1, -1) # apply sum-to-zero coding\n    data$focus_sum_num &lt;- ifelse(data$focus == \"external\", 1, -1) \n    lm_int &lt;- lm(score ~ 1 + focus_sum_num + media_sum_num + focus_sum_num:media_sum_num, data = data) # fit the model with the interaction\n    lm_null &lt;- lm(score ~ 1 + focus_sum_num + media_sum_num, data = data) # fit the model without the interaction\n    p_vals[sim] &lt;- anova(lm_int, lm_null)$`Pr(&gt;F)`[2] # put the p-values in a list\n  }\n    print(n)\n    power_at_n[i] &lt;- mean(p_vals &lt; alpha) # check power (i.e. proportion of p-values that are smaller than alpha-level of .10)\n    names(power_at_n)[i] &lt;- n\n    n &lt;- n+n_increase # increase sample-size by 100 for low-resolution testing first\n    i &lt;- i+1 # increase index of the while-loop by 1 to save power and cohens d to vector\n}\n\n[1] 100\n[1] 200\n[1] 300\n[1] 400\n[1] 500\n[1] 600\n[1] 700\n[1] 800\n[1] 900\n\npower_at_n &lt;- power_at_n[-1] # delete first 0 from the vector\n\nWe can plot the results form the power-simulation:\n\n\n\n\n\n\n\n\n\n\nAt roughly 900 participants we observe sufficient power",
    "crumbs": [
      "Materials",
      "Week 8",
      "Notes"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w08.html",
    "href": "materials/worksheets/worksheets_w08.html",
    "title": "Week 8 Worksheet Exercises",
    "section": "",
    "text": "By the end of the session you will learn how to perform:\n\nSimulation of random variables\nPower analysis via simulation",
    "crumbs": [
      "Materials",
      "Week 8",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w08.html#aims",
    "href": "materials/worksheets/worksheets_w08.html#aims",
    "title": "Week 8 Worksheet Exercises",
    "section": "",
    "text": "By the end of the session you will learn how to perform:\n\nSimulation of random variables\nPower analysis via simulation",
    "crumbs": [
      "Materials",
      "Week 8",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w08.html#setup",
    "href": "materials/worksheets/worksheets_w08.html#setup",
    "title": "Week 8 Worksheet Exercises",
    "section": "Setup",
    "text": "Setup\nCreate a worksheet document\nIn Week 1 you set up R and RStudio, and an RProject folder (we called it “HSS8005_labs”) with an .R script and a .qmd or .Rmd document in it (we called these “Lab_1”). Ideally, you saved this on a cloud drive so you can access it from any computer (e.g. OneDrive). You will be working in this folder. If it’s missing, complete Exercise 3 from the Week 1 Worksheet.\nCreate a new Quarto markdown file (.qmd) for this session (e.g. “Lab_7.qmd”) and work in it to complete the exercises and report on your final analysis.",
    "crumbs": [
      "Materials",
      "Week 8",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w08.html#r-packages",
    "href": "materials/worksheets/worksheets_w08.html#r-packages",
    "title": "Week 8 Worksheet Exercises",
    "section": "R packages",
    "text": "R packages\n\nCode# Just in case we get errors asking that the package repositories be explicitly set when installing new packages:\n\noptions(repos = list(CRAN = \"http://cran.rstudio.com/\"))\n\n# Install and load required packages\n\n# We can use the {pacman} package to easily install and load several packages:\n# ({pacman} itself may need installing if not yet installed)\n\npacman::p_load(\n  tidyverse, sjlabelled, easystats, \n  ggformula, ggeffects, marginaleffects, \n  modelsummary, gtsummary,\n  MASS                           # for the function `mvrnorm` to generate variables with pre-specified covariance structure\n  )",
    "crumbs": [
      "Materials",
      "Week 8",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w08.html#exercise-1bbasic-data-simulation",
    "href": "materials/worksheets/worksheets_w08.html#exercise-1bbasic-data-simulation",
    "title": "Week 8 Worksheet Exercises",
    "section": "Exercise 1:bBasic data simulation",
    "text": "Exercise 1:bBasic data simulation\n\n\n\n\n\n\n\n\n\nCompare the above distribution with a normal distribution that has a standard deviation of 2 instead of 1.\nSample 10,000 new values in rnorm with sd = 2 instead of sd = 1 and create a new histogram with hist.\nTo see what the distribution of sampled data might look like given a low sample size (e.g., 10), repeat the process of sampling from rnorm(n = 10, mean = 0, sd = 1) multiple times and look at the shape of the resulting histogram.",
    "crumbs": [
      "Materials",
      "Week 8",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w08.html#exercise-1-basic-data-simulation",
    "href": "materials/worksheets/worksheets_w08.html#exercise-1-basic-data-simulation",
    "title": "Week 8 Worksheet Exercises",
    "section": "Exercise 1: basic data simulation",
    "text": "Exercise 1: basic data simulation\n\nCoderand_norms_10000 &lt;- rnorm(n = 10000, mean = 0, sd = 1)\n\nhist(rand_norms_10000, xlab = \"Random value (X)\", col = \"grey\",\n     main = \"\", cex.lab = 1.5, cex.axis = 1.5)\n\n\n\n\n\n\n\n\nCompare the above distribution with a normal distribution that has a standard deviation of 2 instead of 1.\nSample 10,000 new values in rnorm with sd = 2 instead of sd = 1 and create a new histogram with hist.\nTo see what the distribution of sampled data might look like given a low sample size (e.g., 10), repeat the process of sampling from rnorm(n = 10, mean = 0, sd = 1) multiple times and look at the shape of the resulting histogram.",
    "crumbs": [
      "Materials",
      "Week 8",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w08.html#exercise-2-simple-randomised-experiment",
    "href": "materials/worksheets/worksheets_w08.html#exercise-2-simple-randomised-experiment",
    "title": "Week 8 Worksheet Exercises",
    "section": "Exercise 2: Simple randomised experiment",
    "text": "Exercise 2: Simple randomised experiment\nWork through Example 1 in the Notes, making the following adjustments:\n\nchange the seed number for the simulations to 8005\n\ndraw 300 samples instead of 100\nonce you have done the exercise with a normally distributed grade outcome, try another simulation for a Fail/Pass binary outcome and adjust the model functions accordingly",
    "crumbs": [
      "Materials",
      "Week 8",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/worksheets/worksheets_w08.html#exercise-3-advanced-multivariate-distributions",
    "href": "materials/worksheets/worksheets_w08.html#exercise-3-advanced-multivariate-distributions",
    "title": "Week 8 Worksheet Exercises",
    "section": "Exercise 3: (advanced) Multivariate distributions",
    "text": "Exercise 3: (advanced) Multivariate distributions\nWork through Example 2 in the Notes, and as an exercise, try to expand the work in Exercise 2 above by simulating an additional covariate and modelling joint effects on that data.",
    "crumbs": [
      "Materials",
      "Week 8",
      "Exercises"
    ]
  },
  {
    "objectID": "materials/slides/w8.html#the-uses-of-simulation-methods",
    "href": "materials/slides/w8.html#the-uses-of-simulation-methods",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "The uses of simulation methods",
    "text": "The uses of simulation methods\nSimulating data uses generating random data sets with known properties using code (or some other method). This can be useful in various contexts.\n\n\nTo better understand our models. Probability models mimic variation in the world, and the tools of simulation can help us better understand this variation. Patterns of randomness are contrary to normal human thinking and simulation helps in training our intuitions about averages and variation\n\nTo run statistical analyses (e.g., simulating a null distribution against which to compare a sample)\n\nTo approximate the sampling distribution of data and propagate this to the sampling distribution of statistical estimates and procedures"
  },
  {
    "objectID": "materials/slides/w8.html#distribution-functions",
    "href": "materials/slides/w8.html#distribution-functions",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Distribution functions",
    "text": "Distribution functions\nBase R functions:\n\nrnorm(): sampling from a normal distribution\nrunif(): sampling from a uniform distribution\nrbinom(): sampling from a binomial distribution\nrpois(): sampling from a Poisson distribution\n\n(Other distributions are also available)\n\nsample(): sampling elements from an R object with or without replacement\nreplicate(): often plays a role in conjunction with sampling functions; it is used to evaluate an expression N number of times repeatedly\n\nFrom non-base packages:\n\n\nMASS::mvtnorm(): multivariate normal; sampling multiple variables with a known correlation structure (i.e., we can tell R how variables should be correlated with one another) and normally distributed errors"
  },
  {
    "objectID": "materials/slides/w8.html#sampling-from-a-uniform-distribution",
    "href": "materials/slides/w8.html#sampling-from-a-uniform-distribution",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Sampling from a uniform distribution",
    "text": "Sampling from a uniform distribution\nThe runif function returns some number (n) of random numbers from a uniform distribution with a range from \\(a\\) (min) to \\(b\\) (max) such that \\(X\\sim\\mathcal U(a,b)\\) (verbally, \\(X\\) is sampled from a uniform distribution with the parameters \\(a\\) and \\(b\\)), where \\(-\\infty &lt; a &lt; b &lt; \\infty\\) (verbally, \\(a\\) is greater than negative infinity but less than \\(b\\), and \\(b\\) is finite). The default is to draw from a standard uniform distribution (i.e., \\(a = 0\\) and \\(b = 1\\)):\n\n\n# Sample a vector of ten numbers and store the results in the object `rand_unifs`\n# Note that the numbers will be different each time we re-run the `runif` function above.\n# If we want to recreate the same sample, we should set a `seed` number first\n\nrand_unifs &lt;- runif(n = 10000, min = 0, max = 1);\n\n\n\n\n\nThe first 40 numbers from the sample are:\n\n\n [1] 0.890188523 0.591166379 0.399648855 0.972892989 0.101147806 0.262360107\n [7] 0.181185795 0.474828251 0.250801761 0.511658177 0.738156238 0.628122433\n[13] 0.365605151 0.045501343 0.230871157 0.460637787 0.250218366 0.492162029\n[19] 0.856357203 0.566203399 0.147660543 0.383201637 0.093662443 0.001523262\n[25] 0.111942857 0.936084684 0.014159835 0.679044370 0.960550269 0.389671817\n[31] 0.849250339 0.568449457 0.938294313 0.012541510 0.262154853 0.101214718\n[37] 0.090681904 0.984074978 0.031501658 0.954211052 0.792093656 0.284537536\n[43] 0.661775433 0.281384660 0.681993441 0.760708201 0.130558664 0.793561081\n[49] 0.703461216 0.427160911\n\n\nTo visualise the entire sample, we can plot it on a histogram:"
  },
  {
    "objectID": "materials/slides/w8.html#sampling-from-a-normal-distribution",
    "href": "materials/slides/w8.html#sampling-from-a-normal-distribution",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Sampling from a normal distribution",
    "text": "Sampling from a normal distribution\nThe rnorm function returns some number (n) of randomly generated values given a set mean (\\(\\mu\\); mean) and standard deviation (\\(\\sigma\\); sd), such that \\(X\\sim\\mathcal N(\\mu,\\sigma^2)\\). The default is to draw from a standard normal (a.k.a., Gaussian) distribution (i.e., \\(\\mu = 0\\) and \\(\\sigma = 1\\)):\n\n\nrand_norms_10000 &lt;- rnorm(n = 10000, mean = 0, sd = 1)\n\nprint(rand_norms_10000[1:20])\n\n\n\n [1] -0.74432228  0.33997728  0.58149118  0.05342097 -0.65516320  0.30875826\n [7]  0.42112635  0.97564581  1.80259443 -0.64037078  0.23910519 -0.03569876\n[13] -0.76900149 -0.54166882 -0.02412268 -0.61409177 -1.12341512 -1.54125305\n[19]  0.16835280 -1.26876048"
  },
  {
    "objectID": "materials/slides/w8.html#sampling-from-a-normal-distribution-1",
    "href": "materials/slides/w8.html#sampling-from-a-normal-distribution-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Sampling from a normal distribution",
    "text": "Sampling from a normal distribution\n\nHistograms allow us to check how samples from the same distribution might vary.\nExercise: Compare the above distribution with a normal distribution that had a standard deviation of 2 instead of 1.\nSample 10,000 new values in rnorm with sd = 2 instead of sd = 1 and create a new histogram with hist.\nTo see what the distribution of sampled data might look like given a low sample size (e.g., 10), repeat the process of sampling from rnorm(n = 10, mean = 0, sd = 1) multiple times and look at the shape of the resulting histogram."
  },
  {
    "objectID": "materials/slides/w8.html#sampling-from-a-poisson-distribution",
    "href": "materials/slides/w8.html#sampling-from-a-poisson-distribution",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Sampling from a Poisson distribution",
    "text": "Sampling from a Poisson distribution\nA Poisson process describes events happening with some given probability over an area of time or space such that \\(X\\sim Poisson(\\lambda)\\), where the rate parameter \\(\\lambda\\) is both the mean and variance of the Poisson distribution (note that by definition, \\(\\lambda &gt; 0\\), and although \\(\\lambda\\) can be any positive real number, data are always integers, as with count data).\n\nSampling from a Poisson distribution can be done in R with rpois, which takes only two arguments specifying the number of values to be returned (n) and the rate parameter (lambda). There are no default values for rpois.\n\n\nrand_poissons &lt;- rpois(n = 10, lambda = 1.5)\n\nprint(rand_poissons)\n\n\n\n [1] 2 0 1 1 1 0 0 1 1 2"
  },
  {
    "objectID": "materials/slides/w8.html#sampling-from-a-poisson-distribution-1",
    "href": "materials/slides/w8.html#sampling-from-a-poisson-distribution-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Sampling from a Poisson distribution",
    "text": "Sampling from a Poisson distribution\nA histogram of a large number of values to see the distribution when \\(\\lambda = 4.5\\):\n\n\nrand_poissons_10000 &lt;- rpois(n = 10000, lambda = 4.5)"
  },
  {
    "objectID": "materials/slides/w8.html#sampling-from-a-binomial-distribution",
    "href": "materials/slides/w8.html#sampling-from-a-binomial-distribution",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Sampling from a binomial distribution",
    "text": "Sampling from a binomial distribution\n\nA binomial distribution describes the number of successes for some number of independent trials (\\(\\Pr(success) = p\\)).\nThe rbinom function returns the number of successes after size trials, in which the probability of success in each trial is prob.\nSampling from a binomial distribution in R with rbinom is a bit more complex than using runif, rnorm, or rpois.\nLike those previous functions, the rbinom function returns some number (n) of random numbers, but the arguments and output can be slightly confusing at first."
  },
  {
    "objectID": "materials/slides/w8.html#sampling-from-a-binomial-distribution-1",
    "href": "materials/slides/w8.html#sampling-from-a-binomial-distribution-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Sampling from a binomial distribution",
    "text": "Sampling from a binomial distribution\n\nFor example, suppose we want to simulate the flipping of a fair coin 1000 times, and we want to know how many times that coin comes up heads (success). We can do this with the following code:\n\n\n\ncoin_flips &lt;- rbinom(n = 1, size = 1000, prob = 0.5)\n\ncoin_flips\n\n\n\n[1] 491\n\n\n\n\nThe above result shows that the coin came up heads 491 times. But note the (required) argument n. This allows us to set the number of sequences to run.\nIf we instead set n = 2, then this could simulate the flipping of a fair coin 1000 times once to see how many times heads comes up, then repeating the whole process a second time to see how many times heads comes up again (or, if it is more intuitive, the flipping of two separate fair coins 1000 times at the same time)."
  },
  {
    "objectID": "materials/slides/w8.html#sampling-from-a-binomial-distribution-2",
    "href": "materials/slides/w8.html#sampling-from-a-binomial-distribution-2",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Sampling from a binomial distribution",
    "text": "Sampling from a binomial distribution\n\n\ncoin_flips_2 &lt;- rbinom(n = 2, size = 1000, prob = 0.5)\n\ncoin_flips_2\n\n\n\n[1] 496 506\n\n\n\n\nA coin was flipped 1000 times and returned 496 heads, and then another fair coin was flipped 1000 times and returned 506 heads.\nAs with the rnorm and runif functions, we can check to see what the distribution of the binomial function looks like if we repeat this process."
  },
  {
    "objectID": "materials/slides/w8.html#sampling-from-a-binomial-distribution-3",
    "href": "materials/slides/w8.html#sampling-from-a-binomial-distribution-3",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Sampling from a binomial distribution",
    "text": "Sampling from a binomial distribution\n\nSuppose that we want to see the distribution of the number of times heads comes up after 1000 flips. We can simulate the process of flipping 1000 times in a row with 10000 different coins:\n\n\n\ncoin_flips_10000 &lt;- rbinom(n = 10000, size = 1000, prob = 0.5)"
  },
  {
    "objectID": "materials/slides/w8.html#random-sampling-using-sample",
    "href": "materials/slides/w8.html#random-sampling-using-sample",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Random sampling using sample\n",
    "text": "Random sampling using sample\n\n\nSometimes it is useful to sample a set of values from a vector or list. The R function sample is very flexible for sampling a subset of numbers or elements from some structure (x) in R according to some set probabilities (prob).\nElements can be sampled from x some number of times (size) with or without replacement (replace), though an error will be returned if the size of the sample is larger than x but replace = FALSE (default).\nSuppose we want to ask R to pick a random number from one to ten with equal probability:\n\n\n\nrand_number_1 &lt;- sample(x = 1:10, size = 1)\n\nprint(rand_number_1)\n\n\n\n[1] 6"
  },
  {
    "objectID": "materials/slides/w8.html#random-sampling-using-sample-1",
    "href": "materials/slides/w8.html#random-sampling-using-sample-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Random sampling using sample\n",
    "text": "Random sampling using sample\n\n\nWe can increase the size of the sample to 10:\n\n\n\nrand_number_10 &lt;- sample(x = 1:10, size = 10)\nprint(rand_number_10)\n\n\n\n [1]  9  5  1 10  6  8  7  3  2  4\n\n\n\n\nNote that all numbers from 1 to 10 have been sampled, but in a random order. This is because the default is to sample without replacement, meaning that once a number has been sampled for the first element in rand_number_10, it is no longer available to be sampled again.\nWe can change this and allow for sampling with replacement:\n\n\n\nrand_number_10_r &lt;- sample(x = 1:10, size = 10, replace = TRUE)\n\nprint(rand_number_10_r)\n\n\n\n [1] 10  9  4  7  9  4  6 10  2  1\n\n\n\n\nNote that the numbers {4, 9, 10} are now repeated in the set of randomly sampled values above."
  },
  {
    "objectID": "materials/slides/w8.html#random-sampling-using-sample-2",
    "href": "materials/slides/w8.html#random-sampling-using-sample-2",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Random sampling using sample\n",
    "text": "Random sampling using sample\n\n\nSo far, because we have not specified a probability vector prob, the function assumes that every element in 1:10 is sampled with equal probability\nHere’s an example in which the numbers 1-5 are sampled with a probability of 0.05, while the numbers 6-10 are sampled with a probability of 0.15, thereby biasing sampling toward larger numbers; we always need to ensure that these probabilities need to sum to 1.\n\n\n\nprob_vec      &lt;- c( rep(x = 0.05, times = 5), rep(x = 0.15, times = 5))\n\nrand_num_bias &lt;- sample(x = 1:10, size = 10, replace = TRUE, prob = prob_vec)\n\nprint(rand_num_bias)\n\n\n\n [1] 10  8  1 10  7  8  4 10 10  5"
  },
  {
    "objectID": "materials/slides/w8.html#sampling-random-characters-from-a-list",
    "href": "materials/slides/w8.html#sampling-random-characters-from-a-list",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Sampling random characters from a list",
    "text": "Sampling random characters from a list\n\nWe can also sample characters from a list of elements; it is no different than sampling numbers\nFor example, if we want to create a simulated data set that includes three different species of some plant or animal, we could create a vector of species identities from which to sample:\n\n\n\nspecies &lt;- c(\"species_A\", \"species_B\", \"species_C\");\n\n\n\n\n\n\nWe can then sample from these three possible categories. For example:\n\n\n\nsp_sample &lt;- sample(x = species, size = 24, replace = TRUE, \n                    prob = c(0.5, 0.25, 0.25))\n\n\n\n\n\n\nWhat did the code above do?\n\n\n\n [1] \"species_C\" \"species_B\" \"species_A\" \"species_B\" \"species_A\" \"species_B\"\n [7] \"species_B\" \"species_B\" \"species_A\" \"species_B\" \"species_A\" \"species_B\"\n[13] \"species_A\" \"species_C\" \"species_A\" \"species_A\" \"species_B\" \"species_A\"\n[19] \"species_A\" \"species_A\" \"species_B\" \"species_B\" \"species_A\" \"species_B\""
  },
  {
    "objectID": "materials/slides/w8.html#simulating-data-with-known-correlations",
    "href": "materials/slides/w8.html#simulating-data-with-known-correlations",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Simulating data with known correlations",
    "text": "Simulating data with known correlations\n\nWe can generate variables \\(X_{1}\\) and \\(X_{2}\\) that have known correlations \\(\\rho\\) with with one another.\nFor example: two standard normal random variables with a sample size of 10000, and with correlation between them of 0.3:\n\n\n\nN   &lt;- 10000\nrho &lt;- 0.3\nx1  &lt;- rnorm(n = N, mean = 0, sd = 1)\nx2  &lt;- (rho * x1) + sqrt(1 - rho*rho) * rnorm(n = N, mean = 0, sd = 1)\n\n\n\n\n\n\nThese variables are generated by first simulating the sample \\(x_{1}\\) (x1 above) from a standard normal distribution. Then, \\(x_{2}\\) (x2 above) is calculated as\n\n\\(x_{2} = \\rho x_{1} + \\sqrt{1 - \\rho^{2}}x_{rand}\\),\nwhere \\(x_{rand}\\) is a sample from a normal distribution with the same variance as \\(x_{1}\\)."
  },
  {
    "objectID": "materials/slides/w8.html#simulating-data-with-known-correlations-1",
    "href": "materials/slides/w8.html#simulating-data-with-known-correlations-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Simulating data with known correlations",
    "text": "Simulating data with known correlations\n\nWe can generate variables \\(X_{1}\\) and \\(X_{2}\\) that have known correlations \\(\\rho\\) with with one another.\nFor example: two standard normal random variables with a sample size of 10000, and with correlation between them of 0.3:\n\n\n\nN   &lt;- 10000\nrho &lt;- 0.3\nx1  &lt;- rnorm(n = N, mean = 0, sd = 1)\nx2  &lt;- (rho * x1) + sqrt(1 - rho*rho) * rnorm(n = N, mean = 0, sd = 1)\n\n\n\n\n\n\nDoes the correlation equal rho (with some sampling error)?\n\n\n\ncor(x1, x2)\n\n\n\n[1] 0.2967485"
  },
  {
    "objectID": "materials/slides/w8.html#simulating-data-with-known-correlations-2",
    "href": "materials/slides/w8.html#simulating-data-with-known-correlations-2",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Simulating data with known correlations",
    "text": "Simulating data with known correlations\n\nThere is a more efficient way to generate any number of variables with different variances and correlations to one another.\nWe need to use the MASS library, which can be installed and loaded as below:\nIn the MASS library, the function mvrnorm can be used to generate any number of variables for a pre-specified covariance structure."
  },
  {
    "objectID": "materials/slides/w8.html#example-simulating-a-regression-design",
    "href": "materials/slides/w8.html#example-simulating-a-regression-design",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Example: simulating a regression design",
    "text": "Example: simulating a regression design\n\nassume that we expect that people’s attitude will be more negative after seeing a visual rather than text message if the focus is internal (i.e. the message is about yourself) because it might be difficult to imagine that oneself would get cancer after reading a text but seeing a picture might cause fear regardless\nfor the external focus on the other hand, we expect a more negative attitude after reading a text as compared to seeing a picture, as it might have more impact on attitude to imagine a loved one get hurt than seeing a stranger in a picture suffering from the consequences of second-hand smoking\nwe expect that the internal focus messages will be related to lower attitudes compared to the external focus messages on average but we expect no main-effect of picture vs. text-messages"
  },
  {
    "objectID": "materials/slides/w8.html#example-simulating-a-regression-design-1",
    "href": "materials/slides/w8.html#example-simulating-a-regression-design-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Example: simulating a regression design",
    "text": "Example: simulating a regression design\n\nvisualize some rough means that show the desired behavior that we described in words earlier and see where we are going\nwe could make the overall mean of the internal focus groups (group_TI and group_VI) 20 and the mean of the external groups (group_TE and group_VE) 50 (this would already reflect the main-effect but also a belief that the smoking-attitudes are on average quite negative as we assume both means to be on the low end of the scale)\nassume that the mean of group_TI is 30 while the mean of group_VI is 10 and we could assume that the mean of group_TE is 40 and the mean of group_VE is 60"
  },
  {
    "objectID": "materials/slides/w8.html#section-1",
    "href": "materials/slides/w8.html#section-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "focus &lt;- rep(c(\"internal\", \"external\"), each = 2)\nmedia &lt;- rep(c(\"text\", \"visual\"), times = 2)\nmean_TI &lt;- 43\nmean_VI &lt;- 40\nmean_TE &lt;- 45\nmean_VE &lt;- 47\n\npd &lt;- data.frame(score = c(mean_TI, mean_VI, mean_TE, mean_VE), focus = focus, media = media)\n\ninteraction.plot(pd$focus, pd$media, pd$score, ylim = c(0,100))"
  },
  {
    "objectID": "materials/slides/w8.html#section-2",
    "href": "materials/slides/w8.html#section-2",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "focus &lt;- rep(c(\"internal\", \"external\"), each = 2)\nmedia &lt;- rep(c(\"text\", \"visual\"), times = 2)\nmean_TI &lt;- 43\nmean_VI &lt;- 40\nmean_TE &lt;- 45\nmean_VE &lt;- 47\n\npd &lt;- data.frame(score = c(mean_TI, mean_VI, mean_TE, mean_VE), focus = focus, media = media)\n\ninteraction.plot(pd$focus, pd$media, pd$score, ylim = c(0,100))"
  },
  {
    "objectID": "materials/slides/w8.html#example-simulating-a-regression-design-2",
    "href": "materials/slides/w8.html#example-simulating-a-regression-design-2",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Example: simulating a regression design",
    "text": "Example: simulating a regression design\n\nin the new example there is a difference between the two media groups on average but it is only .50 points, so arguably it is small enough to represent the assumption of no effect, as in real-life no effect in terms of a difference being actually 0 is rather rare\ncome up with some reasonable standard-deviation; if we start at 50 and we want most people to be &lt; 80, we can set the 2-SD bound at 80 to get a standard-deviation of 15 (80-50)/2.\nlet’s assume that each of our groups has a standard-deviation of 15 points.\n\ngroup_TI = normal(n, 43, 15)\ngroup_VI = normal(n, 40, 15)\ngroup_TE = normal(n, 45, 15)\ngroup_VE = normal(n, 47, 15)"
  },
  {
    "objectID": "materials/slides/w8.html#example-simulating-a-regression-design-3",
    "href": "materials/slides/w8.html#example-simulating-a-regression-design-3",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Example: simulating a regression design",
    "text": "Example: simulating a regression design\n\n\nn &lt;- 1e5\ngroup_TI &lt;-  rnorm(n, 43, 15)\ngroup_VI &lt;-  rnorm(n, 40, 15)\ngroup_TE &lt;-  rnorm(n, 45, 15)\ngroup_VE &lt;-  rnorm(n, 47, 15)\n\nparticipant &lt;- c(1:(n*4))\nfocus &lt;- rep(c(\"internal\", \"external\"), each = n*2)\nmedia &lt;- rep(c(\"text\", \"visual\"), each = n, times = 2)\n\ndata &lt;- data.frame(participant = participant, focus = focus, media = media, score = c(group_TI, group_VI, group_TE, group_VE))\n\nsummary(data)\n\n\n\n  participant       focus              media               score       \n Min.   :1e+00   Length:400000      Length:400000      Min.   :-26.82  \n 1st Qu.:1e+05   Class :character   Class :character   1st Qu.: 33.41  \n Median :2e+05   Mode  :character   Mode  :character   Median : 43.69  \n Mean   :2e+05                                         Mean   : 43.72  \n 3rd Qu.:3e+05                                         3rd Qu.: 54.00  \n Max.   :4e+05                                         Max.   :115.45"
  },
  {
    "objectID": "materials/slides/w8.html#ready-for-power-analysis",
    "href": "materials/slides/w8.html#ready-for-power-analysis",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Ready for power-analysis",
    "text": "Ready for power-analysis\n\nSome additional assumptions: suppose we have enough funding for a sizeable data collection and the aim is to ensure that we do not draw unwarranted conclusions from the research\nWe should then set the alpha-level at a more conservative value (\\(\\alpha = .001\\)); with this, we expect to draw non-realistic conclusions in the interaction effect in only about 1 in every 1,000 experiments\nWe also want to be sure that we do detect an existing effect and keep our power high at 95%; with this, we expect that if there is an interaction effect, we would detect it in 19 out of 20 cases (only miss it in 1 out of 20, or 5%)\nRunning the power-simulation can be very memory-demanding and the code can run a very long time to complete; it’s advised to start from various low-resolution sample-sizes (e.g. n = 10, n = 100, n = 200, etc.) to get a rough idea of where we can expect our loop to end. Then, the search can be made more specific in order to identify a more precise sample size."
  },
  {
    "objectID": "materials/slides/w8.html#ready-for-power-analysis-1",
    "href": "materials/slides/w8.html#ready-for-power-analysis-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Ready for power-analysis",
    "text": "Ready for power-analysis\n\n\nset.seed(1)\nn_sims &lt;- 1000 # we want 1000 simulations\np_vals &lt;- c()\npower_at_n &lt;- c(0) # this vector will contain the power for each sample-size (it needs the initial 0 for the while-loop to work)\nn &lt;- 100 # sample-size and start at 100 as we can be pretty sure this will not suffice for such a small effect\nn_increase &lt;- 100 # by which stepsize should n be increased\ni &lt;- 2\n\npower_crit &lt;- .95\nalpha &lt;- .001\n\nwhile(power_at_n[i-1] &lt; power_crit){\n  for(sim in 1:n_sims){\n    group_TI &lt;-  rnorm(n, 43, 15)\n    group_VI &lt;-  rnorm(n, 40, 15)\n    group_TE &lt;-  rnorm(n, 45, 15)\n    group_VE &lt;-  rnorm(n, 47, 15)\n    \n    participant &lt;- c(1:(n*4))\n    focus &lt;- rep(c(\"internal\", \"external\"), each = n*2)\n    media &lt;- rep(c(\"text\", \"visual\"), each = n, times = 2)\n    \n    data &lt;- data.frame(participant = participant, focus = focus, media = media, score = c(group_TI, group_VI, group_TE, group_VE))\n    data$media_sum_num &lt;- ifelse(data$media == \"text\", 1, -1) # apply sum-to-zero coding\n    data$focus_sum_num &lt;- ifelse(data$focus == \"external\", 1, -1) \n    lm_int &lt;- lm(score ~ 1 + focus_sum_num + media_sum_num + focus_sum_num:media_sum_num, data = data) # fit the model with the interaction\n    lm_null &lt;- lm(score ~ 1 + focus_sum_num + media_sum_num, data = data) # fit the model without the interaction\n    p_vals[sim] &lt;- anova(lm_int, lm_null)$`Pr(&gt;F)`[2] # put the p-values in a list\n  }\n    print(n)\n    power_at_n[i] &lt;- mean(p_vals &lt; alpha) # check power (i.e. proportion of p-values that are smaller than alpha-level of .10)\n    names(power_at_n)[i] &lt;- n\n    n &lt;- n+n_increase # increase sample-size by 100 for low-resolution testing first\n    i &lt;- i+1 # increase index of the while-loop by 1 to save power and cohens d to vector\n}\n\n\n\n[1] 100\n[1] 200\n[1] 300\n[1] 400\n[1] 500\n[1] 600\n[1] 700\n[1] 800\n[1] 900\n\npower_at_n &lt;- power_at_n[-1] # delete first 0 from the vector"
  },
  {
    "objectID": "materials/slides/w8.html#example-simulating-a-regression-design-4",
    "href": "materials/slides/w8.html#example-simulating-a-regression-design-4",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Example: simulating a regression design",
    "text": "Example: simulating a regression design\nWe can plot the results form the power-simulation:\n\n\nAt roughly 900 participants we observe sufficient power"
  },
  {
    "objectID": "materials/slides/w8.html#outline",
    "href": "materials/slides/w8.html#outline",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Outline",
    "text": "Outline\n\n\nStatistical power\nData simulation\nStatistical power analysis via data simulation"
  },
  {
    "objectID": "materials/slides/w8.html#statistical-power-1",
    "href": "materials/slides/w8.html#statistical-power-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Statistical power",
    "text": "Statistical power\n\nStatistical power is defined as the probability, before a study is performed, that a particular comparison will achieve statistical significance at some predetermined level (typically a p-value below 0.05), given some assumed true effect size\nIf a certain effect of interest exists (e.g. a difference between two groups) power is the chance that we actually find the effect in a given study\nA power analysis is performed by first hypothesizing an effect size, then making some assumptions about the variation in the data and the sample size of the study to be conducted, and finally using probability calculations to determine the chance of the p-value being below the threshold\nThe conventional view is that you should avoid low-power studies because they are unlikely to succeed\nThere are several problems with this view, but it’s often required by research funding bodies"
  },
  {
    "objectID": "materials/slides/w8.html#simulating-a-regression-design-1",
    "href": "materials/slides/w8.html#simulating-a-regression-design-1",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Simulating a regression design",
    "text": "Simulating a regression design\n\nWe can use simulation to test rather complex study designs\nImagine you are interested in students attitude towards smoking and how it depends on the medium of the message and the focus of the message\nWe want to know whether people’s attitude is different after seeing a visual anti-smoking message (these pictures on the package) vs. a text-message (the text belonging to that picture)\nWe are interested in whether the attitude that people report is different after seeing a message that regards the consequences on other people (e.g. smoking can harm your loved ones) as compared to yourself (smoking can cause cancer)\n\nStudy design:\nDV: attitude towards smoking (0-100) IV1: medium (text vs. visual) IV2: focus (internal vs. external)\nThis is, there are 4 groups:\n\ngroup_TI will receive text-messages that are internal\ngroup_TE will receive text-messages that are external\ngroup_VI will receive visual messages that are internal\ngroup_VE will receive visual messages that are external"
  },
  {
    "objectID": "materials/slides/w8.html#section",
    "href": "materials/slides/w8.html#section",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "",
    "text": "focus &lt;- rep(c(\"internal\", \"external\"), each = 2)\nmedia &lt;- rep(c(\"text\", \"visual\"), times = 2)\nmean_TI &lt;- 50\nmean_VI &lt;- 20\nmean_TE &lt;- 30\nmean_VE &lt;- 60\n\npd &lt;- data.frame(score = c(mean_TI, mean_VI, mean_TE, mean_VE), focus = focus, media = media)\n\ninteraction.plot(pd$focus, pd$media, pd$score, ylim = c(0,100))"
  },
  {
    "objectID": "materials/slides/w8.html#outline-background-iframehttpscgmoreh.github.iowebslidesparticles-bkgparticles.html-background-opacity0.2-smallerfalse",
    "href": "materials/slides/w8.html#outline-background-iframehttpscgmoreh.github.iowebslidesparticles-bkgparticles.html-background-opacity0.2-smallerfalse",
    "title": "HSS8005 {{< iconify line-md plus >}}",
    "section": "Outline {background-iframe=https://cgmoreh.github.io/webslides/particles-bkg/particles.html background-opacity=0.2, smaller=FALSE}",
    "text": "Outline {background-iframe=https://cgmoreh.github.io/webslides/particles-bkg/particles.html background-opacity=0.2, smaller=FALSE}\n\n\nStatistical power\nData simulation\nStatistical power analysis via data simulation"
  }
]